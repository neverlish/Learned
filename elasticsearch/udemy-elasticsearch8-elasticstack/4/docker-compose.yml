version: "3.8"

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.26
    container_name: es7
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data

  mysql:
    image: mariadb:10.11  # MariaDB 10.11 사용
    container_name: mariadb
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: movielens
      MYSQL_USER: test
      MYSQL_PASSWORD: test
    ports:
      - "3306:3306"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./ml-100k:/docker-entrypoint-initdb.d/ml-100k
    command: 
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_unicode_ci
      - --local-infile=1


  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.26
    container_name: logstash7
    depends_on:
      - elasticsearch
      - kafka
    ports:
      - "5050:5000"
      - "5051:5001"
    environment:
      - "dead_letter_queue_enable=true"
      - "path.dead_letter_queue=/home/student/dlq"
    volumes:
      - ./logstash-input-plugins:/etc/logstash/conf.d/logstash-input-plugins\
      - ./logstash-syslog:/etc/logstash/conf.d/logstash-syslog
      - ./dlq:/home/student/dlq
    command: logstash -f /etc/logstash/conf.d/logstash.conf  
    # command: logstash -f /etc/logstash/conf.d/logstash/nginx/nginx-access-final.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/iis/iis-final-working.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/mongodb/mongodb-final.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/apache/apache-access-enriched.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/elasticsearch_logs/es-logs-final.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/elasticsearch_slowlogs/es-slowlog-final.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/mysql_slowlogs/mysql-slowlog-final.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/aws_elb/aws-elb.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/aws_alb/aws-alb.conf
    # command: logstash -f /etc/logstash/conf.d/logstash/aws_cloudfront/aws-cloudfront.conf
    # command: logstash -f /etc/logstash/conf.d/logstash-input-plugins/heartbeat/heartbeat.conf
    # command: logstash -f /etc/logstash/conf.d/logstash-input-plugins/generator/generator.conf
    # command: >
    #   bash -c "logstash -f /etc/logstash/conf.d/logstash-input-plugins/dead-letter-queue/dlq-data-01-ingest.conf;
    #            logstash -f /etc/logstash/conf.d/logstash-input-plugins/dead-letter-queue/dlq.conf"
    # command: logstash -f /etc/logstash/conf.d/logstash-input-plugins/http-poller/http-poller.conf
    # command: >
    #   bash -c "logstash -f /etc/logstash/conf.d/logstash-input-plugins/generator/generator.conf;
    #            logstash -f /etc/logstash/conf.d/logstash-syslog/syslog-forward-tcp.conf;
    #            logstash -f /etc/logstash/conf.d/logstash-syslog/logstash-monitoring-syslog.conf;"
  
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD-SHELL", "echo srvr | nc localhost 2181 | grep Mode"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:29092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
    mem_limit: 2G
    restart: unless-stopped
    

  spark:
    image: apache/spark:3.5.0
    container_name: spark
    user: root
    ports:
      - "4040:4040"  # Spark UI
      - "7077:7077"  # Spark Master
      - "8080:8080"  # Spark Master Web UI
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - IVY_HOME=/home/spark/.ivy2
    volumes:
      - ./spark-apps:/app  # Mount local directory for Spark applications
      - spark-ivy-cache:/home/spark/.ivy2
    command: 
      - bash
      - -c
      - |
        chown -R spark:spark /home/spark/.ivy2
        chmod -R 777 /home/spark/.ivy2
        gosu spark /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark

  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    depends_on:
      - spark
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_MASTER=spark://spark:7077
    volumes:
      - ./spark-apps:/app
    command: 
      - /opt/spark/bin/spark-class
      - org.apache.spark.deploy.worker.Worker
      - spark://spark:7077

volumes:
  esdata:
  kafka_data:
  spark-ivy-cache: