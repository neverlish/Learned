{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760ee404-aa9f-4e9b-a592-b4cfaba085d7",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94f14f-8f37-42ff-890c-a73607930545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53840e9-8fd2-4593-abe8-7ab2b2b3d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"/home/wonkyum/fc-asr/gridspace-stanford-harper-valley\"\n",
    "transcript_files=glob.glob(os.path.join(root_dir, \"data/transcript\", \"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e288b5-a7da-4dfe-8b09-f9ca4dc15a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[]\n",
    "for jsonfile in transcript_files:\n",
    "    jsondata=json.load(open(jsonfile,'r'))\n",
    "    for datum in jsondata:\n",
    "        if \"transcript\" in datum and \"dialog_acts\" in datum:\n",
    "            if len(datum[\"transcript\"]) > 20:\n",
    "                all_data.append({\"transcript\": datum[\"speaker_role\"]+\": \"+datum[\"human_transcript\"], \"dialog_acts\": datum[\"dialog_acts\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bee5b-66d2-4bf0-a78c-70b554e94bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c59f02-fdf0-49fd-bb48-c64d9b8cc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels=[]\n",
    "for datum in all_data:\n",
    "    for label in datum[\"dialog_acts\"]:\n",
    "        all_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a52ecc-34b2-43dc-a22a-cc9bb194c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels=sorted(list(set(all_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de0be4-2471-4597-b9b3-2781c3985099",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bfbf3a-e727-474b-9aa8-0cd1a1af48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3d42e1-a248-4db0-9751-cd294d35f485",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea2081e-72a5-4381-974f-e1d585aeeac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a7e9-cba6-4a3c-8963-72980608fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe321898-7841-4c0b-899b-f4d714e6377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.fit_transform([[\"gridspace_bear_with_me\", \"gridspace_acknowledgement\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f8289-831c-4619-a9e9-698445c985fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[]\n",
    "labels=[]\n",
    "\n",
    "for datum in all_data:\n",
    "    texts.append(datum[\"transcript\"])\n",
    "    labels.append(datum[\"dialog_acts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3a997-5bee-42e2-8454-b12abb1a8f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0], labels[1], labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e7a06-de5f-4542-9d2c-e5eec30012d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels=mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360193d3-5b1d-4302-ac96-274c8a516926",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_labels[0], binary_labels[1], binary_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9e475-bb76-44a2-9cf5-cde6b12c4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_texts(texts):\n",
    "    return tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce65da5-16a4-4010-86a0-f17ab2c8b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = encode_texts(texts)\n",
    "binary_labels = torch.tensor(binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44890e3c-2c17-4985-b06b-69d01d88d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(encoded_inputs['input_ids'], encoded_inputs['attention_mask'], binary_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefa629-24e0-4458-ad20-f5dc7c7a81a9",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5108b-c7c8-4ca5-9343-09c6e7e85b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "class BertForMultiLabelClassification(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BertForMultiLabelClassification, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # Load pre-trained BERT\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return torch.sigmoid(logits)  # Apply sigmoid to output logits for binary classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0266710-2021-4a3d-b486-26b5a03fe4e7",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b54ece-54e5-4afc-8ae3-e00e86671bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0575fd-24da-4600-af0c-69fd53bc1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = BertForMultiLabelClassification(num_labels=len(unique_labels))\n",
    "# Freeze all the parameters in the BERT model\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Move the model to the GPU after freezing the parameters\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490549b1-3405-4045-832c-ab4542f956ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f05993-4914-44be-9453-1c2137bfc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "num_epochs=10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = [b.to(\"cuda\") for b in batch]\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_function(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c60f1-25cd-4c49-97be-642395ca873d",
   "metadata": {},
   "source": [
    "# ASR + Dialog Acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb33b56-8ab4-461a-9cec-aa763a5f7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from lightning import ConformerRNNTModule\n",
    "from transforms import get_data_module\n",
    "import json\n",
    "from torchaudio.models import Hypothesis, RNNTBeamSearch\n",
    "from typing import List, Tuple\n",
    "import math\n",
    "from IPython.display import Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c1a41-d062-4958-a74d-5a192adb68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_model = spm.SentencePieceProcessor(model_file='/home/wonkyum/fc-asr/spm_unigram_1023.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47431c11-283f-4d8b-bd01-f03859eddb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/home/wonkyum/fc-asr/exp/checkpoints/epoch=21-step=1451337.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b3a25-1965-4521-8061-46aebe30747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnt_module = ConformerRNNTModule.load_from_checkpoint(checkpoint_path, sp_model=sp_model).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb34233-c091-4c77-8f28-58205d4a2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnt_module.model.to(\"cuda\")\n",
    "decoder = RNNTBeamSearch(rnnt_module.model, 1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26567872-8fe1-46c2-83aa-94abc0470d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_hypos(\n",
    "    hypos: List[Hypothesis], sp_model: spm.SentencePieceProcessor\n",
    ") -> List[Tuple[str, float, List[int], List[int]]]:\n",
    "    tokens_idx = 0\n",
    "    score_idx = 3\n",
    "    post_process_remove_list = [\n",
    "        sp_model.unk_id(),\n",
    "        sp_model.eos_id(),\n",
    "        sp_model.pad_id(),\n",
    "    ]\n",
    "    filtered_hypo_tokens = [\n",
    "        [token_index for token_index in h[tokens_idx][1:] if token_index not in post_process_remove_list] for h in hypos\n",
    "    ]\n",
    "    hypos_str = [sp_model.decode(s) for s in filtered_hypo_tokens]\n",
    "    hypos_ids = [h[tokens_idx][1:] for h in hypos]\n",
    "    hypos_score = [[math.exp(h[score_idx])] for h in hypos]\n",
    "\n",
    "    nbest_batch = list(zip(hypos_str, hypos_score, hypos_ids))\n",
    "\n",
    "    return nbest_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474c8f6-c2ce-457a-81f6-9517dbfec7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _piecewise_linear_log(x):\n",
    "    x = x * _gain\n",
    "    x[x > math.e] = torch.log(x[x > math.e])\n",
    "    x[x <= math.e] = x[x <= math.e] / math.e\n",
    "    return x\n",
    "\n",
    "\n",
    "class FunctionalModule(torch.nn.Module):\n",
    "    def __init__(self, functional):\n",
    "        super().__init__()\n",
    "        self.functional = functional\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.functional(input)\n",
    "\n",
    "class GlobalStatsNormalization(torch.nn.Module):\n",
    "    def __init__(self, global_stats_path):\n",
    "        super().__init__()\n",
    "\n",
    "        with open(global_stats_path) as f:\n",
    "            blob = json.loads(f.read())\n",
    "\n",
    "        self.mean = torch.tensor(blob[\"mean\"])\n",
    "        self.invstddev = torch.tensor(blob[\"invstddev\"])\n",
    "\n",
    "    def forward(self, input):\n",
    "        return (input - self.mean) * self.invstddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d33cee-5955-4911-8303-8573daab06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decibel = 2 * 20 * math.log10(torch.iinfo(torch.int16).max)\n",
    "_gain = pow(10, 0.05 * _decibel)\n",
    "_spectrogram_transform = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=400, n_mels=80, hop_length=160)\n",
    "\n",
    "\n",
    "\n",
    "def run_decoder(waveform):\n",
    "    extra_pipeline= torch.nn.Sequential(\n",
    "            FunctionalModule(_piecewise_linear_log),\n",
    "            GlobalStatsNormalization('./global_stats.json'),\n",
    "    )\n",
    "    mel_f = _spectrogram_transform(waveform[0].squeeze()).transpose(1, 0)\n",
    "    mel_f = torch.nn.utils.rnn.pad_sequence(mel_f, batch_first=True)\n",
    "    feats=extra_pipeline(mel_f)\n",
    "    lengths=torch.tensor(feats.shape[0])\n",
    "    hypotheses = decoder(feats.to(\"cuda\"), lengths.to(\"cuda\"), 20)\n",
    "    result=post_process_hypos(hypotheses, sp_model)\n",
    "    return result[0][0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ddfff-37be-49d2-87e6-ca0a773ee638",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_wave_form, samplerate=torchaudio.load('/home/wonkyum/help.wav')\n",
    "Audio(my_wave_form.numpy(), rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4576185-d0ff-4a3c-9590-1cb7305d0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_text=run_decoder(my_wave_form)\n",
    "print(asr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c404f-360c-4ac5-b088-6ecb7d167a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = encode_texts(\"agent: \"+asr_text)\n",
    "model(encoded_inputs['input_ids'].to(\"cuda\"), encoded_inputs['attention_mask'].to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263f745-7c10-4dac-9b07-77b75e0347c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
