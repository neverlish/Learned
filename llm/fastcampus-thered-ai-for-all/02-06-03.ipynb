{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0_caBv3uJCn"
      },
      "source": [
        "# 6교시 1. 어텐션의 핵심 원리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n6fxgcwuJCu"
      },
      "source": [
        "### 실습: 어텐션의 핵심 원리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq1D4w0LBvI2"
      },
      "source": [
        "입력 데이터 준비\n",
        "\n",
        "<img src=\"https://github.com/taehojo/fastcampus_ai/blob/master/data/img/06-01.png?raw=1\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rlF741qHBvI2",
        "outputId": "662cee32-2e50-4cd8-9e12-0a4c6c6bd23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 형태: (3, 5, 512)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 전체 출력 형식을 소수점 이하 네 자리로 설정\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "\n",
        "# 단어와 해당 임베딩 벡터를 딕셔너리로 정의합니다.\n",
        "embedding_dict = {\n",
        "    '<sos>': np.random.rand(512),\n",
        "    '<eos>': np.random.rand(512),\n",
        "    '커피': np.random.rand(512),\n",
        "    '한잔': np.random.rand(512),\n",
        "    '어때': np.random.rand(512),\n",
        "    '오늘': np.random.rand(512),\n",
        "    '날씨': np.random.rand(512),\n",
        "    '좋네': np.random.rand(512),\n",
        "    '옷이': np.random.rand(512),\n",
        "    '어울려요': np.random.rand(512),\n",
        "    'PAD': np.zeros(512)  # 패딩 벡터는 0으로 채웁니다.\n",
        "}\n",
        "\n",
        "# 입력 문장\n",
        "sentences = [\n",
        "    ['<sos>', '커피', '한잔', '어때', '<eos>'],\n",
        "    ['<sos>', '오늘', '날씨', '좋네', '<eos>'],\n",
        "    ['<sos>', '옷이', '어울려요', '<eos>', 'PAD']\n",
        "]\n",
        "\n",
        "# 토큰을 임베딩 벡터로 변환\n",
        "embeddings = np.array([[embedding_dict[token] for token in sentence] for sentence in sentences])\n",
        "print(\"임베딩 행렬의 형태:\", embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY5IGHoUBvI3"
      },
      "source": [
        "쿼리, 키, 밸류\n",
        "\n",
        "<img src=\"https://github.com/taehojo/fastcampus_ai/blob/master/data/img/06-02.png?raw=1\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-eAk1VcBvI3",
        "outputId": "76055e9f-63d0-4723-cc7a-84625146641d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "쿼리 행렬의 형태: (3, 5, 64)\n",
            "키 행렬의 형태: (3, 64, 5)\n",
            "밸류 행렬의 형태: (3, 5, 64)\n"
          ]
        }
      ],
      "source": [
        "# 쿼리, 키, 밸류 행렬 초기화\n",
        "num_heads = 8\n",
        "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
        "heads = np.split(embeddings, num_heads, axis=2)  # 512차원 임베딩 벡터를 8개의 헤드로 분할하여 heads에 저장\n",
        "queries = heads.copy()\n",
        "keys = [head.transpose(0, 2, 1) for head in heads]  # 키 행렬을 각 헤드의 전치를 통해 초기화 (첫 번째 축: 배치 크기, 두 번째 축: 문장 길이, 세 번째 축: 헤드 차원)\n",
        "values = heads.copy()\n",
        "\n",
        "print(\"쿼리 행렬의 형태:\", queries[0].shape)\n",
        "print(\"키 행렬의 형태:\", keys[0].shape)\n",
        "print(\"밸류 행렬의 형태:\", values[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UwwfCKbEBvI3",
        "outputId": "be635f09-a41e-4491-94ac-93311aa29c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
            "[0.5164 0.5101 0.4976]\n"
          ]
        }
      ],
      "source": [
        "# 특정 토큰 (커피, 한잔, 어때)의 인덱스\n",
        "tokens_of_interest = ['커피', '한잔', '어때']\n",
        "indices_of_interest = [sentences[0].index(token) for token in tokens_of_interest]\n",
        "\n",
        "# 어텐션 이전의 임베딩 테이블 중 특정 토큰들의 평균 값 계산\n",
        "print(\"어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
        "initial_avg = np.mean(embeddings[0, indices_of_interest, :], axis=1)\n",
        "print(initial_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obIaUdGSBvI3"
      },
      "source": [
        "---\n",
        "스케일링 및 소프트맥스\n",
        "\n",
        "<img src=\"https://github.com/taehojo/fastcampus_ai/blob/master/data/img/06-03.png?raw=1\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_ZMLBpdcBvI3",
        "outputId": "7aa60847-19de-474f-a159-9c04d2347851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
            "[0.5144 0.5137 0.5113]\n"
          ]
        }
      ],
      "source": [
        "# 스케일링 및 어텐션 스코어 계산\n",
        "attention_scores = np.matmul(queries[0], keys[0])\n",
        "scaling_factor = np.sqrt(head_dim)\n",
        "scaled_attention_scores = attention_scores / scaling_factor\n",
        "\n",
        "# 패딩 처리\n",
        "mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
        "mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
        "scaled_attention_scores = np.where(mask, -np.inf, scaled_attention_scores)\n",
        "\n",
        "# 소프트맥스 적용 함수\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "# 복원된 헤드를 저장할 리스트\n",
        "restored_heads = []\n",
        "\n",
        "for i in range(num_heads):\n",
        "    query = queries[i]\n",
        "    key = keys[i]\n",
        "    value = values[i]\n",
        "\n",
        "    # 내적 계산 후 스케일링\n",
        "    attention_scores = np.matmul(query, key) / scaling_factor\n",
        "\n",
        "    # 패딩 처리\n",
        "    mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
        "    mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
        "    attention_scores = np.where(mask, -np.inf, attention_scores)\n",
        "\n",
        "    # 소프트맥스 적용\n",
        "    attention_weights = softmax(attention_scores)\n",
        "\n",
        "    # 밸류와의 곱셈\n",
        "    restored_head = np.matmul(attention_weights, value)\n",
        "    restored_heads.append(restored_head)\n",
        "\n",
        "# 모든 헤드를 결합하여 원래 차원으로 복원\n",
        "final_output = np.concatenate(restored_heads, axis=2)\n",
        "\n",
        "# 어텐션 이후의 결과 중 특정 토큰들의 평균 값 계산\n",
        "print(\"어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
        "final_avg = np.mean(final_output[0, indices_of_interest, :], axis=1)\n",
        "print(final_avg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yAUrC0iBvI3"
      },
      "source": [
        "## 전체 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70uH79l7BvI3"
      },
      "source": [
        "<img src=\"https://github.com/taehojo/fastcampus_ai/blob/master/data/img/06-04.png?raw=1\" width=\"200\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0D80gNEyBvI4",
        "outputId": "79c215d8-d727-4d8e-e6c3-06229e75d519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 형태: (3, 5, 512)\n",
            "쿼리 행렬의 형태: (3, 5, 64)\n",
            "키 행렬의 형태: (3, 64, 5)\n",
            "밸류 행렬의 형태: (3, 5, 64)\n",
            "어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
            "[0.5095 0.5078 0.4998]\n",
            "어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\n",
            "[0.5048 0.5039 0.5036]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 전체 출력 형식을 소수점 이하 네 자리로 설정\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "\n",
        "# 단어와 해당 임베딩 벡터를 딕셔너리로 정의합니다.\n",
        "embedding_dict = {\n",
        "    '<sos>': np.random.rand(512),\n",
        "    '<eos>': np.random.rand(512),\n",
        "    '커피': np.random.rand(512),\n",
        "    '한잔': np.random.rand(512),\n",
        "    '어때': np.random.rand(512),\n",
        "    '오늘': np.random.rand(512),\n",
        "    '날씨': np.random.rand(512),\n",
        "    '좋네': np.random.rand(512),\n",
        "    '옷이': np.random.rand(512),\n",
        "    '어울려요': np.random.rand(512),\n",
        "    'PAD': np.zeros(512)  # 패딩 벡터는 0으로 채웁니다.\n",
        "}\n",
        "\n",
        "# 입력 문장\n",
        "sentences = [\n",
        "    ['<sos>', '커피', '한잔', '어때', '<eos>'],\n",
        "    ['<sos>', '오늘', '날씨', '좋네', '<eos>'],\n",
        "    ['<sos>', '옷이', '어울려요', '<eos>', 'PAD']\n",
        "]\n",
        "max_len = 6  # 최대 문장 길이\n",
        "\n",
        "# 토큰을 임베딩 벡터로 변환\n",
        "embeddings = np.array([[embedding_dict[token] for token in sentence] for sentence in sentences])\n",
        "print(\"임베딩 행렬의 형태:\", embeddings.shape)  # (3, 6, 512)\n",
        "\n",
        "# 쿼리, 키, 밸류 행렬 초기화\n",
        "num_heads = 8\n",
        "head_dim = 512 // num_heads  # 각 헤드의 차원\n",
        "heads = np.split(embeddings, num_heads, axis=2)  # 512차원 임베딩 벡터를 8개의 헤드로 분할하여 heads에 저장\n",
        "queries = heads.copy()\n",
        "keys = [head.transpose(0, 2, 1) for head in heads]  # 키 행렬을 각 헤드의 전치를 통해 초기화 (첫 번째 축: 배치 크기, 두 번째 축: 문장 길이, 세 번째 축: 헤드 차원)\n",
        "values = heads.copy()\n",
        "\n",
        "print(\"쿼리 행렬의 형태:\", queries[0].shape)  # (3, 6, 64)\n",
        "print(\"키 행렬의 형태:\", keys[0].shape)  # (3, 64, 6)\n",
        "print(\"밸류 행렬의 형태:\", values[0].shape)  # (3, 6, 64)\n",
        "\n",
        "# 특정 토큰 (커피, 한잔, 어때)의 인덱스\n",
        "tokens_of_interest = ['커피', '한잔', '어때']\n",
        "indices_of_interest = [sentences[0].index(token) for token in tokens_of_interest]\n",
        "\n",
        "# 어텐션 이전의 임베딩 테이블 중 특정 토큰들의 평균 값 계산\n",
        "print(\"어텐션 이전의 임베딩 테이블 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
        "initial_avg = np.mean(embeddings[0, indices_of_interest, :], axis=1)\n",
        "print(initial_avg)\n",
        "\n",
        "# 스케일링 및 어텐션 스코어 계산\n",
        "attention_scores = np.matmul(queries[0], keys[0])\n",
        "scaling_factor = np.sqrt(head_dim)\n",
        "scaled_attention_scores = attention_scores / scaling_factor\n",
        "\n",
        "# 패딩 처리\n",
        "mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
        "mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
        "scaled_attention_scores = np.where(mask, -np.inf, scaled_attention_scores)\n",
        "\n",
        "# 소프트맥스 적용 함수\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "# 복원된 헤드를 저장할 리스트\n",
        "restored_heads = []\n",
        "\n",
        "for i in range(num_heads):\n",
        "    query = queries[i]\n",
        "    key = keys[i]\n",
        "    value = values[i]\n",
        "\n",
        "    # 내적 계산 후 스케일링\n",
        "    attention_scores = np.matmul(query, key) / scaling_factor\n",
        "\n",
        "    # 패딩 처리\n",
        "    mask = np.array([[token == 'PAD' for token in sentence] for sentence in sentences])\n",
        "    mask = mask[:, np.newaxis, :]  # 차원을 맞추기 위해 확장\n",
        "    attention_scores = np.where(mask, -np.inf, attention_scores)\n",
        "\n",
        "    # 소프트맥스 적용\n",
        "    attention_weights = softmax(attention_scores)\n",
        "\n",
        "    # 밸류와의 곱셈\n",
        "    restored_head = np.matmul(attention_weights, value)\n",
        "    restored_heads.append(restored_head)\n",
        "\n",
        "# 모든 헤드를 결합하여 원래 차원으로 복원\n",
        "final_output = np.concatenate(restored_heads, axis=2)\n",
        "\n",
        "# 어텐션 이후의 결과 중 특정 토큰들의 평균 값 계산\n",
        "print(\"어텐션 이후의 결과 중 '커피', '한잔', '어때' 토큰의 평균 값:\")\n",
        "final_avg = np.mean(final_output[0, indices_of_interest, :], axis=1)\n",
        "print(final_avg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNMhTf-RBvI4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "13-colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
