{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../dataset/llamaindex_data/openai.txt\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 0}, page_content='Mistral AI SAS\\nCompany type Private\\nIndustry Artificial intelligence\\nFounded 28 April 2023\\nFounders Arthur Mensch\\nGuillaume Lample\\nTimoth é e Lacroix\\nHeadquarters Paris, France\\nKey people Arthur Mensch (CEO)\\nGuillaume Lample (Chief\\nScientist)\\nTimoth é e Lacroix (CTO)\\nProducts Mistral 7B\\nMixtral 8x7B\\nMistral Medium\\nMistral Large\\nMistral Large 2 (123B)\\nMixtral 8x22B\\nCodestral 22B\\nCodestral Mamba (7B)\\nMathstral (7B)\\nMistral NeMo 12B\\nMistral Embed\\nNumber of\\nemployees\\n150 (2025)[1]\\nWebsite mistral.ai (https://mistral.a\\ni/)\\nMistral AI\\nMistral AI SAS is a French artificial intelligence\\n(AI) startup, headquartered in Paris. It specializes in\\nopen-weight large language models (LLMs).[2][3]\\nThe company is named after the mistral, a powerful,\\ncold wind in southern France.[4]\\nMistral AI was established in April 2023 by three\\nFrench AI researchers, Arthur Mensch, Guillaume\\nLample and Timothée Lacroix.[5]\\nMensch, an expert in advanced AI systems, is a\\nformer employee of Google DeepMind; Lample and\\nLacroix, meanwhile, are large-scale AI models\\nspecialists who had worked for Meta Platforms.[6]\\nThe trio originally met during their studies at École\\nPolytechnique.[4]\\nMistral AI emphasizes openness and innovation in\\nthe AI field and positions itself as an alternative to\\nproprietary models.[7]\\nThe company has gained prominence as an\\nalternative to proprietary AI systems as it aims to\\n\"democratize\" AI by focusing on open-source\\ninnovation.[8]\\nNamesake\\nHistory\\nCompany operation\\nPhilosophy\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 1/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 1}, page_content=\"Example of an image generated with Le Chat,\\nthe prompt is Generate an image you\\nfeel represents yourself,\\nMistral AI\\nScreenshot of Le Chat, Mistral AI chatbot,\\ndescribing Wikipedia in a thoughtful way\\nIn June 2023, the start-up carried out a first fundraising\\nof €105 million ($117 million) with investors including\\nthe American fund Lightspeed Venture Partners, Eric\\nSchmidt, Xavier Niel and JCDecaux. The valuation is then\\nestimated by the Financial Times at €240 million ($267\\nmillion).\\nOn 10 December 2023, Mistral AI announced that it had\\nraised €385 million ($428 million) as part of its second\\nfundraising. This round of financing involves the\\nCalifornian fund Andreessen Horowitz, BNP Paribas and\\nthe software publisher Salesforce.[9]\\nIn October 2023, Mistral AI raised €385 million.[10]\\nBy December 2023, it was valued at over $2\\nbillion.[11][12][13]\\nOn 16 April 2024, reporting revealed that Mistral was in\\ntalks to raise €500 million, a deal that would more than\\ndouble its current valuation to at least €5 billion.[14]\\nIn June 2024, Mistral AI secured a €600 million ($645\\nmillion) funding round, elevating its valuation to €5.8\\nbillion ($6.2 billion).[15]\\nLed by venture capital firm General Catalyst,[16] this\\nround resulted in additional contributions from existing\\ninvestors. The funds aim to support the company's\\nexpansion.\\nBased on valuation, the company is currently in fourth\\nplace in the global AI race and in first place outside the\\nSan Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection and\\nPerplexity.[17]\\nOn 26 February 2024, Microsoft announced a new partnership with the company to expand its\\npresence in the artificial intelligence industry.\\nUnder the agreement, Mistral's language models will be available on Microsoft's Azure cloud, while\\nthe multilingual conversational assistant Le Chat will be launched in the style of ChatGPT.[18]\\nFunding\\nPartnership with Microsoft\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 2/9\"),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 2}, page_content='On November 19, 2024, the company announced updates for Le Chat.\\nIt added the ability to create images, in partnership with Black Forest Labs, utilizing the Flux Pro\\nmodel.\\nAdditionally, it introduced the capability to search for information on the internet to provide\\nreliable and up-to-date information.\\nFurthermore, it launched the Canvas system, a collaborative interface where the AI generates code\\nand the user can modify it.\\nOn February 6, 2025, Mistral AI released its AI assistant, Le Chat, on iOS and Android, making its\\nlanguage models accessible on mobile devices.\\nLe Chat offers features including web search, image generation, and real-time updates.\\nMistral AI also introduced a Pro subscription tier, priced at $14.99 per month, which provides\\naccess to more advanced models, unlimited messaging, and web browsing.[19]\\nServices\\nLe Chat\\nMobile app\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 3/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 3}, page_content='Name Release Date\\nNumber of\\nParameters\\n(Billion)\\nLicense Notes\\nMistral\\nSmall 3\\n25.01\\nJanuary 2025 24 Apache 2.0\\nUpon its release in January 2025, Mistral Small 3 is\\nbenchmarked as the leader in the \"small\" models\\ncategory below 70B, featuring 24B parameters and\\ncapabilities comparable to those of larger\\nmodels.[20][21]\\nMistral\\nLarge 2\\n24.11\\nNovember 2024 123\\nMistral\\nResearch\\nLicense\\n[21]\\nPixtral\\nLarge\\n24.11\\nNovember 2024 124\\nMistral\\nResearch\\nLicense\\nOn November 19, 2024, the company introduced\\nPixtral Large, an improvement over Pixtral 12B,\\nintegrating a 1-billion-parameter visual encoder\\ncoupled with Mistral Large 2. This model has also been\\nenhanced, particularly for long contexts and function\\ncalls.[22] [21]\\nMinistral\\n8B 24.10 October 2024 8\\nMistral\\nResearch\\nLicense\\n[21]\\nMinistral\\n3B 24.10 October 2024 3 Proprietary [21]\\nPixtral\\n24.09 September 2024 12 Apache 2.0 [21]\\nMistral\\nLarge 2\\n24.07\\nJuly 2024 123\\nMistral\\nResearch\\nLicense\\nMistral Large 2 was announced on July 24, 2024, and\\nreleased on Hugging Face. It is available for free with a\\nMistral Research Licence, and with a commercial\\nlicence for commercial purposes. Mistral AI claims that\\nit is fluent in dozens of languages, including many\\nprogramming languages. Unlike the previous Mistral\\nLarge, this version was released with open weights.\\nThe model has 123 billion parameters and a context\\nlength of 128,000 tokens. [21]\\nCodestral\\nMamba\\n7B\\nJuly 2024 7 Apache 2.0\\nCodestral Mamba is based on the Mamba 2\\narchitecture, which allows it to generate responses\\neven with longer input.[23] Unlike Codestral, it was\\nreleased under the Apache 2.0 license. While previous\\nreleases often included both the base model and the\\ninstruct version, only the instruct version of Codestral\\nMamba was released.[24][21]\\nMathstral\\n7B July 2024 7 Apache 2.0\\nMathstral 7B is a model with 7 billion parameters\\nreleased by Mistral AI on July 16, 2024, focusing on\\nSTEM subjects.[25] The model was produced in\\ncollaboration with Project Numina,[23] and was\\nreleased under the Apache 2.0 License with a context\\nlength of 32k tokens.[25] [21]\\nModels\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 4/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 4}, page_content='Name Release Date\\nNumber of\\nParameters\\n(Billion)\\nLicense Notes\\nCodestral\\n22B May 2024 22\\nMistral\\nNon-\\nProduction\\nLicense\\nCodestral is Mistral\\'s first code-focused open weight\\nmodel which was launched on May 29, 2024. Mistral\\nclaims Codestral is fluent in more than 80\\nprogramming languages[26] Codestral has its own\\nlicense which forbids the usage of Codestral for\\ncommercial purposes.[27][21]\\nMistral\\n8x22B April 2024 22 Apache 2.0\\nSimilar to Mistral\\'s previous open models, Mixtral\\n8x22B was released via a BitTorrent link on Twitter on\\nApril 10, 2024,[28] with a release on Hugging Face soon\\nafter.[29] The model uses an architecture similar to\\nthat of Mistral 8x7B, but with each expert having 22\\nbillion parameters instead of 7. In total, the model\\ncontains 141 billion parameters, as some parameters\\nare shared among the experts, but offering higher\\nperformance.[29][30] [21]\\nMistral\\nSmall February 2024 Unknown Proprietary Like the Large model, Mistral Small was launched on\\nFebruary 26, 2024.[21]\\nMistral\\nLarge\\n24.02\\nFebruary 2024 Unknown Proprietary\\nMistral Large was launched on February 26, 2024, and\\nMistral claims it is second in the world only to\\nOpenAI\\'s GPT-4. It is fluent in English, French, Spanish,\\nGerman, and Italian, with Mistral claiming\\nunderstanding of both grammar and cultural context,\\nand provides coding capabilities. As of early 2024, it is\\nMistral\\'s flagship AI.[31] It is also available on Microsoft\\nAzure.[32][21]\\nMistral\\nMedium December 2023 Unknown Proprietary\\nMistral Medium is trained in various languages\\nincluding English, French, Italian, German, Spanish and\\ncode with a score of 8.6 on MT-Bench.[33] It is ranked\\nin performance above Claude and below GPT-4 on the\\nLMSys ELO Arena benchmark.[34] The number of\\nparameters, and architecture of Mistral Medium is not\\nknown as Mistral has not published public information\\nabout it.[21]\\nMistral\\n8x7B December 2023 46.7 Apache 2.0\\nMuch like Mistral\\'s first model, Mixtral 8x7B was\\nreleased via a BitTorrent link posted on Twitter on\\nDecember 9, 2023,[2] and later Hugging Face and a\\nblog post were released two days later.[35] Unlike the\\nprevious Mistral model, Mixtral 8x7B uses a sparse\\nmixture of experts architecture. The model has 8\\ndistinct groups of \"experts\", giving the model a total of\\n46.7B usable parameters.[36][37] Each single token can\\nonly use 12.9B parameters, therefore giving the speed\\nand cost that a 12.9B parameter model would incur.[35]\\nA version trained to follow instructions called “Mixtral\\n8x7B Instruct” is also offered.[35][21]\\nMistral 7B September 2023 7.3 Apache 2.0 Mistral 7B is a 7.3B parameter language model using\\nthe transformers architecture. It was officially released\\non September 27, 2023, via a BitTorrent magnet\\nlink,[38] and Hugging Face[39] under the Apache 2.0\\nlicense. Mistral 7B employs grouped-query attention\\n(GQA), which is a variant of the standard attention\\nmechanism. This architecture optimizes performance\\nby calculating attention within specific groups of\\nhidden states rather than across all hidden states,\\nimproving efficiency and scalability.[40] Both a base\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 5/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 5}, page_content='Name Release Date\\nNumber of\\nParameters\\n(Billion)\\nLicense Notes\\nmodel and \"instruct\" model were released with the\\nlatter receiving additional tuning to follow chat-style\\nprompts. The fine-tuned model is only intended for\\ndemonstration purposes, and does not have guardrails\\nor moderation built-in.[41][21]\\nMistral AI claimed in the Mistral 7B release blog post that the model outperforms LLaMA 2 13B on\\nall benchmarks tested, and is on par with LLaMA 34B on many benchmarks tested,[41] despite\\nhaving only 7 billion parameters, a small size compared to its competitors.\\nMistral AI\\'s testing in 2023 shows the model beats both LLaMA 70B, and GPT-3.5 in most\\nbenchmarks.[42]\\nIn March 2024, a research conducted by Patronus AI comparing performance of LLMs on a 100-\\nquestion test with prompts to generate text from books protected under U.S. copyright law found\\nthat Open AI\\'s GPT-4, Mixtral, Meta AI\\'s LLaMA-2, and Anthropic\\'s Claude 2 generated\\ncopyrighted text verbatim in 44%, 22%, 10%, and 8% of responses respectively.[43][44]\\nAccording to Mistral AI, Large 2\\'s performance in benchmarks is competitive with Llama 3.1 405B,\\nparticularly in programming-related tasks.[45][46]\\nAs of its release date, Codestral 22B surpasses Meta\\'s Llama3 70B and DeepSeek Coder 33B\\n(78.2% - 91.6%), another code-focused model on the HumanEval FIM benchmark.[47]\\nMathstral 7B achieved a score of 56.6% on the MATH benchmark and 63.47% on the MMLU\\nbenchmark.[25]\\nAccording to Mistral AI,[48] the company\\'s products have been used by\\xa0:\\nPerformance\\nMistral 7B\\nMixtral 8x7B\\nMistral Large 2\\nCodestral 22B\\nMathstral 7B\\nUsage\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 6/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 6}, page_content='1. BNP Paribas\\n2. AXA\\n3. Laboratoires Pierre Fabre\\n4. CMA CGM\\n5. Zalando\\n6. Mirakl\\n7. France Travail\\n1. Bradshaw, Tim; Abboud, Leila (30 January 2025). \"Has Europe\\'s great hope for AI missed its\\nmoment?\" (https://www.ft.com/content/fa8bad75-dc55-47d9-9eb4-79ac94e54d82). Financial\\nTimes.\\n2. \"Buzzy Startup Just Dumps AI Model That Beats GPT-3.5 Into a Torrent Link\" (https://gizmodo.com/\\nmistral-artificial-intelligence-gpt-3-openai-1851091217). Gizmodo. 12 December 2023. Retrieved\\n16 December 2023.\\n3. \"What is Mistral AI?\" (https://www.ibm.com/think/topics/mistral-ai). IBM. October 2024.\\n4. Journal, Sam Schechner | Photographs by Edouard Jacquinet for The Wall Street. \"The 9-Month-Old\\nAI Startup Challenging Silicon Valley\\'s Giants\" (https://www.wsj.com/tech/ai/the-9-month-old-ai-sta\\nrtup-challenging-silicon-valleys-giants-ee2e4c48). WSJ. Retrieved 31 March 2024.\\n5. \"Spotlight Interview: Mistral AI CEO Arthur Mensch\" (https://frenchtechjournal.com/spotlight-intervi\\new-mistral-ai-arthur-mensch/). The French Tech Journal. 24 June 2024.\\n6. \"France\\'s unicorn start-up Mistral AI embodies its artificial intelligence hopes\" (https://www.lemond\\ne.fr/en/economy/article/2023/12/12/french-unicorn-start-up-mistral-ai-embodies-its-artificial-intelli\\ngence-hopes_6337125_19.html). Le Monde.fr. 12 December 2023.\\n7. \"Bringing open AI models to the frontier\" (https://mistral.ai/news/about-mistral-ai/). Mistral AI. 27\\nSeptember 2023. Retrieved 4 January 2024.\\n8. Webb, Maria (2 January 2024). \"Mistral AI: Exploring Europe\\'s Latest Tech Unicorn\" (https://www.te\\nchopedia.com/mistral-ai-exploring-europes-latest-tech-unicorn). techopedia.com. Retrieved\\n13 June 2024.\\n9. \"Mistral l è ve 385 M €  et devient une licorne fran ç aise - le Monde Informatique\" (https://www.lemon\\ndeinformatique.fr/actualites/lire-mistral-leve-385-meteuro-et-devient-une-licorne-francaise-9239\\n2.html). 11 December 2023.\\n10. Metz, Cade (10 December 2023). \"Mistral, French A.I. Start-Up, Is Valued at $2 Billion in Funding\\nRound\" (https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html). The New York\\nTimes.\\n11. Fink, Charlie. \"This Week In XR: Epic Triumphs Over Google, Mistral AI Raises $415 Million, $56.5\\nMillion For Essential AI\" (https://www.forbes.com/sites/charliefink/2023/12/14/this-week-in-xr-epic-\\ntriumphs-over-google-mistral-ai-raises-415-million-565-million-for-essential-ai/). Forbes. Retrieved\\n16 December 2023.\\n12. \"A French AI start-up may have commenced an AI revolution, silently\" (https://www.hindustantimes.\\ncom/business/a-french-ai-start-up-may-have-commenced-an-ai-revolution-silently-101702370816\\n617.html). Hindustan Times. 12 December 2023.\\n13. Abboud, Leila; Levingston, Ivan; Hammond, George (8 December 2023). \"French AI start-up Mistral\\nsecures € 2bn valuation\" (https://www.ft.com/content/ea29ddf8-91cb-45e8-86a0-f501ab7ad9bb).\\nFinancial Times. ft.com Financial Times.\\n14. Abboud, Leila; Levingston, Ivan; Hammond, George (19 April 2024). \"Mistral in talks to raise\\n€ 500mn at € 5bn valuation\" (https://www.ft.com/content/358fc1d8-8276-4e81-9ee6-e0391575d56\\n9). Financial Times. Retrieved 19 April 2024.\\nReferences\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 7/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 7}, page_content='15. Kharpal, Arjun (24 May 2024). \"CEOs of AI startups backed by Microsoft and Amazon are the new\\ntech rockstars\" (https://www.cnbc.com/2024/05/24/mistral-ai-anthropic-ceos-are-the-new-tech-ro\\nckstars-in-ai-boom.html). CNBC. Retrieved 13 June 2024.\\n16. \"Tripling Down on Mistral AI | General Catalyst\" (https://www.generalcatalyst.com/perspectives/tripli\\nng-down-on-mistral-ai). www.generalcatalyst.com. Retrieved 13 June 2024.\\n17. Bratton, Laura (12 June 2024). \"OpenAI\\'s French rival Mistral AI is now worth $6 billion. That\\'s still a\\nfraction of its top competitors\" (https://qz.com/openai-mistral-ai-funding-valuation-microsoft-18515\\n35049). Quartz (publication). Retrieved 13 June 2024.\\n18. Bableshwar (26 February 2024). \"Mistral Large, Mistral AI\\'s flagship LLM, debuts on Azure AI\\nModels-as-a-Service\" (https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mistral-la\\nrge-mistral-ai-s-flagship-llm-debuts-on-azure-ai/ba-p/4066996). techcommunity.microsoft.com.\\nRetrieved 26 February 2024.\\n19. \"Mistral releases its genAI assistant Le Chat for IOS and Android\" (https://www.computerworld.com/\\narticle/3819932/mistral-releases-its-ai-assistant-le-chat-for-ios-and-android.html). Computerworld.\\n7 February 2025. Retrieved 7 February 2025.\\n20. https://ollama.com/library/mistral-small:24b\\n21. https://docs.mistral.ai/getting-started/models/models_overview/}}\\n22. \"Mistral has entered the chat\" (https://mistral.ai/news/mistral-chat/). Mistral AI. 18 November 2024.\\nRetrieved 11 December 2024.\\n23. David, Emilia (16 July 2024). \"Mistral releases Codestral Mamba for faster, longer code generation\"\\n(https://venturebeat.com/ai/mistral-releases-codestral-mamba-for-faster-longer-code-generation/).\\nVentureBeat. Retrieved 17 July 2024.\\n24. AI, Mistral (16 July 2024). \"Codestral Mamba\" (https://mistral.ai/news/codestral-mamba/). mistral.ai.\\nRetrieved 16 July 2024.\\n25. AI, Mistral (16 July 2024). \"MathΣtral\" (https://mistral.ai/news/mathstral/). mistral.ai. Retrieved\\n16 July 2024.\\n26. Sharma, Shubham (29 May 2024). \"Mistral announces Codestral, its first programming focused AI\\nmodel\" (https://venturebeat.com/ai/mistral-announces-codestral-its-first-programming-focused-ai-\\nmodel/). VentureBeat. Retrieved 30 May 2024.\\n27. Wiggers, Kyle (29 May 2024). \"Mistral releases Codestral, its first generative AI model for code\" (htt\\nps://techcrunch.com/2024/05/29/mistral-releases-its-first-generative-ai-model-for-code/).\\nTechCrunch. Retrieved 30 May 2024.\\n28. @MistralAI (10 April 2024). \"Torrent\" (https://x.com/MistralAI/status/1777869263778291896)\\n(Tweet) \\xad via Twitter.\\n29. \"mistralai/Mixtral-8x22B-v0.1 · Hugging Face\" (https://huggingface.co/mistralai/Mixtral-8x22B-v0.1).\\nhuggingface.co. Retrieved 5 May 2024.\\n30. \"Mistral Releases Latest Open Source Model, Mixtral 8x22B\" (https://pureai.com/Articles/2024/04/1\\n7/Mistral-Mixtral-8x22B.aspx). Pure AI. 17 April 2024.\\n31. AI, Mistral (26 February 2024). \"Au Large\" (https://mistral.ai/news/mistral-large/). mistral.ai.\\nRetrieved 6 March 2024.\\n32. Boyd, Eric (26 February 2024). \"Introducing Mistral-Large on Azure in partnership with Mistral AI\" (h\\nttps://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-acc\\nelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/). Microsoft Azure Blog. Retrieved\\n17 February 2025.\\n33. AI, Mistral (11 December 2023). \"La plateforme\" (https://mistral.ai/news/la-plateforme/). mistral.ai.\\nRetrieved 22 January 2024.\\n34. \"LMSys Chatbot Arena Leaderboard - a Hugging Face Space by lmsys\" (https://huggingface.co/space\\ns/lmsys/chatbot-arena-leaderboard). huggingface.co. Retrieved 22 January 2024.\\n35. \"Mixtral of experts\" (https://mistral.ai/news/mixtral-of-experts/). mistral.ai. 11 December 2023.\\nRetrieved 4 January 2024.\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 8/9'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf', 'page': 8}, page_content='36. \"Mixture of Experts Explained\" (https://huggingface.co/blog/moe). huggingface.co. Retrieved\\n4 January 2024.\\n37. Marie, Benjamin (15 December 2023). \"Mixtral-8x7B: Understanding and Running the Sparse\\nMixture of Experts\" (https://towardsdatascience.com/mixtral-8x7b-understanding-and-running-the\\n-sparse-mixture-of-experts-0e3fc7fde818). Medium. Retrieved 4 January 2024.\\n38. Goldman, Sharon (8 December 2023). \"Mistral AI bucks release trend by dropping torrent link to\\nnew open source LLM\" (https://venturebeat.com/ai/mistral-ai-bucks-release-trend-by-dropping-tor\\nrent-link-to-new-open-source-llm/). VentureBeat. Retrieved 4 January 2024.\\n39. Coldewey, Devin (27 September 2023). \"Mistral AI makes its first large language model free for\\neveryone\" (https://techcrunch.com/2023/09/27/mistral-ai-makes-its-first-large-language-model-fre\\ne-for-everyone/). TechCrunch. Retrieved 4 January 2024.\\n40. Jiang, Albert Q.; Sablayrolles, Alexandre; Mensch, Arthur; Bamford, Chris; Chaplot, Devendra Singh;\\nCasas, Diego de las; Bressand, Florian; Lengyel, Gianna; Lample, Guillaume (10 October 2023).\\n\"Mistral 7B\". arXiv:2310.06825v1 (https://arxiv.org/abs/2310.06825v1) [cs.CL (https://arxiv.org/archiv\\ne/cs.CL)].\\n41. \"Mistral 7B\" (https://mistral.ai/news/announcing-mistral-7b/). mistral.ai. Mistral AI. 27 September\\n2023. Retrieved 4 January 2024.\\n42. Franzen, Carl (11 December 2023). \"Mistral shocks AI community as latest open source model\\neclipses GPT-3.5 performance\" (https://venturebeat.com/ai/mistral-shocks-ai-community-as-latest-\\nopen-source-model-eclipses-gpt-3-5-performance/). VentureBeat. Retrieved 4 January 2024.\\n43. Field, Hayden (6 March 2024). \"Researchers tested leading AI models for copyright infringement\\nusing popular books, and GPT-4 performed worst\" (https://www.cnbc.com/2024/03/06/gpt-4-resea\\nrchers-tested-leading-ai-models-for-copyright-infringement.html). CNBC. Retrieved 6 March 2024.\\n44. \"Introducing CopyrightCatcher, the first Copyright Detection API for LLMs\" (https://www.patronus.a\\ni/blog/introducing-copyright-catcher). Patronus AI. 6 March 2024. Retrieved 6 March 2024.\\n45. AI, Mistral (24 July 2024). \"Large Enough\" (https://mistral.ai/news/mistral-large-2407/). mistral.ai.\\nRetrieved 24 July 2024.\\n46. \"mistralai/Mistral-Large-Instruct-2407 · Hugging Face\" (https://huggingface.co/mistralai/Mistral-Larg\\ne-Instruct-2407). huggingface.co. Retrieved 24 August 2024.\\n47. AI, Mistral (29 May 2024). \"Codestral: Hello, World!\" (https://mistral.ai/news/codestral/). mistral.ai.\\nRetrieved 30 May 2024.\\n48. \"Solutions - for any use case | Mistral AI\" (https://mistral.ai/en/solutions). mistral.ai. Retrieved\\n17 February 2025.\\nOfficial website (https://mistral.ai/) \\nOfficial Fan Twitter (https://x.com/LeChatonSol)\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Mistral_AI&oldid=1277140258\"\\nExternal links\\n25. 3. 1. 오후  11:31 Mistral AI - Wikipedia\\nhttps://en.wikipedia.org/wiki/Mistral_AI 9/9')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../dataset/llamaindex_data\", glob=\"*\", show_progress=True)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "  separator=\"\\n\",\n",
    "  chunk_size=500,\n",
    "  chunk_overlap=20,\n",
    "  length_function=len,\n",
    "  is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1528, which is longer than the specified 500\n",
      "Created a chunk of size 3451, which is longer than the specified 500\n",
      "Created a chunk of size 2224, which is longer than the specified 500\n",
      "Created a chunk of size 705, which is longer than the specified 500\n",
      "Created a chunk of size 3773, which is longer than the specified 500\n",
      "Created a chunk of size 7769, which is longer than the specified 500\n",
      "Created a chunk of size 1935, which is longer than the specified 500\n",
      "Created a chunk of size 602, which is longer than the specified 500\n",
      "Created a chunk of size 675, which is longer than the specified 500\n",
      "Created a chunk of size 1719, which is longer than the specified 500\n",
      "Created a chunk of size 2704, which is longer than the specified 500\n",
      "Created a chunk of size 809, which is longer than the specified 500\n",
      "Created a chunk of size 755, which is longer than the specified 500\n",
      "Created a chunk of size 1820, which is longer than the specified 500\n",
      "Created a chunk of size 1183, which is longer than the specified 500\n",
      "Created a chunk of size 1659, which is longer than the specified 500\n",
      "Created a chunk of size 1347, which is longer than the specified 500\n",
      "Created a chunk of size 647, which is longer than the specified 500\n",
      "Created a chunk of size 844, which is longer than the specified 500\n",
      "Created a chunk of size 773, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 1770, which is longer than the specified 500\n",
      "Created a chunk of size 747, which is longer than the specified 500\n",
      "Created a chunk of size 2108, which is longer than the specified 500\n",
      "Created a chunk of size 1116, which is longer than the specified 500\n",
      "Created a chunk of size 2132, which is longer than the specified 500\n",
      "Created a chunk of size 1071, which is longer than the specified 500\n",
      "Created a chunk of size 957, which is longer than the specified 500\n",
      "Created a chunk of size 639, which is longer than the specified 500\n",
      "Created a chunk of size 701, which is longer than the specified 500\n",
      "Created a chunk of size 1972, which is longer than the specified 500\n",
      "Created a chunk of size 863, which is longer than the specified 500\n",
      "Created a chunk of size 1076, which is longer than the specified 500\n",
      "Created a chunk of size 1043, which is longer than the specified 500\n",
      "Created a chunk of size 1930, which is longer than the specified 500\n",
      "Created a chunk of size 625, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI. The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI\\'s equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  separators=[\"\\n\\n\", \"\\n\", \" \"],\n",
    "  chunk_size=500,\n",
    "  chunk_overlap=20,\n",
    "  length_function=len,\n",
    "  is_separator_regex=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import  SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI. The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI\\'s equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem. == History ==\\n\\n=== 2015–2018: Non\\n\\nprofit beginnings ===\\n\\nIn December 2015, OpenAI was founded by Sam Altman, Elon Musk, Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk as the co-chairs. A total of $1 billion in capital was pledged by Sam Altman, Greg Brockman, Elon Musk, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "  chunk_size=500,\n",
    "  chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 751, which is longer than the specified 500\n",
      "Created a chunk of size 800, which is longer than the specified 500\n",
      "Created a chunk of size 1578, which is longer than the specified 500\n",
      "Created a chunk of size 558, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI. The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI\\'s equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.\\n\\n== History ==\\n\\n=== 2015–2018: Non\\n\\nprofit beginnings ===')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.010367147624492645, 0.023194052278995514, 0.006391748320311308]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embed_model.embed_query(\"What is Mistral AI?\")\n",
    "emb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embed_model.embed_documents([\"What is Mistral AI?\", \"Hi\", \"ML\"])\n",
    "\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vector_index = Chroma.from_documents(documents, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25. 3. 1. 오후 11:31\\n\\nMistral AI\\n\\nMistral AI SAS is a French artificial intelligence (AI) startup, headquartered in Paris. It specializes in open-weight large language models (LLMs).[2][3]\\n\\nNamesake\\n\\nThe company is named after the mistral, a powerful, cold wind in southern France.[4]\\n\\nHistory\\n\\nMistral AI was established in April 2023 by three French AI researchers, Arthur Mensch, Guillaume Lample and Timothée Lacroix.[5]\\n\\nMensch, an expert in advanced AI systems, is a former employee of Google DeepMind; Lample and Lacroix, meanwhile, are large-scale AI models specialists who had worked for Meta Platforms.[6]\\n\\nThe trio originally met during their studies at École Polytechnique.[4]\\n\\nCompany operation\\n\\nPhilosophy\\n\\nMistral AI emphasizes openness and innovation in the AI field and positions itself as an alternative to proprietary models.[7]\\n\\nThe company has gained prominence as an alternative to proprietary AI systems as it aims to focusing on open-source \"democratize\" AI by innovation.[8]\\n\\nhttps://en.wikipedia.org/wiki/Mistral_AI\\n\\nMistral AI - Wikipedia\\n\\nCompany type\\n\\nIndustry\\n\\nFounded\\n\\nFounders\\n\\nHeadquarters\\n\\nKey people\\n\\nProducts\\n\\nNumber of employees\\n\\nWebsite\\n\\nMistral AI SAS\\n\\nPrivate\\n\\nArtificial intelligence\\n\\n28 April 2023\\n\\nArthur Mensch\\n\\nGuillaume Lample\\n\\nTimothée Lacroix\\n\\nParis, France\\n\\nArthur Mensch (CEO)\\n\\nGuillaume Lample (Chief Scientist)\\n\\nTimothée Lacroix (CTO)\\n\\nMistral 7B\\n\\nMixtral 8x7B\\n\\nMistral Medium\\n\\nMistral Large\\n\\nMistral Large 2 (123B)\\n\\nMixtral 8x22B\\n\\nCodestral 22B\\n\\nCodestral Mamba (7B)\\n\\nMathstral (7B)\\n\\nMistral NeMo 12B\\n\\nMistral Embed\\n\\n150 (2025)[1]\\n\\nmistral.ai (https://mistral.a i/)\\n\\n1/9\\n\\n25. 3. 1. 오후 11:31 Funding\\n\\nMistral AI - Wikipedia'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved = vector_index.similarity_search(\"What is Mistral AI?\")\n",
    "retrieved[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector_index = FAISS.from_documents(documents, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25. 3. 1. 오후 11:31\\n\\nMistral AI\\n\\nMistral AI SAS is a French artificial intelligence (AI) startup, headquartered in Paris. It specializes in open-weight large language models (LLMs).[2][3]\\n\\nNamesake\\n\\nThe company is named after the mistral, a powerful, cold wind in southern France.[4]\\n\\nHistory\\n\\nMistral AI was established in April 2023 by three French AI researchers, Arthur Mensch, Guillaume Lample and Timothée Lacroix.[5]\\n\\nMensch, an expert in advanced AI systems, is a former employee of Google DeepMind; Lample and Lacroix, meanwhile, are large-scale AI models specialists who had worked for Meta Platforms.[6]\\n\\nThe trio originally met during their studies at École Polytechnique.[4]\\n\\nCompany operation\\n\\nPhilosophy\\n\\nMistral AI emphasizes openness and innovation in the AI field and positions itself as an alternative to proprietary models.[7]\\n\\nThe company has gained prominence as an alternative to proprietary AI systems as it aims to focusing on open-source \"democratize\" AI by innovation.[8]\\n\\nhttps://en.wikipedia.org/wiki/Mistral_AI\\n\\nMistral AI - Wikipedia\\n\\nCompany type\\n\\nIndustry\\n\\nFounded\\n\\nFounders\\n\\nHeadquarters\\n\\nKey people\\n\\nProducts\\n\\nNumber of employees\\n\\nWebsite\\n\\nMistral AI SAS\\n\\nPrivate\\n\\nArtificial intelligence\\n\\n28 April 2023\\n\\nArthur Mensch\\n\\nGuillaume Lample\\n\\nTimothée Lacroix\\n\\nParis, France\\n\\nArthur Mensch (CEO)\\n\\nGuillaume Lample (Chief Scientist)\\n\\nTimothée Lacroix (CTO)\\n\\nMistral 7B\\n\\nMixtral 8x7B\\n\\nMistral Medium\\n\\nMistral Large\\n\\nMistral Large 2 (123B)\\n\\nMixtral 8x22B\\n\\nCodestral 22B\\n\\nCodestral Mamba (7B)\\n\\nMathstral (7B)\\n\\nMistral NeMo 12B\\n\\nMistral Embed\\n\\n150 (2025)[1]\\n\\nmistral.ai (https://mistral.a i/)\\n\\n1/9\\n\\n25. 3. 1. 오후 11:31 Funding\\n\\nMistral AI - Wikipedia'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved = vector_index.similarity_search(\"What is Mistral AI?\")\n",
    "retrieved[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"OpenAI의 sora 모델에 대해 알려줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='===== DALL-E 3 ===== In September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text. It was released to the public as a ChatGPT Plus feature in October.\\n\\n=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ====\\n\\nReleased in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\\n\\n=== Music generation ==='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='== Initial motivations == Some scientists, such as Stephen Hawking and Stuart Russell, have articulated concerns that if advanced AI gains the ability to redesign itself at an ever-increasing rate, an unstoppable \"intelligence explosion\" could lead to human extinction. Co-founder Musk characterizes AI as humanity\\'s \"biggest existential threat\". Musk and Altman have stated they are partly motivated by concerns about AI safety and the existential risk from artificial general intelligence. OpenAI states that \"it\\'s hard to fathom how much human-level AI could benefit society,\" and that it is equally difficult to comprehend \"how much it could damage society if built or used incorrectly\". Research on safety cannot safely be postponed: \"because of AI\\'s surprising history, it\\'s hard to predict when human-level AI might come within reach.\" OpenAI states that AI \"should be an extension of individual human wills and, in the spirit of liberty, as broadly and evenly distributed as possible.\" Co-chair Sam Altman expects the decades-long project to surpass human intelligence. Vishal Sikka, former CEO of Infosys, stated that an \"openness\", where the endeavor would \"produce results generally in the greater interest of humanity\", was a fundamental requirement for his support; and that OpenAI \"aligns very nicely with our long-held values\" and their \"endeavor to do purposeful work\". Cade Metz of Wired suggested that corporations such as Amazon might be motivated by a desire to use open-source software and data to level the playing field against corporations such as Google and Facebook, which own enormous supplies of proprietary data. Altman stated that Y Combinator companies would share their data with OpenAI.'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/Mistral AI - Wikipedia.pdf'}, page_content='On November 19, 2024, the company introduced Pixtral Large, an improvement over Pixtral 12B, integrating a 1-billion-parameter visual encoder coupled with Mistral Large 2. This model has also been enhanced, particularly for long contexts and function calls.[22] [21]\\n\\n[21]\\n\\n[21]\\n\\n[21]\\n\\nMistral Large 2 was announced on July 24, 2024, and released on Hugging Face. It is available for free with a Mistral Research Licence, and with a commercial licence for commercial purposes. Mistral AI claims that it is fluent in dozens of languages, including many programming languages. Unlike the previous Mistral Large, this version was released with open weights. The model has 123 billion parameters and a context length of 128,000 tokens. [21]\\n\\nCodestral Mamba is based on the Mamba 2 architecture, which allows it to generate responses even with longer input.[23] Unlike Codestral, it was released under the Apache 2.0 license. While previous releases often included both the base model and the instruct version, only the instruct version of Codestral Mamba was released.[24][21]\\n\\nMathstral 7B is a model with 7 billion parameters released by Mistral AI on July 16, 2024, focusing on STEM subjects.[25] The model was produced in collaboration with Project Numina,[23] and was released under the Apache 2.0 License with a context length of 32k tokens.[25] [21]\\n\\n4/9\\n\\n25. 3. 1. 오후 11:31\\n\\nName\\n\\nRelease Date\\n\\nCodestral 22B\\n\\nMay 2024\\n\\nMistral 8x22B\\n\\nApril 2024\\n\\nMistral Small\\n\\nFebruary 2024\\n\\nMistral Large 24.02\\n\\nFebruary 2024\\n\\nMistral Medium\\n\\nDecember 2023\\n\\nMistral 8x7B\\n\\nDecember 2023\\n\\nMistral 7B\\n\\nSeptember 2023\\n\\nhttps://en.wikipedia.org/wiki/Mistral_AI\\n\\nNumber of Parameters (Billion)\\n\\n22\\n\\n22\\n\\nUnknown\\n\\nUnknown\\n\\nUnknown\\n\\n46.7\\n\\n7.3\\n\\nMistral AI - Wikipedia\\n\\nLicense\\n\\nNotes\\n\\nMistral Non- Production License'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content=\"OpenAI Five is a team of five OpenAI-curated bots used in the competitive five-on-five video game Dota 2, that learn to play against human players at a high skill level entirely through trial-and-error algorithms. Before becoming a team of five, the first public demonstration occurred at The International 2017, the annual premiere championship tournament for the game, where Dendi, a professional Ukrainian player, lost against a bot in a live one-on-one matchup. After the match, CTO Greg Brockman explained that the bot had learned by playing against itself for two weeks of real time, and that the learning software was a step in the direction of creating software that can handle complex tasks like a surgeon. The system uses a form of reinforcement learning, as the bots learn over time by playing against themselves hundreds of times a day for months, and are rewarded for actions such as killing an enemy and taking map objectives. By June 2018, the ability of the bots expanded to play together as a full team of five, and they were able to defeat teams of amateur and semi-professional players. At The International 2018, OpenAI Five played in two exhibition matches against professional players, but ended up losing both games. In April 2019, OpenAI Five defeated OG, the reigning world champions of the game at the time, 2:0 in a live exhibition match in San Francisco. The bots' final public appearance came later that month, where they played in 42,729 total games in a four-day open online competition, winning 99.4% of those games. OpenAI Five's mechanisms in Dota 2's bot player shows the challenges of AI systems in multiplayer online battle arena (MOBA) games and how OpenAI Five has demonstrated the use of deep reinforcement learning (DRL) agents to achieve superhuman competence in Dota 2 matches.\")]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever(search_type=\"mmr\")\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='===== DALL-E 3 ===== In September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text. It was released to the public as a ChatGPT Plus feature in October.\\n\\n=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ====\\n\\nReleased in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\\n\\n=== Music generation ===')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.2})\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='===== DALL-E 3 ===== In September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text. It was released to the public as a ChatGPT Plus feature in October.\\n\\n=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ====\\n\\nReleased in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\\n\\n=== Music generation ==='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI. The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI\\'s equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.\\n\\n== History ==\\n\\n=== 2015–2018: Non\\n\\nprofit beginnings ==='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='In January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI\\'s first partnership with an educational institution. In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman\\'s statements, opened by the Southern New York U.S. Attorney\\'s Office was ongoing. On February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date. It is available for red teams for managing critical harms and risks. On February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI\\'s original mission of developing AI for humanity\\'s benefit. The lawsuit cited OpenAI\\'s policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate. OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\" It denied being a de facto Microsoft subsidiary. On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk\\'s lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\". In June, Musk unexpectedly withdrew the lawsuit, but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit. On May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki to be the Chief Scientist. Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI\\'s leadership. The departures, along with researchers leaving, led OpenAI to absorb the team\\'s work into other research areas, and shut down the superalignment group. According to sources interviewed by Fortune, OpenAI\\'s promise of allocating 20% of its computing capabilities to the superalignment project had not been fulfilled. On May 19, 2024, Reddit and OpenAI announced a partnership to integrate Reddit\\'s content into OpenAI products, including ChatGPT. This allows OpenAI to access Reddit\\'s Data API, providing real-time, structured content to enhance AI tools and user engagement with Reddit communities. Reddit plans to develop new AI-powered features for users and moderators using OpenAI\\'s platform. The partnership aligns with Reddit\\'s commitment to privacy, adhering to its Public Content Policy and existing Data API Terms, which restrict commercial use without approval. OpenAI will serve as a Reddit advertising partner. On May 22, 2024, OpenAI entered into an agreement with News Corp to integrate news content from The Wall Street Journal, New York Post, The Times, and The Sunday Times into its AI platform. Meanwhile, other publications like The New York Times chose to sue OpenAI and Microsoft for copyright infringement over use of their content to train AI models. On May 29, 2024, Axios reported that OpenAI had signed deals with Vox Media and The Atlantic to share content to enhance the accuracy of AI models like ChatGPT by incorporating reliable news sources, addressing concerns about AI misinformation. Concerns were expressed by journalists and unions. The Vox Union stated, \"As both journalists and workers, we have serious concerns about this partnership, which we believe could adversely impact members of our union, not to mention the well-documented ethical and environmental concerns surrounding the use of generative AI.\" A group of nine current and former OpenAI employees has accused the company of prioritizing profits over safety, using restrictive agreements to silence concerns, and moving too quickly with inadequate risk management. They call for greater transparency, whistleblower protections, and legislative regulation of AI development. On June 10, 2024, it was announced that OpenAI had partnered with Apple Inc. to bring ChatGPT features to Apple Intelligence and iPhone. On June 13, 2024, OpenAI announced that Paul Nakasone, the former head of the NSA was joining its board. Nakasone also joined the security subcommittee. On June 24, 2024, OpenAI acquired Multi, a startup running a collaboration platform based on Zoom. In July 2024, Reuters reported that OpenAI is working on a project to enhance AI reasoning capabilities, and to enable AI to plan ahead, navigate the internet autonomously, and conduct \"deep research\". The project was released on September 12 and named o1. On August 5, TechCrunch reported that OpenAI\\'s cofounder John Schulman had left to join rival startup Anthropic. Schulman cited a desire to focus more on AI alignment research. OpenAI\\'s president and co-founder, Greg Brockman, took extended leave till November. In September 2024, OpenAI\\'s global affairs chief, Anna Makanju, expressed support for the UK\\'s approach to AI regulation during her testimony to a House of Lords committee, stating the company favors \"smart regulation\" and sees the UK\\'s AI white paper as a positive step towards responsible AI development. Chief Technology Officer (CTO) Mira Murati announced her departure from the company to \"create the time and space to do my own exploration\". It had been reported Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency. Another major release was ChatGPT Pro, a subscription service priced at $200 per month that provides users with unlimited access to the o1 model and enhanced voice features. OpenAI shared preliminary benchmark results for the upcoming o3 model. The event also saw the expansion of the Canvas feature, allowing all users to utilize side-by-side digital editing capabilities.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever_mult = MultiQueryRetriever.from_llm(\n",
    "  retriever=vector_index.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. OpenAI의 sora 모델은 어떤 특징을 가지고 있나요?', '2. sora 모델은 OpenAI에서 어떻게 활용되고 있나요?', '3. OpenAI의 sora 모델이 다른 모델과 어떻게 다른가요?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='===== DALL-E 3 ===== In September 2023, OpenAI announced DALL-E 3, a more powerful model better able to generate images from complex descriptions without manual prompt engineering and render complex details like hands and text. It was released to the public as a ChatGPT Plus feature in October.\\n\\n=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ====\\n\\nReleased in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\\n\\n=== Music generation ==='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='In January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI\\'s first partnership with an educational institution. In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman\\'s statements, opened by the Southern New York U.S. Attorney\\'s Office was ongoing. On February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date. It is available for red teams for managing critical harms and risks. On February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI\\'s original mission of developing AI for humanity\\'s benefit. The lawsuit cited OpenAI\\'s policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate. OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\" It denied being a de facto Microsoft subsidiary. On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk\\'s lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\". In June, Musk unexpectedly withdrew the lawsuit, but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit. On May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki to be the Chief Scientist. Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI\\'s leadership. The departures, along with researchers leaving, led OpenAI to absorb the team\\'s work into other research areas, and shut down the superalignment group. According to sources interviewed by Fortune, OpenAI\\'s promise of allocating 20% of its computing capabilities to the superalignment project had not been fulfilled. On May 19, 2024, Reddit and OpenAI announced a partnership to integrate Reddit\\'s content into OpenAI products, including ChatGPT. This allows OpenAI to access Reddit\\'s Data API, providing real-time, structured content to enhance AI tools and user engagement with Reddit communities. Reddit plans to develop new AI-powered features for users and moderators using OpenAI\\'s platform. The partnership aligns with Reddit\\'s commitment to privacy, adhering to its Public Content Policy and existing Data API Terms, which restrict commercial use without approval. OpenAI will serve as a Reddit advertising partner. On May 22, 2024, OpenAI entered into an agreement with News Corp to integrate news content from The Wall Street Journal, New York Post, The Times, and The Sunday Times into its AI platform. Meanwhile, other publications like The New York Times chose to sue OpenAI and Microsoft for copyright infringement over use of their content to train AI models. On May 29, 2024, Axios reported that OpenAI had signed deals with Vox Media and The Atlantic to share content to enhance the accuracy of AI models like ChatGPT by incorporating reliable news sources, addressing concerns about AI misinformation. Concerns were expressed by journalists and unions. The Vox Union stated, \"As both journalists and workers, we have serious concerns about this partnership, which we believe could adversely impact members of our union, not to mention the well-documented ethical and environmental concerns surrounding the use of generative AI.\" A group of nine current and former OpenAI employees has accused the company of prioritizing profits over safety, using restrictive agreements to silence concerns, and moving too quickly with inadequate risk management. They call for greater transparency, whistleblower protections, and legislative regulation of AI development. On June 10, 2024, it was announced that OpenAI had partnered with Apple Inc. to bring ChatGPT features to Apple Intelligence and iPhone. On June 13, 2024, OpenAI announced that Paul Nakasone, the former head of the NSA was joining its board. Nakasone also joined the security subcommittee. On June 24, 2024, OpenAI acquired Multi, a startup running a collaboration platform based on Zoom. In July 2024, Reuters reported that OpenAI is working on a project to enhance AI reasoning capabilities, and to enable AI to plan ahead, navigate the internet autonomously, and conduct \"deep research\". The project was released on September 12 and named o1. On August 5, TechCrunch reported that OpenAI\\'s cofounder John Schulman had left to join rival startup Anthropic. Schulman cited a desire to focus more on AI alignment research. OpenAI\\'s president and co-founder, Greg Brockman, took extended leave till November. In September 2024, OpenAI\\'s global affairs chief, Anna Makanju, expressed support for the UK\\'s approach to AI regulation during her testimony to a House of Lords committee, stating the company favors \"smart regulation\" and sees the UK\\'s AI white paper as a positive step towards responsible AI development. Chief Technology Officer (CTO) Mira Murati announced her departure from the company to \"create the time and space to do my own exploration\". It had been reported Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency. Another major release was ChatGPT Pro, a subscription service priced at $200 per month that provides users with unlimited access to the o1 model and enhanced voice features. OpenAI shared preliminary benchmark results for the upcoming o3 model. The event also saw the expansion of the Canvas feature, allowing all users to utilize side-by-side digital editing capabilities.'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='OpenAI, Inc. is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora. Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI. The organization consists of the non-profit OpenAI, Inc., registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC. Its stated mission is to ensure that AGI \"benefits all of humanity\". Microsoft owns roughly 49% of OpenAI\\'s equity, having invested US$13 billion. It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI\\'s products. In November 2023, OpenAI\\'s board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company\\'s prominent role in an industry-wide problem.\\n\\n== History ==\\n\\n=== 2015–2018: Non\\n\\nprofit beginnings ==='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='=== Stance on China === In February 2025, OpenAI CEO Sam Altman stated that the company is interested in collaborating with China, despite regulatory restrictions imposed by the U.S. government. This shift comes in response to the growing influence of the Chinese artificial intelligence company DeepSeek, which has disrupted the AI market with advanced models, including DeepSeek V3 and DeepSeek R1, known for their efficiency and cost-effectiveness. The emergence of DeepSeek has led major Chinese tech firms such as Baidu and others to embrace an open-source strategy, intensifying competition with OpenAI. Altman acknowledged the uncertainty regarding U.S. government approval for AI cooperation with China but emphasized the importance of fostering dialogue between technological leaders in both nations.\\n\\n== Products and applications ==\\n\\n=== Reinforcement learning === At its beginning, OpenAI\\'s research included many projects focused on reinforcement learning (RL). OpenAI has been viewed as an important competitor to DeepMind.\\n\\n==== Gym ==== Announced in 2016, Gym is an open-source Python library designed to facilitate the development of reinforcement learning algorithms. It aimed to standardize how environments are defined in AI research, making published research more easily reproducible while providing users with a simple interface for interacting with these environments. In 2022, new developments of Gym have been moved to the library Gymnasium.\\n\\n===== Gym Retro ===== Released in 2018, Gym Retro is a platform for reinforcement learning (RL) research on video games using RL algorithms and study generalization. Prior RL research focused mainly on optimizing agents to solve single tasks. Gym Retro gives the ability to generalize between games with similar concepts but different appearances.\\n\\n==== RoboSumo ==== Released in 2017, RoboSumo is a virtual world where humanoid metalearning robot agents initially lack knowledge of how to even walk, but are given the goals of learning to move and to push the opposing agent out of the ring. Through this adversarial learning process, the agents learn how to adapt to changing conditions. When an agent is then removed from this virtual environment and placed in a new virtual environment with high winds, the agent braces to remain upright, suggesting it had learned how to balance in a generalized way. OpenAI\\'s Igor Mordatch argued that competition between agents could create an intelligence \"arms race\" that could increase an agent\\'s ability to function even outside the context of the competition.\\n\\n==== OpenAI Five ===='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='On December 20, 2024, OpenAI unveiled o3, the successor of the o1 reasoning model. OpenAI also unveiled o3-mini, a lighter and faster version of OpenAI o3. As of December 21, 2024, this model is not available for public use. According to OpenAI, they are testing o3 and o3-mini. Until January 10, 2025, safety and security researchers had the opportunity to apply for early access to these models. The model is called o3 rather than o2 to avoid confusion with telecommunications services provider O2.\\n\\n==== Deep research ====\\n\\nDeep research is an agent developed by OpenAI, unveiled on February 2, 2025. It leverages the capabilities of OpenAI\\'s o3 model to perform extensive web browsing, data analysis, and synthesis, delivering comprehensive reports within a timeframe of 5 to 30 minutes. With browsing and Python tools enabled, it reached an accuracy of 26.6 percent on HLE (Humanity\\'s Last Exam) benchmark.\\n\\n=== Image classification ===\\n\\n==== CLIP ==== Revealed in 2021, CLIP (Contrastive Language–Image Pre-training) is a model that is trained to analyze the semantic similarity between text and images. It can notably be used for image classification.\\n\\n=== Text\\n\\nto\\n\\nimage ===\\n\\n==== DALL\\n\\nE ====\\n\\nRevealed in 2021, DALL-E is a Transformer model that creates images from textual descriptions. DALL-E uses a 12-billion-parameter version of GPT-3 to interpret natural language inputs (such as \"a green leather purse shaped like a pentagon\" or \"an isometric view of a sad capybara\") and generate corresponding images. It can create images of realistic objects (\"a stained-glass window with an image of a blue strawberry\") as well as objects that do not exist in reality (\"a cube with the texture of a porcupine\"). As of March 2021, no API or code is available.\\n\\n===== DALL-E 2 ===== In April 2022, OpenAI announced DALL-E 2, an updated version of the model with more realistic results. In December 2022, OpenAI published on GitHub software for Point-E, a new rudimentary system for converting a text description into a 3-dimensional model.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_mult.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/st3vh8xs6715dcgqc1gk2hhh0000gn/T/ipykernel_16013/4227533863.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_index = Chroma(collection_name=\"split_parents\", embedding_function=embed_model)\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "vector_index = Chroma(collection_name=\"split_parents\", embedding_function=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ParentDocumentRetriever(\n",
    "  vectorstore = vector_index,\n",
    "  docstore = store,\n",
    "  child_splitter = child_splitter,\n",
    "  parent_splitter = parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ===='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency.'),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='In January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI\\'s first partnership with an educational institution. In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman\\'s statements, opened by the Southern New York U.S. Attorney\\'s Office was ongoing. On February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date. It is available for red teams for managing critical harms and risks. On February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI\\'s original mission of developing AI for humanity\\'s benefit. The lawsuit cited OpenAI\\'s policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate. OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\" It denied being a de facto Microsoft subsidiary. On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk\\'s lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\". In June, Musk unexpectedly withdrew the lawsuit, but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit. On May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki to be the Chief Scientist. Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI\\'s leadership. The departures, along with researchers leaving, led OpenAI to absorb the team\\'s work into other research areas, and shut down the superalignment group.')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generatror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='OpenAI의 sora 모델은 자연어 처리 모델 중 하나로, 텍스트 생성 및 이해를 위해 설계된 모델입니다. 이 모델은 GPT-3 모델을 기반으로 하며, 다양한 자연어 처리 작업을 수행할 수 있습니다. sora 모델은 대화형 AI, 텍스트 생성, 요약, 번역, 질문 응답 등 다양한 작업에 사용될 수 있습니다. 이 모델은 다양한 언어 및 주제에 대해 학습되어 있어 다양한 분야에서 활용될 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 24, 'total_tokens': 200, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2e3ac7ca-d1ed-40e0-b5f4-9dfb445028e5-0', usage_metadata={'input_tokens': 24, 'output_tokens': 176, 'total_tokens': 200, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me something\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. Honey's low water content and acidic pH create an inhospitable environment for bacteria and microorganisms, allowing it to last indefinitely.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 10, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-20edc8c6-81e7-4844-8202-54dc5516584f-0', usage_metadata={'input_tokens': 10, 'output_tokens': 62, 'total_tokens': 72, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Did you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible. Honey's low water content and acidic pH create an inhospitable environment for bacteria and microorganisms, allowing it to remain preserved indefinitely.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me something about {topic}\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a large-scale language model developed by OpenAI that is designed to generate human-like text based on the input it receives. It is trained on a diverse range of internet text data to improve its ability to understand and generate natural language. Sora is capable of generating coherent and contextually relevant responses to a wide variety of prompts, making it a powerful tool for tasks such as text generation, language translation, and content creation.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'topic': 'sora, developed by OpenAI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_formatted = prompt.invoke({'topic': 'sora, developed by OpenAI'})\n",
    "property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sora is a large-scale language model developed by OpenAI that is designed to generate human-like text based on the input it receives. It is trained on a diverse range of internet text data to improve its ability to understand and generate natural language. Sora is capable of generating coherent and contextually relevant responses to a wide variety of prompts, making it a powerful tool for tasks such as text generation, language translation, and content creation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 18, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e6cd8996-2602-4ef2-bf8c-3f8922112407-0', usage_metadata={'input_tokens': 18, 'output_tokens': 88, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = llm.invoke(prompt_formatted)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a large-scale language model developed by OpenAI that is designed to generate human-like text based on the input it receives. It is trained on a diverse range of internet text data to improve its ability to understand and generate natural language. Sora is capable of generating coherent and contextually relevant responses to a wide variety of prompts, making it a powerful tool for tasks such as text generation, language translation, and content creation.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = StrOutputParser()\n",
    "parser.invoke(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a large-scale language model developed by OpenAI that is designed to generate human-like text based on the input it receives. It is trained on a diverse range of internet text data to improve its ability to understand and generate natural language. Sora is capable of generating coherent and contextually relevant responses to a wide variety of prompts, making it a powerful tool for tasks such as text generation, language translation, and content creation.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prompt|llm|parser).invoke({'topic': 'sora, developed by OpenAI'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ===='),\n",
       " Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"Tell me sonething about sora, developed by OpenAI\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_docs(retrieved_docs):\n",
    "  return \"\\n\\n\".join([d.page_content for d in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Whisper model expressed concerns about Altman to the Board in October 2024. OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank. OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple did not participate in this funding round. The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in a contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the domain Chat.com and redirected it to ChatGPT\\'s main site. Greg Brockman rejoined OpenAI after a three-month leave from his role as president. He would collaborate with Altman on tackling key technical challenges. OpenAI launched several significant features in December 2024, including the Sora text-to-video model and the o1 model designed for advanced reasoning and improved accuracy.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(retriever|merge_docs|llm|parser).invoke(\"Tell me sonething about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: ParentDocumentRetriever(vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x35d6971d0>, docstore=<langchain_core.stores.InMemoryStore object at 0x35d6ad1d0>, search_kwargs={}, child_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x35e009950>, parent_splitter=<langchain_text_splitters.character.RecursiveCharacterTextSplitter object at 0x35d2a9890>),\n",
       "  llm: ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x34915af90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x357442250>, root_client=<openai.OpenAI object at 0x356e61f10>, root_async_client=<openai.AsyncOpenAI object at 0x356c22c90>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain_parallel = RunnableParallel({\"context\": retriever, \"llm\": llm})\n",
    "chain_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ===='),\n",
       "  Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency.'),\n",
       "  Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='In January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI\\'s first partnership with an educational institution. In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman\\'s statements, opened by the Southern New York U.S. Attorney\\'s Office was ongoing. On February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date. It is available for red teams for managing critical harms and risks. On February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI\\'s original mission of developing AI for humanity\\'s benefit. The lawsuit cited OpenAI\\'s policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate. OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\" It denied being a de facto Microsoft subsidiary. On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk\\'s lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\". In June, Musk unexpectedly withdrew the lawsuit, but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit. On May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki to be the Chief Scientist. Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI\\'s leadership. The departures, along with researchers leaving, led OpenAI to absorb the team\\'s work into other research areas, and shut down the superalignment group.')],\n",
       " 'llm': AIMessage(content='Sora is a large-scale language model developed by OpenAI that is designed to generate human-like text based on the input it receives. It is trained on a diverse range of internet text data to improve its ability to understand and generate natural language. Sora is capable of generating coherent and contextually relevant responses to a wide variety of prompts, making it a powerful tool for tasks such as text generation, language translation, and content creation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 18, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8a211eb7-5919-466b-87e0-604803905a8b-0', usage_metadata={'input_tokens': 18, 'output_tokens': 88, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_parallel.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain_parallel = RunnableParallel({\"context\": retriever, \"query\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='=== Text\\n\\nto\\n\\nvideo ===\\n\\n==== Sora ====\\n\\nSora is a text-to-video model that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora\\'s development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\". Sora\\'s technology is an adaptation of the technology behind the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model\\'s capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora\\'s typical output. Despite skepticism from some academic leaders following Sora\\'s public demo, notable entertainment-industry figures have shown significant interest in the technology\\'s potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology\\'s ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora\\'s possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.\\n\\n=== Speech\\n\\nto\\n\\ntext ===\\n\\n==== Whisper ===='),\n",
       "  Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='Murati was among those who expressed concerns to the Board about Altman. In October 2024, OpenAI raised $6.6 billion from investors, potentially valuing the company at $157 billion. The funding attracted returning venture capital firms like Thrive Capital and Khosla Ventures, along with major backer Microsoft and new investors Nvidia and SoftBank.  OpenAI\\'s CFO, Sarah Friar, informed employees that a tender offer for share buybacks would follow the funding, although specifics were yet to be determined. Thrive Capital invested around $1.2 billion, with the option for an additional $1 billion if revenue goals were met. Apple, despite initial interest, did not participate in this funding round. Also in October 2024, The Intercept revealed that OpenAI\\'s tools were considered \"essential\" for AFRICOM\\'s mission and included in an \"Exception to Fair Opportunity\" contractual agreement between the Department of Defense and Microsoft. In November 2024, OpenAI acquired the long-standing domain Chat.com and redirected it to ChatGPT\\'s main site. Moreover, Greg Brockman rejoined OpenAI after a three-month leave from his role as president. An OpenAI spokesperson confirmed his return, highlighting that Brockman would collaborate with Altman on tackling key technical challenges. His return followed a wave of high-profile departures, including Mira Murati and Ilya Sutskever, who had since launched their own AI ventures. In December 2024, OpenAI launched several significant features as part of its \"12 Days of OpenAI\" event, which started on December 5. It announced Sora, a text-to-video model intended to create realistic videos from text prompts, and available to ChatGPT Plus and Pro users. Additionally, OpenAI launched the o1 model, which is designed to be capable of advanced reasoning through its chain-of-thought processing, enabling it to engage in explicit reasoning before generating responses. This model is intended to tackle complex tasks with improved accuracy and transparency.'),\n",
       "  Document(metadata={'source': '../dataset/llamaindex_data/openai.txt'}, page_content='In January 2024, OpenAI announced a partnership with Arizona State University that would give it complete access to ChatGPT Enterprise. It was OpenAI\\'s first partnership with an educational institution. In February, the U.S. Securities and Exchange Commission was reportedly investigating OpenAI over whether company communications made by Altman were used to mislead investors; and an investigation of Altman\\'s statements, opened by the Southern New York U.S. Attorney\\'s Office was ongoing. On February 15, 2024, OpenAI announced a text-to-video model named Sora, which it plans to release to the public at an unspecified date. It is available for red teams for managing critical harms and risks. On February 29, 2024, OpenAI and CEO Sam Altman were sued by Elon Musk, who accused them of prioritizing profits over public good, contrary to OpenAI\\'s original mission of developing AI for humanity\\'s benefit. The lawsuit cited OpenAI\\'s policy shift after partnering with Microsoft, questioning its open-source commitment and stirring the AI ethics-vs.-profit debate. OpenAI stated that \"Elon understood the mission did not imply open-sourcing AGI.\" It denied being a de facto Microsoft subsidiary. On March 11, in a court filing, OpenAI said it was \"doing just fine without Elon Musk\" after he left in 2018. They responded to Musk\\'s lawsuit, calling his claims \"incoherent\", \"frivolous\", \"extraordinary\" and \"a fiction\". In June, Musk unexpectedly withdrew the lawsuit, but in August reopened it against Altman and others, alleging Altman claimed OpenAI was going to be founded as a non-profit. On May 15, 2024, Ilya Sutskever resigned and was replaced with Jakub Pachocki to be the Chief Scientist. Jan Leike, the other co-leader of the superalignment team, announced his departure, citing an erosion of safety and trust in OpenAI\\'s leadership. The departures, along with researchers leaving, led OpenAI to absorb the team\\'s work into other research areas, and shut down the superalignment group.')],\n",
       " 'query': 'Tell me something about sora, developed by OpenAI'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_parallel.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Utilizing the context given below, answer the question.\n",
    "\n",
    "[context]\n",
    "{context}\n",
    "\n",
    "question: {query}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"context\": retriever, \"query\": RunnablePassthrough()}) | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a text-to-video model developed by OpenAI that can generate videos based on short descriptive prompts and extend existing videos forwards or backwards in time. It can create videos with resolutions up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. The development team named it after the Japanese word for \"sky\" to signify its \"limitless creative potential\". Sora\\'s technology is based on the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available and copyrighted videos, but did not disclose the exact sources. Sora was demonstrated to the public generating high-definition videos up to one minute long, showcasing its ability to create realistic video from text descriptions. Despite some skepticism, notable entertainment figures like Tyler Perry have shown significant interest in Sora\\'s potential to revolutionize storytelling and content creation.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a text-to-video model developed by OpenAI that can generate videos based on short descriptive prompts and extend existing videos forwards or backwards in time. It can create videos with resolutions up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. The development team named it after the Japanese word for \"sky\" to signify its \"limitless creative potential\". Sora\\'s technology is based on the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available and copyrighted videos, but did not disclose the exact number or sources of the videos. Sora was demonstrated to the public generating high-definition videos up to one minute long, showcasing its capabilities in video generation from text descriptions. Despite some skepticism, notable entertainment-industry figures like Tyler Perry have shown significant interest in Sora\\'s potential to revolutionize storytelling and content creation.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel(context=retriever, query=RunnablePassthrough()) | prompt | llm | StrOutputParser()\n",
    "chain.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a text-to-video model developed by OpenAI that can generate videos based on short descriptive prompts and extend existing videos forwards or backwards in time. It can create videos with resolutions up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. The technology behind Sora is an adaptation of the technology used in the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose. Sora was named after the Japanese word for \"sky\" to signify its \"limitless creative potential\". The model was demonstrated to the public on February 15, 2024, showcasing its ability to generate high-definition videos up to one minute long. Despite some skepticism, notable entertainment-industry figures, like actor/filmmaker Tyler Perry, have shown significant interest in Sora\\'s potential to revolutionize storytelling and content creation.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(anything):\n",
    "  return 'bar'\n",
    "\n",
    "chain = RunnableParallel(context=retriever, query=RunnablePassthrough(), asdf=foo) | prompt | llm | StrOutputParser()\n",
    "chain.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a text-to-video model developed by OpenAI that can generate videos based on short descriptive prompts and extend existing videos forwards or backwards in time. It can create videos with resolutions up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. The development team named it after the Japanese word for \"sky\" to signify its \"limitless creative potential\". Sora\\'s technology is based on the DALL·E 3 text-to-image model. OpenAI trained the system using publicly-available and copyrighted videos, but did not disclose the exact number or sources of the videos. Sora was demonstrated to the public generating high-definition videos up to one minute long, showcasing its capabilities in video generation from text descriptions. Despite some skepticism, notable entertainment-industry figures like Tyler Perry have shown significant interest in Sora\\'s potential to revolutionize storytelling and content creation.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = {\"context\": retriever, \"query\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    "chain.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/.pyenv/versions/3.11.6/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sora is a text-to-video model developed by OpenAI that can generate videos based on short descriptive prompts and extend existing videos. It can create videos with resolutions up to 1920x1080 or 1080x1920 and was named after the Japanese word for \"sky\" to signify its creative potential. OpenAI trained Sora using publicly-available and licensed videos, demonstrating its capabilities in generating high-definition videos up to one minute long.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel(context=retriever, question=RunnablePassthrough()) | prompt | llm | StrOutputParser()\n",
    "chain.invoke(\"Tell me something about sora, developed by OpenAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
