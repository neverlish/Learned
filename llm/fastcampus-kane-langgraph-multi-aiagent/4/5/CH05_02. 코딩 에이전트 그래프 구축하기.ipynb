{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Web 기반 코드 에이전트 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **그래프 State 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"The state of our agent.\"\"\"\n",
    "    question: str\n",
    "    certainty_score: int \n",
    "    search_results: list \n",
    "    web_score: str  \n",
    "    repo_name: str  \n",
    "    generation: str\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **사용자의 질문에 대한 LLM의 답변 신뢰도 점검**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_certainty(state: AgentState) -> AgentState:\n",
    "    \"\"\"Evaluate certainty score for the query.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    class CertaintyScoreResponse(BaseModel):\n",
    "        score: int = Field(description=\"Certainty score from 1 to 100. Higher is better.\")\n",
    "        \n",
    "    certainty_scorer = llm.with_structured_output(CertaintyScoreResponse)\n",
    "\n",
    "    print(\"---CHECKING LLM'S CERTAINTY\")\n",
    "    score_response = certainty_scorer.invoke(question)\n",
    "    \n",
    "    return {\n",
    "        \"certainty_score\": score_response.score\n",
    "    }\n",
    "\n",
    "\n",
    "def route_based_on_certainty(state: AgentState) -> Literal[\"web_search\", \"direct_response\"]:\n",
    "    \"\"\"Route to appropriate node based on certainty score.\"\"\"\n",
    "    score = state[\"certainty_score\"]\n",
    "    \n",
    "    if score != 100:\n",
    "        print(\"---LLM IS NOT CERTAIN SO IT WILL DO WEB SEARCH\")\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        print(\"---LLM IS CERTAIN SO IT WILL GENERATE ANSWER DIRECTLY\")\n",
    "        return \"direct_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECKING LLM'S CERTAINTY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CertaintyScoreResponse(score=85)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Langgraph로 rag를 구축하는 방법\"\n",
    "class CertaintyScoreResponse(BaseModel):\n",
    "    score: int = Field(description=\"Certainty score from 1 to 100. Higher is better.\")\n",
    "    \n",
    "certainty_scorer = llm.with_structured_output(CertaintyScoreResponse)\n",
    "\n",
    "print(\"---CHECKING LLM'S CERTAINTY\")\n",
    "score_response = certainty_scorer.invoke(question)\n",
    "score_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LLM이 스스로 답변할 수 있는 경우의 노드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_response(state:AgentState):\n",
    "    question = state['question']\n",
    "    result = llm.invoke(question)\n",
    "    return {\"generation\": result.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **웹 검색 기반의 답변 가능 여부 판단**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:45:18.739491Z",
     "iopub.status.busy": "2024-10-29T13:45:18.739491Z",
     "iopub.status.idle": "2024-10-29T13:45:18.745728Z",
     "shell.execute_reply": "2024-10-29T13:45:18.745728Z",
     "shell.execute_reply.started": "2024-10-29T13:45:18.739491Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def web_search(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Perform web search and evaluate results\n",
    "    \"\"\"\n",
    "    # Get original question\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    search_tool = TavilySearchResults(max_results=3)\n",
    "    search_results = search_tool.invoke(question)\n",
    "    \n",
    "    class answer_availability(BaseModel):\n",
    "        \"\"\"Binary score for answer availability.\"\"\"\n",
    "        binary_score: str = Field(description=\"\"\"\n",
    "                                  If web search result can solve the user's ask, answer 'yes'. \n",
    "                                  If not, answer 'no'\"\"\")\n",
    "\n",
    "    evaluator = llm.with_structured_output(answer_availability)\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Evaluate if these search results can answer the user's question with a simple yes/no.\"),\n",
    "        (\"user\", \"\"\"\n",
    "        Question: {question}\n",
    "        Search Results: {results}\n",
    "        Can these results answer the question adequately?\n",
    "        \"\"\")\n",
    "    ])\n",
    "    print(\"---CHECK WHETHER WEB SEARCH IS SUFFICIENT FOR USER'S ASK\")\n",
    "    evaluation = evaluator.invoke(\n",
    "        eval_prompt.format(\n",
    "            question=question, results=\"\\n\".join(f\"- {result['content']}\" for result in search_results)\n",
    "        )\n",
    "    )\n",
    "    return {\n",
    "        \"search_results\": search_results,\n",
    "        \"web_score\": evaluation.binary_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **웹 검색으로 해결 가능한지 여부 판단**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:45:50.456522Z",
     "iopub.status.busy": "2024-10-29T13:45:50.455516Z",
     "iopub.status.idle": "2024-10-29T13:45:56.615793Z",
     "shell.execute_reply": "2024-10-29T13:45:56.615793Z",
     "shell.execute_reply.started": "2024-10-29T13:45:50.456522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK WHETHER WEB SEARCH IS SUFFICIENT FOR USER'S ASK\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "question = \"autorag github에서 명시된 설치 방법을 알려줘\"\n",
    "search_tool = TavilySearchResults(max_results=3)\n",
    "search_results = search_tool.invoke(question)\n",
    "\n",
    "class answer_availability(BaseModel):\n",
    "    \"\"\"Binary score for answer availability.\"\"\"\n",
    "    binary_score: str = Field(description=\"\"\"\n",
    "                                If web search result can solve the user's ask, answer 'yes'. \n",
    "                                If user's ask is related with github or search_results are insufficient, answer 'no'\"\"\")\n",
    "\n",
    "evaluator = llm.with_structured_output(answer_availability)\n",
    "eval_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "        Evaluate if these search results can answer the user's question with a simple yes/no. \n",
    "        If user ask github related info, then it is not sufficient with web search so you should answer with no.\"\"\"),\n",
    "    (\"user\", \"\"\"\n",
    "    Question: {question}\n",
    "    Search Results: {results}\n",
    "    Can these results answer the question adequately?\n",
    "    \"\"\")\n",
    "])\n",
    "print(\"---CHECK WHETHER WEB SEARCH IS SUFFICIENT FOR USER'S ASK\")\n",
    "evaluation = evaluator.invoke(\n",
    "    eval_prompt.format(\n",
    "        question=question, results=\"\\n\".join(f\"- {result['content']}\" for result in search_results)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:46:09.135709Z",
     "iopub.status.busy": "2024-10-29T13:46:09.135709Z",
     "iopub.status.idle": "2024-10-29T13:46:09.139257Z",
     "shell.execute_reply": "2024-10-29T13:46:09.139257Z",
     "shell.execute_reply.started": "2024-10-29T13:46:09.135709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_availability(binary_score='no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **웹 검색 결과로 해결 가능/불가능 여부로 다음 노드 라우팅하는 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:46:55.005545Z",
     "iopub.status.busy": "2024-10-29T13:46:55.005545Z",
     "iopub.status.idle": "2024-10-29T13:46:55.009511Z",
     "shell.execute_reply": "2024-10-29T13:46:55.009511Z",
     "shell.execute_reply.started": "2024-10-29T13:46:55.005545Z"
    }
   },
   "outputs": [],
   "source": [
    "def route_after_search(state: AgentState) -> Literal[\"generate\", \"github_search\"]:\n",
    "    \"\"\"\n",
    "    Route based on search evaluation\n",
    "    \"\"\"\n",
    "    if state[\"web_score\"] == \"yes\":\n",
    "        print(\"---DECISION: 웹 검색 결과로 해결 가능합니다.\")\n",
    "        return \"web_generate\"\n",
    "    else:\n",
    "        print(\"---DECISION: 웹 검색 결과로 해결 불가합니다. 깃헙을 찾아보겠습니다.\")\n",
    "        return \"github_generate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **웹 검색 기반 답변 노드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:49:41.504756Z",
     "iopub.status.busy": "2024-10-29T13:49:41.504756Z",
     "iopub.status.idle": "2024-10-29T13:49:41.510115Z",
     "shell.execute_reply": "2024-10-29T13:49:41.510115Z",
     "shell.execute_reply.started": "2024-10-29T13:49:41.504756Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def web_generate(state: AgentState):\n",
    "    question = state[\"question\"]\n",
    "    web_results = state[\"search_results\"]\n",
    "    def format_web_results(results):\n",
    "        formatted = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted.append(f\"Source {i}:\\nURL: {result['url']}\\nContent: {result['content']}\\n\")\n",
    "        return \"\\n\".join(formatted)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a helpful assistant that generates comprehensive answers based on web search results.\n",
    "        Use the provided search results to answer the user's question.\n",
    "        Make sure to synthesize information from multiple sources when possible.\n",
    "        If the search results don't contain enough information to fully answer the question, acknowledge this limitation.\"\"\"),\n",
    "        (\"user\", \"\"\"Question: {question}\n",
    "\n",
    "        Search Results:\n",
    "        {web_results}\n",
    "\n",
    "        Please provide a detailed answer based on these search results. Answer in Korean\"\"\")\n",
    "    ])\n",
    "    chain = (\n",
    "        {\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            \"web_results\": lambda x: format_web_results(x[\"web_results\"])\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "        # Execute the chain\n",
    "    print(\"---웹 검색 결과 기반 답변 생성중...\")\n",
    "    response = chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"web_results\": web_results\n",
    "    })\n",
    "    return {\n",
    "        \"generation\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **깃헙 레포 정보를 가져오는 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:55:35.206496Z",
     "iopub.status.busy": "2024-10-29T13:55:35.206496Z",
     "iopub.status.idle": "2024-10-29T13:55:36.248323Z",
     "shell.execute_reply": "2024-10-29T13:55:36.248323Z",
     "shell.execute_reply.started": "2024-10-29T13:55:35.206496Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GithubFileLoader\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def git_loader(repo, branch_name):\n",
    "    loader = GithubFileLoader(\n",
    "    repo=repo,  # the repo name\n",
    "    branch=branch_name,  # the branch name\n",
    "    access_token=\"github_pat_\",\n",
    "    github_api_url=\"https://api.github.com\",\n",
    "    file_filter=lambda file_path: file_path.endswith(\n",
    "        \".md\"\n",
    "    ),  # load all markdowns files.\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def git_vector_embedding(repo_name):\n",
    "    client = chromadb.Client(Settings(\n",
    "        is_persistent=True,\n",
    "        persist_directory=\"./chroma_db\"  # 저장될 디렉토리 지정\n",
    "        ))\n",
    "\n",
    "    collection_name = repo_name.split(\"/\")[1]\n",
    "\n",
    "    # Check if collection already exists\n",
    "    existing_collections = client.list_collections()\n",
    "    if collection_name in [col.name for col in existing_collections]:\n",
    "        print(f\"Loading existing collection for {collection_name}\")\n",
    "        # Load existing collection\n",
    "        vectorstore = Chroma(\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=OpenAIEmbeddings()\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f\"Creating new collection for {collection_name}\")\n",
    "        # Create new collection with documents\n",
    "        try:\n",
    "            git_docs = git_loader(repo_name, \"master\")\n",
    "        except:\n",
    "            git_docs = git_loader(repo_name, \"main\")\n",
    "            \n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=500, chunk_overlap=50\n",
    "        )    \n",
    "        doc_splits = text_splitter.split_documents(git_docs)\n",
    "        \n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=doc_splits,\n",
    "            collection_name=collection_name,\n",
    "            embedding=OpenAIEmbeddings(),\n",
    "            client=client\n",
    "        )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **깃헙 레포 정보 기반의 답변 생성 노드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T13:59:12.900568Z",
     "iopub.status.busy": "2024-10-29T13:59:12.899562Z",
     "iopub.status.idle": "2024-10-29T13:59:12.910941Z",
     "shell.execute_reply": "2024-10-29T13:59:12.910941Z",
     "shell.execute_reply.started": "2024-10-29T13:59:12.900568Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "def github_generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Find relevant GitHub repositories for the user's question.\n",
    "    \"\"\"\n",
    "    class GitHubRepo(BaseModel):\n",
    "        \"\"\"Best matching GitHub repository\"\"\"\n",
    "        repo_name: str = Field(description=\"Full repository name in format 'owner/repo'\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # 1. Perform targeted web search for GitHub repositories\n",
    "    search_tool = TavilySearchResults(max_results=5)\n",
    "    search_results = search_tool.invoke(\n",
    "        f\"github repository {question} site:github.com\"\n",
    "    )\n",
    "    \n",
    "    # 2. Extract and evaluate repositories from search results\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an expert at identifying the most relevant GitHub repository.\n",
    "        Analyze the search results and identify the SINGLE MOST RELEVANT GitHub repository.\n",
    "        Return ONLY the repository name in the format 'owner/repo'.\"\"\"),\n",
    "        (\"user\", \"\"\"\n",
    "        Question: {question}\n",
    "        Search Results: {results}\n",
    "        \n",
    "        What is the most relevant repository name?\"\"\")\n",
    "    ])\n",
    "    \n",
    "    repo_extractor = llm.with_structured_output(GitHubRepo)\n",
    "    \n",
    "    best_repo = repo_extractor.invoke(\n",
    "        eval_prompt.format(\n",
    "            question=question,\n",
    "            results=\"\\n\\n\".join(f\"URL: {result['url']}\\nContent: {result['content']}\" \n",
    "                               for result in search_results)\n",
    "        )\n",
    "    )\n",
    "    repo_name = best_repo.repo_name\n",
    "    vectorstore = git_vector_embedding(repo_name)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    print(\"---GITHUB REPO 검색 결과 기반의 답변 생성중\")\n",
    "    result = rag_chain.invoke(question)\n",
    "    return {\n",
    "        \"generation\": result\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **그래프 구축**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T14:01:07.996446Z",
     "iopub.status.busy": "2024-10-29T14:01:07.996446Z",
     "iopub.status.idle": "2024-10-29T14:01:08.089294Z",
     "shell.execute_reply": "2024-10-29T14:01:08.089294Z",
     "shell.execute_reply.started": "2024-10-29T14:01:07.996446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Initialize graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add all nodes\n",
    "workflow.add_node(\"check_certainty\", check_certainty)\n",
    "workflow.add_node(\"direct_response\", direct_response)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"web_generate\", web_generate)\n",
    "workflow.add_node(\"github_generate\", github_generate)\n",
    "\n",
    "# Add edges\n",
    "# Start flow\n",
    "workflow.add_edge(START, \"check_certainty\")\n",
    "\n",
    "# Add conditional edges based on certainty score\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_certainty\",\n",
    "    route_based_on_certainty,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"direct_response\": \"direct_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conditional edges after web search\n",
    "workflow.add_conditional_edges(\n",
    "    \"web_search\",\n",
    "    route_after_search,\n",
    "    {\n",
    "        \"web_generate\": \"web_generate\",\n",
    "        \"github_generate\": \"github_generate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges to END\n",
    "workflow.add_edge(\"direct_response\", END)\n",
    "workflow.add_edge(\"web_generate\", END)\n",
    "workflow.add_edge(\"github_generate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T14:01:09.831431Z",
     "iopub.status.busy": "2024-10-29T14:01:09.831431Z",
     "iopub.status.idle": "2024-10-29T14:01:11.604590Z",
     "shell.execute_reply": "2024-10-29T14:01:11.603580Z",
     "shell.execute_reply.started": "2024-10-29T14:01:09.831431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T14:01:39.279665Z",
     "iopub.status.busy": "2024-10-29T14:01:39.278655Z",
     "iopub.status.idle": "2024-10-29T14:01:57.271678Z",
     "shell.execute_reply": "2024-10-29T14:01:57.271678Z",
     "shell.execute_reply.started": "2024-10-29T14:01:39.279665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECKING LLM'S CERTAINTY\n",
      "---LLM IS NOT CERTAIN SO IT WILL DO WEB SEARCH\n",
      "\"Output from node 'check_certainty':\"\n",
      "'---'\n",
      "{'certainty_score': 90}\n",
      "'\\n---\\n'\n",
      "---CHECK WHETHER WEB SEARCH IS SUFFICIENT FOR USER'S ASK\n",
      "---DECISION: 웹 검색 결과로 해결 가능합니다.\n",
      "\"Output from node 'web_search':\"\n",
      "'---'\n",
      "{ 'search_results': [ { 'content': 'YOLO v5 실습해보기\\n'\n",
      "                                   '\\n'\n",
      "                                   '인공지능 기초\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5\\n'\n",
      "                                   '\\n'\n",
      "                                   '오늘은 YOLO v5 모델에 대해서 공부해보겠습니다 두둥\\n'\n",
      "                                   '욜로~\\n'\n",
      "                                   '욜로는 딥러닝 기반으로 객체를 인식해주는 모델이랍니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '실행 환경\\n'\n",
      "                                   '\\n'\n",
      "                                   'Colab 환경에서 실행해주겠습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '우선 깃헙에서 모델을 가져올게요\\n'\n",
      "                                   '\\n'\n",
      "                                   '런타임 유형을 GPU로 바꾸고\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '여러 사양들을 확인해봤습니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '데이터셋 준비\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   'Roboflow 에서 dataset을 다운받아줍니다.\\n'\n",
      "                                   '오늘은 Hard Hat Workers Datasets를 쓸게요\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '포맷은 YOLO v5에서 돌릴거니까 YOLO v5 PyTorch로 '\n",
      "                                   '설정해주고\\n'\n",
      "                                   '깃허브로 로그인 하면 다운받을 수 있는 링크가 나온답니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '링크 복사해서 데이터셋 다운받아주기!!\\n'\n",
      "                                   '옆에 파일 목록에서 새로고침 했더니 잘 받아진걸 볼 수 있군요\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   'train 데이터를 살펴보니 이미지와\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '해당 이미지의 label이 있네요 [...] 이 데이터는 헬맷을 쓴 인부들의 '\n",
      "                                   '이미지에서 헬맷을 탐색하기 때문에\\n'\n",
      "                                   'label의 각 줄은 object가 있는 X좌표, Y좌표, Width, '\n",
      "                                   'Height을 뜻합니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '..데이터가 너무 흩어져있길래 모아줬습니다\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5를 실행하기 위한 준비\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '오른쪽의 requirements.txt는 yolov5모델을 실행하기 위해 '\n",
      "                                   '요구되는 실행환경들입니다\\n'\n",
      "                                   '설치설치~\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '아까 다운받은 dataset폴더에 있는 data.yaml 파일을 보면\\n'\n",
      "                                   'train, validation data의 경로, Nc(클래스 개수), '\n",
      "                                   'Names(클래스 이름)이 있네요\\n'\n",
      "                                   '\\n'\n",
      "                                   '여기서 제 경로에 맞게 데이터 경로를 수정하고,\\n'\n",
      "                                   'train데이터와 validation data를 나눠주겠습니다\\n'\n",
      "                                   '\\n'\n",
      "                                   'train data:모델 학습을 위한 데이터\\n'\n",
      "                                   'validation data:모델 검증을 위한 데이터\\n'\n",
      "                                   '\\n'\n",
      "                                   'train, validation data 나누기 [...] glob 패키지를 '\n",
      "                                   '사용해서 dataset에 있는 모든 jpg이미지를 불러왔습니다\\n'\n",
      "                                   '총 1766개의 이미지가 있군요\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   'sckit-learn 에서 train_test_split 을 import '\n",
      "                                   '하고\\n'\n",
      "                                   'train_img_list 와 val_img_list를 나누어줄게요\\n'\n",
      "                                   'train:val = 8:2 로 설정했기 때문에 test_size는 0.2\\n'\n",
      "                                   '그래서 위의 1766개의 이미지가 train data 1412 개 '\n",
      "                                   'validation data 354개로 잘 나눠졌답니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   'train / val data list를 담은 txt 파일을 만들어줬어요\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '앞서 말했던 yaml 파일의 파일 경로들을 수정해줄게요\\n'\n",
      "                                   '\\n'\n",
      "                                   '학습하기\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '각종 arguments 값을 지정해주고 train코드를 돌렸습니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   'epoch 50까지 열심히 돌아가는중...\\n'\n",
      "                                   '\\n'\n",
      "                                   '학습 결과\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '짜잔\\n'\n",
      "                                   'train data의 라벨링 결과입니다\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\n'\n",
      "                                   '이건 validation data의 라벨이구요',\n",
      "                        'score': 0.7552947,\n",
      "                        'title': 'YOLO v5 실습해보기 - velog',\n",
      "                        'url': 'https://velog.io/@yooniverseis/YOLO-v5-%EC%8B%A4%EC%8A%B5%ED%95%B4%EB%B3%B4%EA%B8%B0'},\n",
      "                      { 'content': '소개\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5 빠른 시작 🚀\\n'\n",
      "                                   '\\n'\n",
      "                                   '실시간 물체 감지의 역동적인 영역으로 Ultralytics YOLOv5 함께 '\n",
      "                                   '여정을 시작하세요! 이 가이드는 YOLOv5 마스터하고자 하는 AI 애호가와 '\n",
      "                                   '전문가를 위한 종합적인 시작점 역할을 하도록 제작되었습니다. 초기 설정부터 '\n",
      "                                   '고급 훈련 기법까지 모든 것을 다룹니다. 이 가이드가 끝나면 최첨단 딥러닝 '\n",
      "                                   '방법을 사용해 프로젝트에 YOLOv5 자신 있게 구현할 수 있는 지식을 '\n",
      "                                   '갖추게 될 것입니다. 이제 엔진에 불을 붙이고 YOLOv5 날아오르세요!\\n'\n",
      "                                   '\\n'\n",
      "                                   '설치\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5 리포지토리를 복제하고 환경을 설정하여 출시를 준비합니다. 이렇게 '\n",
      "                                   '하면 필요한 모든 요구 사항이 설치됩니다. 다음이 설치되어 있는지 '\n",
      "                                   '확인합니다. Python.8.0 및 PyTorch8 이 준비되었는지 '\n",
      "                                   '확인하세요. 이러한 기본 도구는 YOLOv5 효과적으로 실행하는 데 매우 '\n",
      "                                   '중요합니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   'PyTorch 허브를 통한 추론 [...] 결론적으로, YOLOv5 물체 '\n",
      "                                   '감지를 위한 최첨단 도구일 뿐만 아니라 시각적 이해를 통해 세상과 '\n",
      "                                   '상호작용하는 방식을 변화시키는 머신러닝의 힘을 보여주는 증거이기도 합니다. '\n",
      "                                   '이 가이드를 진행하면서 프로젝트에 YOLOv5 적용하기 시작하면 컴퓨터 비전 '\n",
      "                                   '분야에서 놀라운 업적을 달성할 수 있는 기술 혁명의 최전선에 서 있다는 '\n",
      "                                   '사실을 기억하세요. 더 많은 인사이트나 동료 비저너리들의 지원이 필요하다면, '\n",
      "                                   '활발한 개발자 및 연구자 커뮤니티가 있는 GitHub 리포지토리에 '\n",
      "                                   '초대합니다. 코드 없이 데이터 집합 관리 및 모델 학습을 위한 '\n",
      "                                   'Ultralytics HUB와 같은 추가 리소스를 살펴보거나, 실제 적용 '\n",
      "                                   '사례와 영감을 얻을 수 있는 솔루션 페이지를 확인하세요. 계속 탐색하고, '\n",
      "                                   '계속 혁신하며, YOLOv5 경이로움을 즐겨보세요. 행복한 탐지! 🌠🔍\\n'\n",
      "                                   '\\n'\n",
      "                                   '댓글 [...] 최신 YOLOv5 릴리스에서 모델을 원활하게 다운로드할 수 '\n",
      "                                   '있는 YOLOv5 PyTorch Hub 추론의 단순함을 경험해 보세요. 이 '\n",
      "                                   '방법은 PyTorch 의 강력한 기능을 활용하여 모델을 쉽게 로드하고 실행할 '\n",
      "                                   '수 있으므로 예측을 쉽게 얻을 수 있습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   'detect.py를 사용한 추론\\n'\n",
      "                                   '\\n'\n",
      "                                   '하네스 detect.py 다용도 추론 를 검색합니다. 자동으로 다음을 '\n",
      "                                   '가져옵니다. 모델 최신 YOLOv5 릴리스 를 실행하고 결과를 쉽게 저장할 '\n",
      "                                   '수 있습니다. 이 스크립트는 이미지, 동영상, 디렉토리, 웹캠 등의 입력을 '\n",
      "                                   '지원하여 명령줄 사용과 YOLOv5 대규모 시스템에 통합하는 데 '\n",
      "                                   '이상적입니다. 라이브 스트림.\\n'\n",
      "                                   '\\n'\n",
      "                                   '교육',\n",
      "                        'score': 0.71088976,\n",
      "                        'title': 'YOLOv5 빠른 시작 - Ultralytics YOLO 문서',\n",
      "                        'url': 'https://docs.ultralytics.com/ko/yolov5/quickstart_tutorial/'},\n",
      "                      { 'content': \"먼저, 구글 드라이브에 앞서 만든 'guide_cocacola' 폴더를 \"\n",
      "                                   '업로드한 후, Colab 환경을 준비하고,\\n'\n",
      "                                   '\\n'\n",
      "                                   'Colab과 구글 드라이브를 연동해줍니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '그다음 YOLOv5 모델을 GitHub에서 Clone 해서 받아옵니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '(참고: GitHub - ultralytics/yolov5: YOLOv5 '\n",
      "                                   'in PyTorch > ONNX > CoreML > TFLite)\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5 모델을 사용하기 위한 패키지를 설치하고,\\n'\n",
      "                                   '\\n'\n",
      "                                   \"resize 한 cocacola 이미지를 'img_list_co'에 \"\n",
      "                                   '넣어줍니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   \"그다음, 'img_list_co'에 들어있는 resize 된 이미지를 \"\n",
      "                                   'test(20%)/train(80%) dataset으로 나눠주고,\\n'\n",
      "                                   '\\n'\n",
      "                                   \"'guide_cocacola' 폴더에 들어있는 \"\n",
      "                                   \"'guide_cocacola.yaml' 파일을 이용하여,\\n\"\n",
      "                                   '\\n'\n",
      "                                   'train에는 train.txt를, test에는 test.txt를 '\n",
      "                                   '넣어줍니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\u200b\\n'\n",
      "                                   '\\n'\n",
      "                                   \"위 코드를 실행시키면, [...] 다음과 같이 'guide_resize' \"\n",
      "                                   '폴더에서 모든 이미지가 416 X 416 크기로 resize된 결과를 '\n",
      "                                   '확인하실 수 있습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '3. Image Labeling\\n'\n",
      "                                   '\\n'\n",
      "                                   '라벨링을 진행하기 전!\\n'\n",
      "                                   '\\n'\n",
      "                                   'Anaconda에서 YOLOv5 모델의 환경설정을 먼저 해주도록 '\n",
      "                                   '하겠습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   'Anaconda Prompt 창에서 위 코드를 실행한 후,\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\u200b\\n'\n",
      "                                   '\\n'\n",
      "                                   'YOLOv5 in PyTorch > ONNX > CoreML > '\n",
      "                                   'TFLite. Contribute to ultralytics/yolov5 '\n",
      "                                   'development by creating an account on '\n",
      "                                   'GitHub.\\n'\n",
      "                                   '\\n'\n",
      "                                   'github.com\\n'\n",
      "                                   '\\n'\n",
      "                                   'GitHub 링크에 들어가 YOLOv5 모델을 다운받아줍니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '이후, 다시 Anaconda Prompt 창에서 위 코드를 실행시켜주면 '\n",
      "                                   'YOLOv5 모델 환경설정 완료!\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\u200b [...] 즉, 제가 라벨링한 cocacola의 class '\n",
      "                                   '번호는 0임을 알 수 있습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '혹시 class 번호를 일괄적으로 0에서 1로 수정하고싶다면, '\n",
      "                                   'Anaconda Powershell Prompt 창에서 위의 코드를 '\n",
      "                                   '실행시키면 됩니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   \"(위 코드는 '숫자 0을 모두 1로 바꿔줌'을 의미함, 다른 정확한 코드가 \"\n",
      "                                   '있을 것 같음...............더 알아봐야겠습니다ㅜㅅㅜ)\\n'\n",
      "                                   '\\n'\n",
      "                                   '4. Object Detection 진행\\n'\n",
      "                                   '\\n'\n",
      "                                   '드디어 Object Detection 진행을 위한 Dataset 준비가 끝이 '\n",
      "                                   '났네요!\\n'\n",
      "                                   '\\n'\n",
      "                                   '본격적으로 Object Detection Inference 과정을 '\n",
      "                                   '진행해보겠습니다.\\n'\n",
      "                                   '\\n'\n",
      "                                   '\\u200b\\n'\n",
      "                                   '\\n'\n",
      "                                   \"로컬 디스크(C:)에 'guide_cocacola' 폴더를 만들어준 후,\\n\"\n",
      "                                   '\\n'\n",
      "                                   \"그 안에 'export' 폴더를 만들고\\n\"\n",
      "                                   '\\n'\n",
      "                                   '아래 코드가 입력된 메모장(파일 형식은 모든 파일로, 파일명은 '\n",
      "                                   \"'guide_cocacola.yaml'로 설정)도 만들어줍니다.\\n\"\n",
      "                                   '\\n'\n",
      "                                   '그럼 이렇게 총 두 개의 파일이 생성되겠죠!',\n",
      "                        'score': 0.70287734,\n",
      "                        'title': '[yolov5] yolov5 모델의 Object Detection Custom '\n",
      "                                 'Dataset 만들기!',\n",
      "                        'url': 'https://m.blog.naver.com/bsh1004664/222422137547'}],\n",
      "  'web_score': 'yes'}\n",
      "'\\n---\\n'\n",
      "---웹 검색 결과 기반 답변 생성중...\n",
      "\"Output from node 'web_generate':\"\n",
      "'---'\n",
      "{ 'generation': 'YOLOv5를 실행하는 방법에 대해 설명드리겠습니다. 아래는 Google Colab 환경에서 YOLOv5를 '\n",
      "                '실행하기 위한 단계별 코드입니다.\\n'\n",
      "                '\\n'\n",
      "                '### 1. Google Colab 환경 설정\\n'\n",
      "                '먼저 Google Colab을 열고, GPU를 사용할 수 있도록 설정합니다. 상단 메뉴에서 `런타임` > '\n",
      "                '`런타임 유형 변경` > `하드웨어 가속기`를 `GPU`로 선택합니다.\\n'\n",
      "                '\\n'\n",
      "                '### 2. YOLOv5 리포지토리 클론\\n'\n",
      "                'YOLOv5 모델을 GitHub에서 클론합니다. 아래 코드를 Colab의 셀에 입력하고 실행합니다.\\n'\n",
      "                '\\n'\n",
      "                '```python\\n'\n",
      "                '!git clone https://github.com/ultralytics/yolov5.git\\n'\n",
      "                '%cd yolov5\\n'\n",
      "                '```\\n'\n",
      "                '\\n'\n",
      "                '### 3. 필요한 패키지 설치\\n'\n",
      "                'YOLOv5를 실행하기 위해 필요한 패키지를 설치합니다.\\n'\n",
      "                '\\n'\n",
      "                '```python\\n'\n",
      "                '!pip install -r requirements.txt\\n'\n",
      "                '```\\n'\n",
      "                '\\n'\n",
      "                '### 4. 데이터셋 준비\\n'\n",
      "                '데이터셋을 준비합니다. Roboflow와 같은 플랫폼에서 YOLOv5 형식으로 데이터를 다운로드하거나, 직접 '\n",
      "                '데이터를 준비하여 Google Drive에 업로드합니다. 데이터셋의 경로를 설정하는 YAML 파일을 작성해야 '\n",
      "                '합니다.\\n'\n",
      "                '\\n'\n",
      "                '예를 들어, `data.yaml` 파일의 내용은 다음과 같을 수 있습니다:\\n'\n",
      "                '\\n'\n",
      "                '```yaml\\n'\n",
      "                'train: ../path/to/train/images\\n'\n",
      "                'val: ../path/to/val/images\\n'\n",
      "                '\\n'\n",
      "                'nc: 1  # 클래스 수\\n'\n",
      "                \"names: ['class_name']  # 클래스 이름\\n\"\n",
      "                '```\\n'\n",
      "                '\\n'\n",
      "                '### 5. 모델 학습\\n'\n",
      "                '모델을 학습시키기 위해 아래 코드를 실행합니다. `--img`는 이미지 크기, `--batch`는 배치 크기, '\n",
      "                '`--epochs`는 학습할 에폭 수를 설정합니다.\\n'\n",
      "                '\\n'\n",
      "                '```python\\n'\n",
      "                '!python train.py --img 640 --batch 16 --epochs 50 --data '\n",
      "                'data.yaml --weights yolov5s.pt\\n'\n",
      "                '```\\n'\n",
      "                '\\n'\n",
      "                '### 6. 객체 탐지 실행\\n'\n",
      "                '학습이 완료된 후, 객체 탐지를 실행할 수 있습니다. 아래 코드를 사용하여 이미지 또는 비디오에서 객체 탐지를 '\n",
      "                '수행합니다.\\n'\n",
      "                '\\n'\n",
      "                '```python\\n'\n",
      "                '!python detect.py --source ../path/to/your/image_or_video  # '\n",
      "                '이미지 또는 비디오 경로\\n'\n",
      "                '```\\n'\n",
      "                '\\n'\n",
      "                '### 7. 결과 확인\\n'\n",
      "                '탐지 결과는 `runs/detect/exp` 폴더에 저장됩니다. 해당 폴더에서 결과 이미지를 확인할 수 '\n",
      "                '있습니다.\\n'\n",
      "                '\\n'\n",
      "                '이 과정을 통해 YOLOv5를 성공적으로 실행하고 객체 탐지를 수행할 수 있습니다. 각 단계에서 필요한 경로와 '\n",
      "                '파일 이름은 사용자의 환경에 맞게 조정해야 합니다.'}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\": \"Yolo v5를 실행하는 방법에 대해서 알아? 정확한 코드를 줄래?\"\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T14:02:17.569916Z",
     "iopub.status.busy": "2024-10-29T14:02:17.569916Z",
     "iopub.status.idle": "2024-10-29T14:02:17.574332Z",
     "shell.execute_reply": "2024-10-29T14:02:17.574332Z",
     "shell.execute_reply.started": "2024-10-29T14:02:17.569916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'YOLO v5를 실행하는 방법에 대해 설명드리겠습니다. YOLO v5는 객체 탐지 모델로, PyTorch를 '\n",
      "                '기반으로 하고 있습니다. 아래는 YOLO v5를 로컬 PC에서 실행하는 방법에 대한 단계별 가이드와 코드 '\n",
      "                '예시입니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 1. 환경 설정\n",
      "'\n",
      "                '먼저, YOLO v5를 실행하기 위해 필요한 환경을 설정해야 합니다. Python 3.9 이상이 설치되어 '\n",
      "                '있어야 하며, 필요한 패키지를 설치하기 위해 `requirements.txt` 파일을 사용할 수 있습니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '```bash\n",
      "'\n",
      "                '# YOLO v5 저장소 클론\n",
      "'\n",
      "                'git clone https://github.com/ultralytics/yolov5.git\n",
      "'\n",
      "                'cd yolov5\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '# 필요한 패키지 설치\n",
      "'\n",
      "                'pip install -r requirements.txt\n",
      "'\n",
      "                '```\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 2. 데이터 준비\n",
      "'\n",
      "                'YOLO v5를 사용하기 위해서는 데이터셋이 필요합니다. 데이터셋은 이미지와 해당 이미지에 대한 레이블이 '\n",
      "                '포함되어야 합니다. 레이블링 작업은 `labelImg`와 같은 도구를 사용하여 수행할 수 있습니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 3. YAML 파일 생성\n",
      "'\n",
      "                '데이터셋을 준비한 후, YOLO v5가 데이터를 인식할 수 있도록 YAML 파일을 생성해야 합니다. 이 '\n",
      "                '파일에는 데이터셋의 경로와 클래스 정보가 포함되어야 합니다. 예를 들어, `data.yaml` 파일은 다음과 '\n",
      "                '같이 작성할 수 있습니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '```yaml\n",
      "'\n",
      "                'train: ./custom_dataset/train/images\n",
      "'\n",
      "                'val: ./custom_dataset/val/images\n",
      "'\n",
      "                '\n",
      "'\n",
      "                'nc: 2  # 클래스 수\n",
      "'\n",
      "                \"names: ['class1', 'class2']  # 클래스 이름\n",
      "\"\n",
      "                '```\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 4. 모델 학습\n",
      "'\n",
      "                '이제 YOLO v5 모델을 학습시킬 준비가 되었습니다. 아래의 코드를 사용하여 모델을 학습할 수 있습니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '```bash\n",
      "'\n",
      "                '# 모델 학습\n",
      "'\n",
      "                'python train.py --img 640 --batch 16 --epochs 50 --data '\n",
      "                'data.yaml --weights yolov5s.pt\n",
      "'\n",
      "                '```\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '여기서 `--img`는 이미지 크기, `--batch`는 배치 크기, `--epochs`는 학습할 에폭 수, '\n",
      "                '`--data`는 YAML 파일의 경로, `--weights`는 사용할 사전 학습된 모델의 경로를 '\n",
      "                '지정합니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 5. 모델 추론\n",
      "'\n",
      "                '학습이 완료된 후, 모델을 사용하여 이미지를 추론할 수 있습니다. 아래의 코드를 사용하여 이미지를 추론할 수 '\n",
      "                '있습니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '```bash\n",
      "'\n",
      "                '# 추론\n",
      "'\n",
      "                'python detect.py --weights runs/train/exp/weights/best.pt '\n",
      "                '--img 640 --conf 0.25 --source path/to/your/image.jpg\n",
      "'\n",
      "                '```\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '여기서 `--source`는 추론할 이미지의 경로를 지정합니다.\n",
      "'\n",
      "                '\n",
      "'\n",
      "                '### 결론\n",
      "'\n",
      "                '위의 단계들을 통해 YOLO v5를 로컬 환경에서 실행하고, 객체 탐지 모델을 학습 및 추론할 수 있습니다. '\n",
      "                '각 단계에서 필요한 파일과 경로를 정확히 설정하는 것이 중요합니다. 추가적인 세부사항이나 문제가 발생할 경우, '\n",
      "                'YOLO v5의 공식 문서나 GitHub 페이지를 참조하는 것이 좋습니다.'\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"'YOLO v5를 실행하는 방법에 대해 설명드리겠습니다. YOLO v5는 객체 탐지 모델로, PyTorch를 '\n",
    "                '기반으로 하고 있습니다. 아래는 YOLO v5를 로컬 PC에서 실행하는 방법에 대한 단계별 가이드와 코드 '\n",
    "                '예시입니다.\\n'\n",
    "                '\\n'\n",
    "                '### 1. 환경 설정\\n'\n",
    "                '먼저, YOLO v5를 실행하기 위해 필요한 환경을 설정해야 합니다. Python 3.9 이상이 설치되어 '\n",
    "                '있어야 하며, 필요한 패키지를 설치하기 위해 `requirements.txt` 파일을 사용할 수 있습니다.\\n'\n",
    "                '\\n'\n",
    "                '```bash\\n'\n",
    "                '# YOLO v5 저장소 클론\\n'\n",
    "                'git clone https://github.com/ultralytics/yolov5.git\\n'\n",
    "                'cd yolov5\\n'\n",
    "                '\\n'\n",
    "                '# 필요한 패키지 설치\\n'\n",
    "                'pip install -r requirements.txt\\n'\n",
    "                '```\\n'\n",
    "                '\\n'\n",
    "                '### 2. 데이터 준비\\n'\n",
    "                'YOLO v5를 사용하기 위해서는 데이터셋이 필요합니다. 데이터셋은 이미지와 해당 이미지에 대한 레이블이 '\n",
    "                '포함되어야 합니다. 레이블링 작업은 `labelImg`와 같은 도구를 사용하여 수행할 수 있습니다.\\n'\n",
    "                '\\n'\n",
    "                '### 3. YAML 파일 생성\\n'\n",
    "                '데이터셋을 준비한 후, YOLO v5가 데이터를 인식할 수 있도록 YAML 파일을 생성해야 합니다. 이 '\n",
    "                '파일에는 데이터셋의 경로와 클래스 정보가 포함되어야 합니다. 예를 들어, `data.yaml` 파일은 다음과 '\n",
    "                '같이 작성할 수 있습니다.\\n'\n",
    "                '\\n'\n",
    "                '```yaml\\n'\n",
    "                'train: ./custom_dataset/train/images\\n'\n",
    "                'val: ./custom_dataset/val/images\\n'\n",
    "                '\\n'\n",
    "                'nc: 2  # 클래스 수\\n'\n",
    "                \"names: ['class1', 'class2']  # 클래스 이름\\n\"\n",
    "                '```\\n'\n",
    "                '\\n'\n",
    "                '### 4. 모델 학습\\n'\n",
    "                '이제 YOLO v5 모델을 학습시킬 준비가 되었습니다. 아래의 코드를 사용하여 모델을 학습할 수 있습니다.\\n'\n",
    "                '\\n'\n",
    "                '```bash\\n'\n",
    "                '# 모델 학습\\n'\n",
    "                'python train.py --img 640 --batch 16 --epochs 50 --data '\n",
    "                'data.yaml --weights yolov5s.pt\\n'\n",
    "                '```\\n'\n",
    "                '\\n'\n",
    "                '여기서 `--img`는 이미지 크기, `--batch`는 배치 크기, `--epochs`는 학습할 에폭 수, '\n",
    "                '`--data`는 YAML 파일의 경로, `--weights`는 사용할 사전 학습된 모델의 경로를 '\n",
    "                '지정합니다.\\n'\n",
    "                '\\n'\n",
    "                '### 5. 모델 추론\\n'\n",
    "                '학습이 완료된 후, 모델을 사용하여 이미지를 추론할 수 있습니다. 아래의 코드를 사용하여 이미지를 추론할 수 '\n",
    "                '있습니다.\\n'\n",
    "                '\\n'\n",
    "                '```bash\\n'\n",
    "                '# 추론\\n'\n",
    "                'python detect.py --weights runs/train/exp/weights/best.pt '\n",
    "                '--img 640 --conf 0.25 --source path/to/your/image.jpg\\n'\n",
    "                '```\\n'\n",
    "                '\\n'\n",
    "                '여기서 `--source`는 추론할 이미지의 경로를 지정합니다.\\n'\n",
    "                '\\n'\n",
    "                '### 결론\\n'\n",
    "                '위의 단계들을 통해 YOLO v5를 로컬 환경에서 실행하고, 객체 탐지 모델을 학습 및 추론할 수 있습니다. '\n",
    "                '각 단계에서 필요한 파일과 경로를 정확히 설정하는 것이 중요합니다. 추가적인 세부사항이나 문제가 발생할 경우, '\n",
    "                'YOLO v5의 공식 문서나 GitHub 페이지를 참조하는 것이 좋습니다.'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
