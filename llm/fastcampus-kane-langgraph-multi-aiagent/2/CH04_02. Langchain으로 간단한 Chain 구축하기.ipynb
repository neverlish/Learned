{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88978bf5-376e-44e2-9bb8-1696439128da",
   "metadata": {},
   "source": [
    "### **Model 컴포넌트 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07595bcf-63cc-4d89-8b6d-ff5fd153cb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BJzyzXAjQahPheBiDN4EyuhQ1HGiH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='2002년 월드컵 4강에는 독일, 브라질, 터키, 한국이 포함되었습니다.결과적으로 독일과 브라질이 결승에 진출했고, 한국은 준결승에서 독일과, 터키는 브라질과 맞붙었습니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1744106193, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=106, prompt_tokens=31, total_tokens=137, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"2002년 월드컵 4강 국가 알려줘\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa96b6ac-e6fb-4455-8f7d-0c28e1cc67e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 AI 언어 모델로, 다양한 주제에 대해 질문에 답하고 정보를 제공하는 역할을 하고 있어요. 글쓰기, 정보 검색, 언어 번역, 그리고 여러 가지 주제에 대해 대화할 수 있습니다. 무엇이든 궁금한 점이 있다면 언제든지 물어보세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 17, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'stop', 'logprobs': None}, id='run-b60c9203-fc87-4bcc-af0b-f73eb2650259-0', usage_metadata={'input_tokens': 17, 'output_tokens': 71, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model_name = 'gpt-4o-mini'\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220be5e5-a881-4341-9f45-7838c8d93956",
   "metadata": {},
   "source": [
    "### **PromptTemplate 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696ad239-13da-4e00-adfe-47d0bf96f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['개수', '재료'], input_types={}, partial_variables={}, template='\\n        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 {개수}추천하고, \\n        그 요리의 레시피를 제시해줘. 내가 가진 재료는 아래와 같아.\\n        <재료>\\n        {재료}\\n        ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt= (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 {개수}추천하고, \n",
    "        그 요리의 레시피를 제시해줘. 내가 가진 재료는 아래와 같아.\n",
    "        <재료>\n",
    "        {재료}\n",
    "        \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf279ec-c620-44bf-a94b-be654e706526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='\\n        너는 요리사야. 내가 가진 재료들을 갖고 만들 수 있는 요리를 6추천하고, \\n        그 요리의 레시피를 제시해줘. 내가 가진 재료는 아래와 같아.\\n        <재료>\\n        사과, 잼\\n        ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"개수\":6, \"재료\":\"사과, 잼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0987e80b-c669-43d2-b44a-8105ddaefcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t#SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"), \n",
    "    #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186504a7-c64d-4cf7-a264-b8ed1b935c9f",
   "metadata": {},
   "source": [
    "### **LCEL로 Chain 구축하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22049ee-4206-42e6-8cf9-9c6e240b736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What did the ice cream cone say to the refrigerator?  \\n\\n\"Stop staring at me, you’re making me melt!\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#프롬프트 템플릿 설정\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "\n",
    "#LLM 호출\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#LCEL로 프롬프트템플릿-LLM-출력 파서 연결하기\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "#invoke함수로 chain 실행하기\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "797d09dd-7723-4889-bcb9-a45f23437006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do polar bears never get lost?\n",
      "\n",
      "Because they always follow the \"bear\"ings!"
     ]
    }
   ],
   "source": [
    "#Chain 선언\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model\n",
    "\n",
    "#Chain의 stream()함수를 통해 스트리밍 기능 추가\n",
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a9f2f-5fd0-4dc5-8463-dc03f7b587f1",
   "metadata": {},
   "source": [
    "### **OutputParser 실습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d19c7b-0ad6-40b2-ac2f-82d3ff943bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[\"다크 나이트\", \"존 윅\", \"매드 맥스: 분노의 도로\"]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 72, 'total_tokens': 97, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'stop', 'logprobs': None}, id='run-fccbbe9b-cabe-4033-a15a-92030d64e19f-0', usage_metadata={'input_tokens': 72, 'output_tokens': 25, 'total_tokens': 97, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
    "                 temperature = 0)\n",
    "\n",
    "#ChatPromptTemplate에 SystemMessage로 LLM의 역할과 출력 형식 지정\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"너는 영화 전문가 AI야. 사용자가 원하는 장르의 영화를 리스트 형태로 추천해줘.\"\n",
    "                'ex) Query: SF영화 3개 추천해줘 / 답변: [\"인터스텔라\", \"스페이스오디세이\", \"혹성탈출\"]'\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chain = chat_template | model\n",
    "chain.invoke(\"액션\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f136902-310d-4094-8b9b-192886eb4691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#CSV 파서 선언\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "#CSV 파서 작동을 위한 형식 지정 프롬프트 로드\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1593192-62f8-4a54-a63b-da8f3b5fa207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기생충',\n",
       " '곡성',\n",
       " '저주',\n",
       " '악마를 보았다',\n",
       " '사탄의 인형',\n",
       " '더 헌트',\n",
       " '미드소마',\n",
       " '유전',\n",
       " '13일의 금요일',\n",
       " '지옥',\n",
       " '더 링',\n",
       " '일말의 희망',\n",
       " '괴물',\n",
       " '숨바꼭질',\n",
       " '공포의 집']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#CSV 파서 선언\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "#CSV 파서 작동을 위한 형식 지정 프롬프트 로드\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "#프롬프트 템플릿의 partial_variables에 CSV 형식 지정 프롬프트 주입\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List {subject}. answer in Korean \\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#프롬프트템플릿-모델-Output Parser를 체인으로 연결\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"subject\": \"공포 영화\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d70ce4-b497-4179-8e02-65009a5dabec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/.pyenv/versions/3.11.6/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'continent': 'South America', 'population': '45195777'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 데이터 구조를 정의합니다.\n",
    "class Country(BaseModel):\n",
    "    continent: str = Field(description=\"사용자가 물어본 나라가 속한 대륙\")\n",
    "    population: str = Field(description=\"사용자가 물어본 나라의 인구(int 형식)\")\n",
    "    \n",
    "\n",
    "# JsonOutputParser를 설정하고 프롬프트 템플릿에 format_instructions를 삽입합니다.\n",
    "parser = JsonOutputParser(pydantic_object=Country)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "country_query = \"아르헨티나는 어떤 나라야?\"\n",
    "chain.invoke({\"query\": country_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcdc5f-5ffb-46c5-97f0-ceb6bb034fd0",
   "metadata": {},
   "source": [
    "### **LCEL의 Runnable 객체에 대해 알아보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424075d6-47d0-4210-b6cb-a41821ec17ec",
   "metadata": {},
   "source": [
    "#### **RunnablePassthrough 알아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e3b34a-3f9d-48e7-a3fe-0beb72670838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "RunnablePassthrough().invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09adb993-3912-4920-9b1f-275d1a9fdb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elle lit un livre chaque matin.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"다음 한글 문장을 프랑스어로 번역해줘 {sentence}\n",
    "French sentence: (print from here)\"\"\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "runnable_chain = {\"sentence\": RunnablePassthrough()} | prompt | model | output_parser\n",
    "runnable_chain.invoke({\"sentence\": \"그녀는 매일 아침 책을 읽습니다.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ffee4a-a9c4-4a7b-85ac-29a369fb5345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 3, 'mult': 9}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(RunnablePassthrough.assign(mult=lambda x: x[\"num\"]*3)).invoke({\"num\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a779bfbe-07f9-49e0-9a53-ca872e4c602d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9270dc8-e92f-48cd-9d4d-6420bdde55c7",
   "metadata": {},
   "source": [
    "#### **RunnableLambda 알아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31a5ce4c-06d3-48cb-aa4a-61d09a9eac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smile(x):\n",
    "    return x + \":)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41120c5-7f68-4d1c-a3ee-0c1ad7153e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "add_smile = RunnableLambda(add_smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abda72da-e0a8-41eb-8bef-9e9ea53e4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "prompt_str = \"{topic}의 역사에 대해 세문장으로 설명해주세요.\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "\n",
    "model = ChatOpenAI(model_name = 'gpt-4o-mini')\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c241a9dd-2aa3-4495-a99f-ef0e96eedfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_thank(x):\n",
    "    return x + \" 들어주셔서 감사합니다 :)\"\n",
    "\n",
    "add_thank = RunnableLambda(add_thank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "354443f8-b19f-45a4-b647-591bbe8c8616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'반도체는 20세기 중반에 트랜지스터의 발명으로 시작되었으며, 이는 전자기기의 소형화와 효율성을 크게 향상시켰습니다. 이후 집적회로(IC)의 개발로 반도체 기술은 급속히 발전하였고, 컴퓨터, 통신 및 다양한 전자기기에 필수적인 요소가 되었습니다. 현재 반도체 산업은 인공지능, IoT, 자율주행차 등 혁신적인 기술의 기반을 제공하며 글로벌 경제의 중요한 축으로 자리잡고 있습니다. 들어주셔서 감사합니다 :)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser | add_thank\n",
    "chain.invoke(\"반도체\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0700efc0-6ed8-4624-95b7-0f534d4fa322",
   "metadata": {},
   "source": [
    "#### **RunnableParallel 알아보기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0134b7c-7daf-4865-865e-4f6d769e99ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'modified': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b0a2b4-49ce-420e-88ef-fba021bb3311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': '안녕하세요', 'modified': '안녕하세요 들어주셔서 감사합니다 :)'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    modified=add_thank,\n",
    ")\n",
    "\n",
    "runnable.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b49a9c0-c275-457c-a108-df06403adc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI는 \"Artificial Intelligence\"의 약자로, 한국어로는 \"인공지능\"이라고 합니다. 인공지능은 컴퓨터 시스템이 인간의 지능을 모방하여 학습, 추론, 문제 해결, 이해 등의 작업을 수행할 수 있도록 하는 기술을 의미합니다.',\n",
       " 'celeb': '1. 앤드류 응 (Andrew Ng)\\n2. 제프리 힌튼 (Geoffrey Hinton)\\n3. 얀 르쿤 (Yann LeCun)'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model = 'gpt-4o-mini', max_tokens = 128, temperature = 0)\n",
    "\n",
    "history_prompt = ChatPromptTemplate.from_template(\"{topic}가 무엇의 약자인지 알려주세요.\")\n",
    "celeb_prompt = ChatPromptTemplate.from_template(\"{topic} 분야의 유명인사 3명의 이름만 알려주세요.\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "history_chain = history_prompt | model | output_parser\n",
    "celeb_chain = celeb_prompt | model | output_parser\n",
    "\n",
    "map_chain = RunnableParallel(history=history_chain, celeb=celeb_chain)\n",
    "\n",
    "result = map_chain.invoke({\"topic\": \"AI\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e88bfb-32f5-4f2b-833e-dfdc3b580bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
