{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6368,
     "status": "ok",
     "timestamp": 1715499823144,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "K2zVdPiulhhZ",
    "outputId": "116263dd-bec0-4758-88b5-506a8913ca86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2066,
     "status": "ok",
     "timestamp": 1715499825208,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "zL1HWDnrqC2Q",
    "outputId": "9127575b-73d8-48b9-c0ba-4a8677b06334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Qfz5V6tlr8c"
   },
   "source": [
    "### Whisper, STT API를 활용한 음성 인식 및 오류 교정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8_fmcj9na5e"
   },
   "source": [
    "##### 1. OPEN AI Whisper api 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1715499828467,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "6fEpLftSntr9"
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY='sk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25905,
     "status": "ok",
     "timestamp": 1715498200388,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "I3Keo1x8lvH1",
    "outputId": "48ea42b0-edee-47f5-8231-a4292d8db4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 챕터의 7번째 클립, RAG, 자체 문서를 위한 커스텀 검색 시스템 제작 강의 시작하겠습니다. 먼저 개념에 대해서 설명드리고 실습으로 넘어가도록 하겠습니다. 외부 정보 통합 자동화의 필요성에 대해서 먼저 설명을 드리고 시작을 해보도록 하겠습니다. 그래서 지금까지의 강의에서 계속해서 다뤘던 내용들은 왼쪽에서 보시다시피 사용자가 어떤 특정 질문을 던지게 되고 상담복이 회사에서 가지고 있는 데이터베이스로부터 정보를 받아서 응답을 하는 이런 시나리오를 많이 보여드렸습니다. 근데 생각을 해보시면, 저희가 실습했던 내용을 생각해보시면 저희가 직접 어떤 문서를 봐야 해당 질문에 대해서 답변을 할 수 있는지 직접 그 문서를 골라서 프롬프트에 투입을 해줬던 것으로 기억을 하실 겁니다. 저번 시간에 있던 RAG를 제외하고서는요. 그래서 그 질문에 대해서 답변할 수 있는 문서들은 회사에서 가지고 있는 매뉴얼이라던가 뭐 다양한 정보들이 있을 건데 그 정보들이 상당히 다양하기 때문에 항상 상담복에게 프롬프트에 인풋으로 넣어줄 수는 없을 거고요. 그렇기 때문에 저희는 질문에 따라서 필요한 문서가 어떤 것인지를 검색해서 그 검색된 결과에 따라서 답변을 생성할 수 있는 이런 외부정보 통합 과정을 자동화할 필요성은 상당히 중요하다라고 말씀을 드릴 수 있겠습니다. 그래서 이 과정을 어떻게 할 수 있을까요? 이 데이터베이스와 상담복과의 인터랙션, 상호작용을 어떻게 디자인을 할 수 있을지에 대해서 오늘 강의에서 설명을 드려보도록 하겠습니다. 그래서 검색 시스템에 대해서 알아야 되겠죠? 검색 시스템에 대해서 크게 설명을 드리기 위해서 두 가지 분류를 먼저 나눠서 설명을 드려보겠습니다. 그래서 스팔스 리트리버와 댄스 리트리버, 그러니까 저번 시간에도 설명드렸다시피 검색이라는 단어를 자연어 처리에서는 Retriever, 반환이라는 단어를 쓴다고 말씀을 드렸죠. 그래서 스팔스랑 댄스라는 것을 한국말로 번역을 하기에는 좀 어려워서 그대로 가지고 왔습니다. 그래서 설명을 드려보면요. 첫 번째로 스팔스 리트리버 같은 경우에는 직접적인 키워드의 일치를 통해서 정보를 검색한다라고 말씀드릴 수 있겠습니다. 그래서 지난 시간에 MS문서 기반 답변생성 강의에서 설명드렸다시피 BM25 혹은 TF-IDF 같은 스코어를 통해서 구할 수 있다고 말씀을 드렸습니다. 그래서 여기서 보시게 되면 각각의 워드들에 대한 프리퀀시를 각각의 다큐먼트에서 해당 워드가 몇 번씩 나왔는지, 이렇게 두 번 나왔을 때, 한 번 나왔을 때, 이렇게 매트릭스 행렬 형태로 나타내준 것을 보실 수 있습니다. 그래서 이 매트릭스에서 턴 프리퀀시를 잰 다음에 어떤 그 스코어를 계산하는 과정을 통해서 인덱스를 만든다라고 말씀드릴 수 있겠는데요. 여기에 이 행렬의 특징을 한번 봐주시기 바랍니다. 해당 단어가 등장한 횟수를 얘기했기 때문에 한 번도 등장하지 않은 0이 상당히 많겠죠? 이 워드가 점점 더 많아지고, 이 다큐먼트가 더 다양하다면요. 그래서 이렇게 꽉 차지 않고 0값이 들어가 있는 이런 것들을 좀 촘촘하지 않고 좀 구멍이 펑펑 뚫려있다, 이런 의미로 스팔스 하다라고 말씀을 드릴 수 있겠습니다. 그래서 이 스팔스 리트리버 키워드 검색 같은 경우에는 시스템 자원을 적게 사용하는 효율적인 방법이고요. 하지만 키워드를 기반으로 검색을 하기 때문에 동음 이이어에 대해서 취약하다라고 말씀드릴 수 있겠습니다. 그래서 검색이라는 단어를 가지고 여기에서 체크를 했을 때는 반환이라는 단어를 가지고 오지 못하는 거예요. 의미는 같지만 다른 스트링, 문자로 표현이 되어 있기 때문에 이 스팔스 리트리버 키워드 검색 같은 경우에는 그런 단점을 가진다라고 말씀을 드릴 수 있겠고요. 반면에 댄스 리트리버, 오른쪽에 있는 댄스 리트리버 같은 경우에는 임베딩 벡터 변환을 통해서 이 임베딩 벡터들 간의 유사도를 기반으로 검색을 합니다. 그렇기 때문에 스팔스 리트리버와 반대로 의미적 유사성을 고려할 수 있다라는 장점을 가지고요. 그리고 이 벡터 변환과 유사성 계산에 높은 컴퓨팅 비용이 들어간다라고 말씀을 드릴 수 있겠습니다. 그래서 기본적인 구조를 보시게 되면 먼저 저희가 가지고 있는 검색하고 싶은 대상이 되는 다큐먼트, 문서들을 전부 다 특정 인코더를 활용을 해서 이 각각의 다큐먼트들에 대한 임베딩 벡터로 변환을 시켜놓는다. 이렇게 여러 개를 만들어 놓는다라고 봐주시면 되겠습니다. 그래서 문서를 보통 몇백만 단위로도 만들 수 있고 몇십만 단위로도 만들 수 있을텐데 그런 모든 문서들에 대해서 벡터화를 시킨 벡터라이스드 인덱스라는 것을 어떤 일종의 DB 같은 걸 구성을 해두고요. 여기 중에서 이 쿼리, 지리가 들어왔을 때 이 지리를 똑같이 비슷한 과정으로 이 임베딩 벡터를 만들어줍니다. 그리고 이 임베딩 벡터를 만들어준 다음에 벡터라이스드 인덱스에 있었던 다큐먼트에 대한 임베딩들 간의 유사도를 비교를 해서 가장 유사한 다큐먼트를 반환하는 방식이다. 이렇게 말씀을 드릴 수 있겠습니다. 그래서 이 내용이 많이 어려우실 것으로 좀 예상이 되는데요. 하나씩 먼저 말씀을 드리면 스팔스 리트리벌 같은 경우는 저번에 말씀을 드렸던 TF-IDF를 어떻게 계산하는지에 대해서 설명을 드렸었습니다. 그래서 이 방법을 통해서 스코어를 계산을 하고 스팔스 리트리벌도 마찬가지로 이 스코어를 기반으로 가장 유사한 문서들을 반환을 한다고 말씀을 드릴 수가 있겠고요. 그리고 댄스 리트리벌 같은 경우에는 지금 임베딩이라는 개념에 대해서도 모르시는 분들이 있으실 것 같아서 좀 기본적인 개념부터 한번 짚고 넘어가 보도록 하겠습니다. 그래서 단어 임베딩이라는 것이 있습니다. 그래서 임베딩이 뭐냐라고 좀 이 부분부터 모르실 수 있는데 임베딩이란 머신러닝 분야에서 데이터를 표현하는데 사용되는 고차원의 벡터이다 라고 말씀을 드릴 수 있겠습니다. 그래서 텍스트 이미지 사운드와 같은 복잡한 데이터를 저차원의 수치적 공간에 표현하기 위해 사용된다라고 상당히 어렵게 써져 있는데 그냥 아래의 피규어를 한번 봐주세요. 그래서 여기 오브젝트 1, 오브젝트 2 뭐 이런 것들을 지금 저희는 자연어 처리를 하고 있으니까 하나하나의 단어다라고 생각을 해주세요. 그래서 여기 첫 번째 단어가 애플이다. 그리고 두 번째 단어가 피치, 복숭아다. 그리고 세 번째는 갑자기 패스트 캠퍼스 이렇게 단어가 있다고 생각을 해 볼게요. 그래서 저희는 이러한 단어들을 결국에는 컴퓨터가 연산 가능한 수치적인 값으로 표현을 해줘야지 이 AI 모델들이 이해를 하고 연산을 진행을 하는 과정인 거잖아요. 그러니까 이 단어 텍스트를 수치적 값으로 표현을 해주는 그 과정이 필요합니다. 그래서 그 과정을 임베딩이다. 임베딩을 하는 과정이다 라고 이해를 해주시면 되겠습니다. 그래서 특정 어떤 개체를 컴퓨터가 이해할 수 있는 밸류들의 집합, 값들의 집합 보통은 행렬로 나타나게 되겠죠. 그래서 수치적 행렬들로 표현했다. 수치적 행렬로 전환을 시켰다 라는 것을 임베딩이라고 생각을 해주시고요. 그래서 이 각각이 가지고 있는 숫자들이 어떤 의미를 가지게 되는 거죠. 이 컴퓨팅 하는 데 있어서. 그래서 아까 예를 들었던\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "audio_path = \"/content/drive/MyDrive/데이터/ch0601/CH03-07_sound_cut.mp3\"\n",
    "\n",
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    transcript = openai.Audio.transcribe(\n",
    "        file = audio_file,\n",
    "        model = \"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"ko\",\n",
    "        api_key = OPENAI_API_KEY\n",
    "    )\n",
    "print(transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk3Up8RIohph"
   },
   "source": [
    "##### 2. 문법 교정 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1715500126825,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "90VOEZ_oYh2Z",
    "outputId": "61abb258-0783-49a7-a6e0-24345e26c8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상담복: 상담봇, 스팔스 리트리버: Sparse Retriever, 덴스 리트리버: Dense Retriever, 프리퀀시: Frequency, \n"
     ]
    }
   ],
   "source": [
    "keywords = [\"상담복: 상담봇\", \"스팔스 리트리버: Sparse Retriever\", \"덴스 리트리버: Dense Retriever\", \"프리퀀시: Frequency\"]\n",
    "\n",
    "prompt = \"\"\n",
    "for keyword in keywords:\n",
    "  prompt += keyword + \", \"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25423,
     "status": "ok",
     "timestamp": 1714823032749,
     "user": {
      "displayName": "전병국",
      "userId": "04716627198164050618"
     },
     "user_tz": -540
    },
    "id": "ToZazhVOZWYs",
    "outputId": "48245f06-673d-4bee-bd85-6604f5ca89ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 챕터의 7번째 클립, RAG, 자체 문서를 위한 커스텀 검색 시스템 제작 강의 시작하겠습니다. 먼저 개념에 대해서 설명드리고 실습으로 넘어가도록 하겠습니다. 외부 정보 통합 자동화의 필요성에 대해서 먼저 설명을 드리고 시작을 해보도록 하겠습니다. 그래서 지금까지의 강의에서 계속해서 다뤘던 내용들은 왼쪽에서 보시다시피 사용자가 어떤 특정 질문을 던지게 되고 상담봇이 회사에서 가지고 있는 데이터베이스로부터 정보를 받아서 응답을 하는 이런 시나리오를 많이 보여드렸습니다. 그런데 생각을 해보시면 저희가 실습했던 내용을 생각해보시면 저희가 직접 어떤 문서를 봐야 해당 질문에 대해서 답변을 할 수 있는지 직접 그 문서를 골라서 프롬프트에 투입을 해줬던 것으로 기억하실 겁니다. 저번 시간에 있던 RAG를 제외하고서는요. 그래서 그 질문에 대해서 답변할 수 있는 문서들은 회사에서 가지고 있는 매뉴얼이라던가 다양한 정보들이 있을 건데 그 정보들이 상당히 다양하기 때문에 항상 상담봇에게 프롬프트에 인풋으로 넣어줄 수는 없을 거고요. 그렇기 때문에 저희는 질문에 따라서 필요한 문서가 어떤 것인지를 검색해서 그 검색된 결과에 따라서 답변을 생성할 수 있는 외부 정보 통합 과정을 자동화할 필요성은 상당히 중요하다라고 말씀드릴 수 있겠습니다. 그래서 이 과정을 어떻게 할 수 있을까요? 데이터베이스와 상담봇과의 인터랙션, 상호작용을 어떻게 디자인을 할 수 있을지에 대해서 오늘 강의에서 설명을 드려보도록 하겠습니다. 그래서 검색 시스템에 대해서 알아야 되겠죠? 검색 시스템에 대해서 크게 설명을 드리기 위해서 두 가지 분류를 먼저 나눠서 설명을 드려보겠습니다. 그래서 Sparse Retrieval과 Dense Retrieval, 그러니까 저번 시간에도 설명드렸다시피 검색이라는 단어를 자연어 처리에서는 Retrieval, 반환이라는 단어를 쓴다고 말씀을 드렸죠? 그래서 Sparse랑 Dense라는 것을 한국말로 번역을 하기에는 어려워서 그대로 가지고 왔습니다. 그래서 설명을 드려보면요. 첫 번째로 Sparse Retrieval 같은 경우에는 직접적인 키워드 일치를 통해서 정보를 검색한다라고 말씀드릴 수 있겠습니다. 그래서 지난 시간에, 저번 시간에 MS문서 기반 답변생성 강의에서 설명드렸다시피 BM25 혹은 TF-IDF 같은 스코어를 통해서 구할 수 있다고 말씀을 드렸습니다. 그래서 여기서 보시게 되면 여기 워드, 각각의 워드들에 대한 프리퀀시를 각각의 다큐먼트에서 해당 워드가 몇 번씩 나왔는지, 이렇게 두 번 나왔을 때, 한 번 나왔을 때 이렇게 매트릭스 행렬 형태로 나타내 준 것을 보실 수 있습니다. 그래서 이 매트릭스에서 턴 프리퀀시를 잰 다음에 어떤 그 스코어를 계산하는 과정을 통해서 인덱스를 만든다라고 말씀드릴 수 있겠는데요. 여기에 이 행렬의 특징을 한번 봐주시기 바랍니다. 해당 단어가 등장한 횟수를 얘기했기 때문에 한 번도 등장하지 않은 0이 상당히 많겠죠? 이 워드가 점점 더 많아지고, 이 다큐먼트가 더 다양하다면요. 그래서 이렇게 꽉 차지 않고 0값이 들어가 있는 이런 것들을 좀 촘촘하지 않고, 좀 구멍이 펑펑 뚫려있다, 이런 의미로 스팔스 하다라고 말씀을 드릴 수 있겠습니다. 그래서 이 스팔스 리트리버 키워드 검색 같은 경우에는 시스템 자원을 적게 사용하는 효율적인 방법이고요. 하지만 키워드를 기반으로 검색을 하기 때문에 동음 이의어에 대해서 취약하다라고 말씀드릴 수 있겠습니다. 그래서 검색이라는 단어를 가지고 여기에서 체크를 했을 때는 반환이라는 단어를 가지고 오지 못하는 거예요. 의미는 같지만 다른 스트링, 문자로 표현이 되어 있기 때문에 이 스팔스 리트리버 키워드 검색 같은 경우에는 그런 단점을 가진다라고 말씀을 드릴 수 있겠고요. 반면에 댄스 리트리버, 오른쪽에 있는 댄스 리트리버 같은 경우에는 임베딩 벡터 변환을 통해서 이 임베딩 벡터들 간의 유사도를 기반으로 검색을 합니다. 그렇기 때문에 스팔스 리트리버와 반대로 의미적 유사성을 고려할 수 있다라는 장점을 가지고요. 그리고 이 벡터 변환과 유사성 계산에 높은 컴퓨팅 비용이 들어간다라고 말씀을 드릴 수 있겠습니다. 그래서 기본적인 구조를 보시게 되면 먼저 저희가 가지고 있는 검색하고 싶은 대상이 되는 다큐먼트, 문서들을 전부 다 특정 인코더를 활용을 해서 이 각각의 다큐먼트들에 대한 임베딩 벡터로 변환을 시켜놓는다. 이렇게 여러 개를 만들어 놓는다라고 봐주시면 되겠습니다. 그래서 문서를 보통 몇백만 단위로도 만들 수 있고 몇십만 단위로도 만들 수 있을 텐데 그런 모든 문서들에 대해서 벡터화를 시킨 벡터라이스드 인덱스라는 것을 어떤 일종의 DB 같은 걸 구성을 해두고요. 여기 중에서 이 쿼리, 지리가 들어왔을 때 이 지리를 똑같이, 비슷한 과정으로 이 임베딩 벡터를 만들어줍니다. 그리고 이 임베딩 벡터를 만들어준 다음에 벡터라이스드 인덱스에 있었던 다큐먼트에 대한 임베딩들 간의 유사도를 비교를 해서 가장 유사한 다큐먼트를 반환하는 방식이다. 이렇게 말씀을 드릴 수 있겠습니다. 그래서 이 내용이 많이 어려우실 것으로 예상이 되는데요. 하나씩 먼저 말씀을 드리면 스팔스 리트리벌 같은 경우는 저번에 말씀을 드렸던 TF-IDF를 어떻게 계산하는지에 대해서 설명을 드렸었습니다. 그래서 이 방법을 통해서 스코어를 계산을 하고 스팔스 리트리벌도 마찬가지로 이 스코어를 기반으로 가장 유사한 문서들을 반환을 한다고 말씀을 드릴 수가 있겠고요. 그리고 댄스 리트리벌 같은 경우에는 지금 임베딩이라는 개념에 대해서도 모르시는 분들이 있으실 것 같아서 좀 기본적인 개념부터 한번 짚고 넘어가 보도록 하겠습니다. 그래서 단어 임베딩이라는 것이 있습니다. 그래서 임베딩이 뭐냐라고 좀 이 부분부터 모르실 수 있는데 임베딩이란 머신러닝 분야에서 데이터를 표현하는데 사용되는 고차원의 벡터이다 라고 말씀을 드릴 수 있겠습니다. 그래서 텍스트 이미지 사운드와 같은 복잡한 데이터를 저차원의 수치적 공간에 표현하기 위해 사용된다라고 상당히 어렵게 써져 있는데 그냥 아래의 피규어를 한번 봐주세요. 그래서 여기 오브젝트 1, 오브젝트 2 뭐 이런 것들을 지금 저희는 자연어 처리를 하고 있으니까 하나하나의 단어다라고 생각을 해주세요. 그래서 뭐 여기 첫 번째 단어가 애플이다. 그리고 두 번째 단어가 피치, 복숭아다. 그리고 세 번째는 갑자기 패스트 캠퍼스 뭐 이렇게 단어가 있다고 생각을 해 볼게요. 그래서 저희는 이러한 단어들을 결국에는 컴퓨터가 연산 가능한 수치적인 값으로 표현을 해줘야지 이 AI 모델들이 이해를 하고 연산을 진행을 하는 과정인 거잖아요. 그러니까 이 단어 텍스트를 수치적 값으로 표현을 해주는 그 과정이 필요합니다. 그 과정을 임베딩이다. 임베딩을 하는 과정이다. 라고 이해를 해주시면 되겠습니다. 그래서 특정 어떤 개체를 컴퓨터가 이해할 수 있는 밸류들의 집합, 값들의 집합 보통은 행렬로 나타나게 되겠죠. 그래서 이게 행렬의 수치적 행렬들로 표현했다. 수치적 행렬로 전환을 시켰다라는 것을 임베딩이라고 생각을 해주시고요. 그래서 이 각각의 가지고 있는 숫자들이 어떤 의미를 가지게 되는 거죠. 컴퓨팅 하는 데 있어서. 그래서 아까 예를 들었던\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(audio_path, \"rb\") as audio_file:\n",
    "    transcript = openai.Audio.transcribe(\n",
    "        prompt=prompt,\n",
    "        file = audio_file,\n",
    "        model = \"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"ko\",\n",
    "        api_key = OPENAI_API_KEY\n",
    "    )\n",
    "print(transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1txC0Jj8Tji"
   },
   "source": [
    "### 영어에서 가능한 설정들\n",
    "- 스타일 변화 주기: in casual style\n",
    "- separator 설정: Instead of periods, end every sentence with elipses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2CYnG7jokPL"
   },
   "source": [
    "##### 3. 언어 모델을 이용하여 STT 결과 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1715500250574,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "T9bFMx8VbCzN",
    "outputId": "971c479f-3cfe-40a4-9d35-92315cffb0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 무엇을 도와드릴까요? :)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"안녕하세요\"}],\n",
    "    api_key = OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(chat_completion[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1715500297560,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "vfwFrLFebt8Y",
    "outputId": "7f8b9594-5c92-40ed-dd7d-179ac870a404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "아래 내용은 사용자의 음성을 텍스트로 변환한 내용입니다.\n",
      "\n",
      "내용을 요약해 주세요.\n",
      "\n",
      "내용: {투입될 텍스트가 입력될 자리입니다}\n",
      "요약:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from string import Template\n",
    "\n",
    "summary_prompt = Template(\"\"\"\n",
    "아래 내용은 사용자의 음성을 텍스트로 변환한 내용입니다.\n",
    "\n",
    "내용을 요약해 주세요.\n",
    "\n",
    "내용: $input\n",
    "요약:\n",
    "\"\"\")\n",
    "\n",
    "print(summary_prompt.substitute(input=\"{투입될 텍스트가 입력될 자리입니다}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30152,
     "status": "ok",
     "timestamp": 1715500342509,
     "user": {
      "displayName": "Gangwoo Kim",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "LrTGlelCZuzr",
    "outputId": "516fda63-8526-4393-ad09-fb46006be6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번째 챕터의 7번째 클립에서는 RAG 자체 문서를 위한 커스텀 검색 시스템 제작 강의가 시작됩니다. 외부 정보 통합 자동화의 필요성을 강조하며, 스팔스 리트리버와 댄스 리트리버를 통해 검색 시스템의 두 가지 분류를 설명합니다. 스팔스 리트리버는 직접적인 키워드 일치를 통해 검색하고, 댄스 리트리버는 임베딩 벡터를 통해 의미적 유사성을 고려한 검색을 합니다. 임베딩은 데이터를 저차원 수치적 벡터로 표현하는 과정이며, 컴퓨터가 이해할 수 있는 값으로 표현하는 과정이라고 설명됩니다.\n"
     ]
    }
   ],
   "source": [
    "def summary_voice(voice_path):\n",
    "  with open(audio_path, \"rb\") as audio_file:\n",
    "    transcript = openai.Audio.transcribe(\n",
    "        prompt=prompt,\n",
    "        file = audio_file,\n",
    "        model = \"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"ko\",\n",
    "        api_key = OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "  chat_completion = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=[{\"role\": \"user\", \"content\": summary_prompt.substitute(input=transcript)}],\n",
    "      api_key = OPENAI_API_KEY\n",
    "  )\n",
    "\n",
    "  return chat_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(summary_voice(\"/content/drive/MyDrive/데이터/ch0601/CH03-07_sound_cut.mp3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-jC9RZGYoM7"
   },
   "source": [
    "**Reference**\n",
    "\n",
    "https://cookbook.openai.com/examples/whisper_prompting_guide"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
