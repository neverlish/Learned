import streamlit as st
import asyncio
from utils import llm_call_async

# ë³‘ë ¬ ì²˜ë¦¬ í•¨ìˆ˜ ê°œì„ 
async def run_llm_parallel(prompt_details):

    tasks = [
        llm_call_async(prompt["user_prompt"], prompt["model"])
        for prompt in prompt_details
    ]
    responses = []

    for task in asyncio.as_completed(tasks):
        result = await task
        responses.append(result)

    # ìµìŠ¤íœë”ì— ëª¨ë“  ì‘ë‹µ í¬í•¨
    with st.expander("ëª¨ë¸ ì‘ë‹µ ì „ì²´ ë³´ê¸°"):
        for response in responses:
            st.markdown(f" ëª¨ë¸ ì‘ë‹µ: {response}")

    return responses

# ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜ ì„ ì–¸
async def run_parallel_agent(question, selected_models):
    parallel_prompt_details = [
        {"user_prompt": question, "model": model} for model in selected_models
    ]

    responses = await run_llm_parallel(parallel_prompt_details)

    aggregator_prompt = (
        "ë‹¤ìŒì€ ì—¬ëŸ¬ LLMì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìƒì„±í•œ ì‘ë‹µì´ì•¼.\n"
        "ë„ˆì˜ ì—­í• ì€ ì´ ì‘ë‹µì„ ëª¨ë‘ ì¢…í•©í•´ ìµœì¢… ë²ˆì—­ë¬¸ì„ ì œê³µí•˜ëŠ” ê±°ì•¼.\n"
        "ì¼ë¶€ ì‘ë‹µì´ ë¶€ì •í™•í•˜ê±°ë‚˜ í¸í–¥ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì‹ ë¢°ì„± ìˆê³  ì •í™•í•œ ë‹µë³€ì„ í•´ì¤˜.\n"
        "ìµœì¢… ì‘ë‹µë§Œ ì¶œë ¥í•´.\n"
        "ì‚¬ìš©ì ì§ˆë¬¸:\n"
        f"{question}\n\n"
        "ëª¨ë¸ ì‘ë‹µ:"
    )
    for i in range(len(parallel_prompt_details)):
        aggregator_prompt += f"\n{i+1}. ëª¨ë¸ ì‘ë‹µ: {responses[i]}\n"

    with st.expander("ìµœì¢… í”„ë¡¬í”„íŠ¸ ë³´ê¸°", expanded=False):
        st.code(aggregator_prompt, language='markdown')

    final_response = await llm_call_async(aggregator_prompt, model="gpt-4o")
    st.subheader("ìµœì¢… ì‘ë‹µ")
    st.markdown(final_response)

def main():
    st.title("ë³‘ë ¬ ì²˜ë¦¬ ì—ì´ì „íŠ¸")

    # ì§ˆë¬¸ ì…ë ¥ ë° ëª¨ë¸ ìœ„ì ¯ ì„¤ì •
    question = st.text_area(
        "âœ ì‚¬ìš©ì ì§ˆë¬¸",
        height = 100,
        value = """ì•„ë˜ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜.
"Do what you can, with what you have, where you are." â€” Theodore Roosevelt
""")
    model_options = ["gpt-4o", "gpt-4o-mini", "o3"]
    selected_models = st.multiselect(
        "ğŸ” ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.",
        model_options,
        default = model_options[:3]
    )

# ì—ì´ì „íŠ¸ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ì—ì´ì „íŠ¸ ì‹¤í–‰"):
        if not question.strip():
            st.warning("â— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        elif not selected_models:
            st.warning("â— í•œ ê°€ì§€ ì´ìƒì˜ ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            asyncio.run(run_parallel_agent(question.strip(), selected_models))

if __name__ == "__main__":
    main()