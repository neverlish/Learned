{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3895dc92-227d-4d19-bb2c-4f42a9cf1eaa",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a8bfbf-3475-4a35-8781-40f5e0a572ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2dacc-cb63-4024-9ba6-52e759f6aa1c",
   "metadata": {},
   "source": [
    "## Text Completion models - DEPRECATED - we will just use ChatModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f27cb37a-24e4-4263-b139-c5cda7f1e8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/.pyenv/versions/3.9.18/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8f44c9-408e-46b3-88f4-15b6efecccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy don't scientists trust atoms? \\n\\nBecause they make up everything.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Tell me a joke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b089bdb-7fcc-4222-a68b-f13edd20de27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy don't scientists trust atoms? Because they make up everything.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(input=\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d340b5-6c8a-4f0c-9ca7-b040487e3008",
   "metadata": {},
   "source": [
    "Batch Processing - Make multiple requests at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb59873a-e8ed-4bb6-a31f-8231e6189617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\nWhy did the cow cross the road?\\n\\nTo get to the moooo-vies!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nWhy did the parrot go to the doctor?\\n\\nBecause it was feeling a little \"polly\" !', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 13, 'total_tokens': 54, 'completion_tokens': 41}, 'model_name': 'gpt-3.5-turbo-instruct'} run=[RunInfo(run_id=UUID('a137b3eb-16a0-4d4f-8605-69c204a54af7')), RunInfo(run_id=UUID('09f32994-b565-493b-891b-4b15e3ea4c76'))]\n"
     ]
    }
   ],
   "source": [
    "result = llm.generate([\"Tell me a joke about cows\", \"Tell me a joke about parrots\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5abee8-afb7-4edf-aa81-3b3e8c556d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 13,\n",
       "  'total_tokens': 54,\n",
       "  'completion_tokens': 41},\n",
       " 'model_name': 'gpt-3.5-turbo-instruct'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f0d6b-fd9a-4ef5-9e6f-b26b52cbc29c",
   "metadata": {},
   "source": [
    "## Creating a conversation with SystemMessage, AIMessage and SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7bd5f1c-41f8-4198-9050-7eefc138d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4154f6-b6f5-4f7c-81e3-f1d45874347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Why did the cow go to outer space?\\n\\nTo find the udder side of the moon!' response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 13, 'total_tokens': 33}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None} id='run-1b161495-0eba-4ff2-a2ec-511e4169ce8b-0'\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Tell me a joke about cows\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f42830-bfff-439b-aeeb-984e8e14ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant specialized in providing information about BellaVista Italian Restaurant.\"),\n",
    "    HumanMessage(content=\"What's on the menu?\"),\n",
    "    AIMessage(content=\"BellaVista offers a variety of Italian dishes including pasta, pizza, and seafood.\"),\n",
    "    HumanMessage(content=\"Do you have vegan options?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494ebfdf-bbdb-4236-913a-27a98d18e256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, BellaVista Italian Restaurant offers a selection of vegan options on their menu. Some popular choices include vegan pasta dishes, salads, and vegetable-based pizzas. Please check with the restaurant for specific vegan options available.', response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 65, 'total_tokens': 108}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-97f934ca-292f-426b-aec0-bec44ff79acb-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result = llm.invoke(input=messages)\n",
    "llm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f34415e-668e-4b9f-9c32-654611713018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Haben Sie vegane Optionen?', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Haben Sie vegane Optionen?', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 27, 'total_tokens': 35}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-a214ad27-ade3-482f-a2be-15b744950d52-0'))], [ChatGeneration(text='¿Tiene opciones veganas?', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='¿Tiene opciones veganas?', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 29, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-96bf85f6-f824-4219-81e9-2b6a6f175309-0'))]], llm_output={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 56, 'total_tokens': 71}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8'}, run=[RunInfo(run_id=UUID('a214ad27-ade3-482f-a2be-15b744950d52')), RunInfo(run_id=UUID('96bf85f6-f824-4219-81e9-2b6a6f175309'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to German\"),\n",
    "        HumanMessage(content=\"Do you have vegan options?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates the English to Spanish.\"),\n",
    "        HumanMessage(content=\"Do you have vegan options?\")\n",
    "    ],\n",
    "]\n",
    "batch_result = llm.generate(batch_messages)\n",
    "batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4021c360-6b02-4185-86a0-d5d4be134607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Haben Sie vegane Optionen?', '¿Tiene opciones veganas?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = [generation[0].text for generation in batch_result.generations]\n",
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fd572-03cc-40f1-9ef0-39a5dc7751e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
