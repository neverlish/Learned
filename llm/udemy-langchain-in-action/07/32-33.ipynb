{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef724e70-0e74-46af-8151-67a729cb2467",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba65fe75-10d1-4a59-bcc3-ddebb678007a",
   "metadata": {},
   "source": [
    "The newer OpenAI Function Calling Functionality allows to to define functions which will be passed to the LLM. The LLM will identify the correct function for the request and provide parameters for the function call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3836e938-ab94-478e-ba84-bc4b7817cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85decbc8-3c2b-4acc-aaf0-84747921ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def chat(query):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f65ad2f-f867-4ccd-ad35-1ec5c56a2e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cost of pizza salami can vary depending on the size of the pizza, the restaurant or store it is purchased from, and the region. On average, a medium-sized pizza with salami toppings can cost around $10 to $15.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf9126-c03d-40a0-826a-a7e9fddc7cd6",
   "metadata": {},
   "source": [
    "To make use of Function calling you need:\n",
    "\n",
    "1. A function\n",
    "2. A dictionary which describes the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283f5b22-a345-4687-9afc-8798f3809855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_pizza_info(pizza_name: str):\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return json.dumps(pizza_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ec236e-d858-4e37-9f63-23754317f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_pizza_info\",\n",
    "        \"description\": \"Get name and price of a pizza of the restaurant\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pizza_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the pizza, e.g. Salami\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"pizza_name\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531cdad5-d5bb-412b-a087-3a78783e21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        functions=functions, # this is new\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0166ec97-3145-4da8-af04-f081223f5046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the capital of france?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceee0502-5dfb-42e8-8de7-f6ca9721b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"pizza_name\":\"Salami\"}', name='get_pizza_info'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183b0ffd-224f-449b-a215-43d7ad64231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salami\n",
      "{\"name\": \"Salami\", \"price\": \"10.99\"}\n"
     ]
    }
   ],
   "source": [
    "if message.function_call:\n",
    "    pizza_name = json.loads(message.function_call.arguments).get(\"pizza_name\")\n",
    "    print(pizza_name)\n",
    "    function_response = get_pizza_info(\n",
    "        pizza_name=pizza_name\n",
    "    )\n",
    "    print(function_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebad8e75-22cc-45dd-9a42-fe7ffe917b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9BHDTYvmThdpekNN3Mvl3TU5xL7Tq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The cost of a pizza salami is $10.99.', role='assistant', function_call=None, tool_calls=None))], created=1712474815, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=55, total_tokens=68))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_pizza_info\",\n",
    "            \"content\": function_response,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27059918-bdb1-4d22-85bc-a89c9ae06c43",
   "metadata": {},
   "source": [
    "The same can be achieved with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410f6a1d-562e-4d79-83f7-1f6af0dcb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.openai_functions import create_openai_fn_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a07b76d-b59c-4f22-9deb-ecc755291437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/.pyenv/versions/3.9.18/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `create_openai_fn_chain` was deprecated in LangChain 0.1.1 and will be removed in 0.2.0. Use create_openai_fn_runnable instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template = \"\"\"You are an AI chatbot having a conversation with a human.\n",
    "\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"human_input\"], template=template)\n",
    "\n",
    "chain = create_openai_fn_chain(functions, llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc245db9-bd15-46fd-9344-36a7fb513f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/.pyenv/versions/3.9.18/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pizza_name': 'Salami'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f446bf-0139-46da-9c12-46d20186c7cb",
   "metadata": {},
   "source": [
    "We can also use Pydantic Classes instead of JSON Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a0b5b1-28b2-4e05-9f09-3125bfa43721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetPizzaInfo(BaseModel):\n",
    "    \"\"\"Get name and price of a pizza of the restaurant.\"\"\"\n",
    "\n",
    "    pizza_name: str = Field(..., description=\"The name of the pizza, e.g. Salami\")\n",
    "\n",
    "pydantic_classes = [GetPizzaInfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42066906-aab4-4907-9e10-237cc9b5098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_openai_fn_chain(pydantic_classes, llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54afed4a-a3d1-4237-bfb5-d1c9213418ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pizza_name': 'salami'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97415961-4858-48d8-906a-6ec4e1289e3f",
   "metadata": {},
   "source": [
    "We can also pass Functions directly. To pass Python function in directly, we'll want to make sure our parameters have type hints, we have a docstring, and we use Google Python style docstrings to describe the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd0ee1af-7707-492e-8b86-eddf006108e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pizza_info(pizza_name: str) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Get name and price of a pizza of the restaurant.\n",
    "\n",
    "    Args:\n",
    "        pizza_name: The name of the pizza, e.g. Salami.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the name and price of the pizza.\n",
    "    \"\"\"\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return pizza_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab5516aa-3279-49f4-8d20-f6d1ee5ebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_openai_fn_chain([get_pizza_info], llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a939d705-4bb4-4bd0-9d48-d0f3912b32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pizza_name': 'Salami'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3a17f-695b-45bc-bdab-28b1b3d7d655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
