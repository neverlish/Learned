{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b65012-8b10-4652-b432-70a471c775f9",
   "metadata": {},
   "source": [
    "# Chains with multiple inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff13a0f8-9854-4639-b8df-b215f9fa1d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e7f907-16f2-442b-8eba-fd1e3b1ee9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'text': 'Why did the parrot wear a raincoat?\\n\\nBecause he wanted to be polyunsaturated!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke(input=\"a parrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf39910-598b-488d-bff4-e2db0a97151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'a parrot',\n",
       " 'language': 'german',\n",
       " 'text': 'Warum hat der Papagei den Bus verpasst?\\n\\nWeil er noch schnell einen Vogel hatte!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(input_variables=[\"input\", \"language\"], template=\"Tell me a joke about {input} in {language}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.invoke({\"input\": \"a parrot\", \"language\": \"german\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978c532-c86a-450a-b6e3-bd5eefcd8d02",
   "metadata": {},
   "source": [
    "Chains can be more complex and not all sequential chains will be as simple as passing a single string as an argument and getting a single string as output for all steps in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ed0fad-ee6d-4443-86aa-b182111cd0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# This is an LLMChain to write a review given a dish name and the experience.\n",
    "prompt_review = PromptTemplate.from_template(\n",
    "    template=\"You ordered {dish_name} and your experience was {experience}. Write a review: \"\n",
    ")\n",
    "chain_review = LLMChain(llm=llm, prompt=prompt_review, output_key=\"review\")\n",
    "\n",
    "# This is an LLMChain to write a follow-up comment given the restaurant review.\n",
    "prompt_comment = PromptTemplate.from_template(\n",
    "    template=\"Given the restaurant review: {review}, write a follow-up comment: \"\n",
    ")\n",
    "chain_comment = LLMChain(llm=llm, prompt=prompt_comment, output_key=\"comment\")\n",
    "\n",
    "# This is an LLMChain to summarize a review.\n",
    "prompt_summary = PromptTemplate.from_template(\n",
    "    template=\"Summarise the review in one short sentence: \\n\\n {comment}\"\n",
    ")\n",
    "chain_summary = LLMChain(llm=llm, prompt=prompt_summary, output_key=\"summary\")\n",
    "\n",
    "# This is an LLMChain to translate a summary into German.\n",
    "prompt_translation = PromptTemplate.from_template(\n",
    "    template=\"Translate the summary to german: \\n\\n {summary}\"\n",
    ")\n",
    "chain_translation = LLMChain(\n",
    "    llm=llm, prompt=prompt_translation, output_key=\"german_translation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e468ee3b-d3cf-4cca-bca1-2de80aaae636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dish_name': 'Pizza Salami',\n",
       " 'experience': 'It was awful!',\n",
       " 'review': 'I recently ordered the Pizza Salami from this restaurant and I have to say, it was absolutely awful. The pizza arrived cold and soggy, with barely any toppings on it. The salami was barely noticeable and tasted like it had been sitting out for hours.\\n\\nThe crust was overcooked and tasted like cardboard. I was extremely disappointed with the quality of the pizza, especially considering the price I paid for it.\\n\\nOverall, I would not recommend ordering the Pizza Salami from this restaurant. Save your money and go somewhere else for a better pizza experience.',\n",
       " 'comment': \"I had a similar experience when I ordered the Pizza Salami from this restaurant. The quality was definitely not up to par and I was very disappointed. I agree that the toppings were sparse and the salami was barely there.\\n\\nI also found the crust to be overcooked and lacking in flavor. It's a shame because I had heard good things about this place before trying it myself. I definitely won't be ordering from here again and would recommend others to do the same. There are plenty of other pizza places that offer a much better experience for the price.\",\n",
       " 'summary': 'The reviewer had a disappointing experience with the Pizza Salami from this restaurant, citing sparse toppings, barely-there salami, overcooked crust, and lack of flavor, and advises against ordering from here again.',\n",
       " 'german_translation': 'Der Rezensent hatte eine enttäuschende Erfahrung mit der Pizza Salami aus diesem Restaurant, bemängelte spärliche Beläge, kaum vorhandene Salami, überbackenen Teig und mangelnden Geschmack und rät davon ab, hier erneut zu bestellen.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_review, chain_comment, chain_summary, chain_translation],\n",
    "    input_variables=[\"dish_name\", \"experience\"],\n",
    "    output_variables=[\"review\", \"comment\", \"summary\", \"german_translation\"],\n",
    ")\n",
    "\n",
    "overall_chain.invoke({\"dish_name\": \"Pizza Salami\", \"experience\": \"It was awful!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8f0ac-8aff-4686-b727-e31f8dc34bed",
   "metadata": {},
   "source": [
    "Instead of chaining multiple chains together we can also use an LLM to decide which follow up chain is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705f46a6-48c9-44a7-8f3f-69f5dbbad3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "positive_template = \"\"\"You are an AI that focuses on the positive side of things. \\\n",
    "Whenever you analyze a text, you look for the positive aspects and highlight them. \\\n",
    "Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template = \"\"\"You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, \\\n",
    "not favoring any positive or negative aspects. Here is the text:\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template = \"\"\"You are an AI that is designed to find the negative aspects in a text. \\\n",
    "You analyze a text and show the potential downsides. Here is the text:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb1891f-9e4b-4fdf-86db-b93ae483023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive\",\n",
    "        \"description\": \"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\": positive_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"neutral\",\n",
    "        \"description\": \"Good for analyzing neutral sentiments\",\n",
    "        \"prompt_template\": neutral_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative\",\n",
    "        \"description\": \"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\": negative_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c2208f-1943-44c0-a88f-1115ede2ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='You are an AI that focuses on the positive side of things. Whenever you analyze a text, you look for the positive aspects and highlight them. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x107b29e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107b3c3a0>, openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'neutral': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='You are an AI that has a neutral perspective. You just provide a balanced analysis of the text, not favoring any positive or negative aspects. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x107b29e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107b3c3a0>, openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'negative': LLMChain(prompt=PromptTemplate(input_variables=['input'], template='You are an AI that is designed to find the negative aspects in a text. You analyze a text and show the potential downsides. Here is the text:\\n{input}'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x107b29e50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x107b3c3a0>, openai_api_key=SecretStr('**********'), openai_proxy=''))}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d705952a-8df9-4ebc-b648-97dc0f45cf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive: Good for analyzing positive sentiments\n",
      "neutral: Good for analyzing neutral sentiments\n",
      "negative: Good for analyzing negative sentiments\n"
     ]
    }
   ],
   "source": [
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcdcb00-ffe8-4c6d-a70c-3e1310b7f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "positive: {'input': 'I ordered Pizza Salami for 9.99$ and it was awesome!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I ordered Pizza Salami for 9.99$ and it was awesome!',\n",
       " 'text': \"That's great to hear! It sounds like you enjoyed a delicious Pizza Salami at a reasonable price. It's always nice to treat yourself to a tasty meal.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=destination_chains[\"neutral\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.invoke({\"input\": \"I ordered Pizza Salami for 9.99$ and it was awesome!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ed7ef-6bff-4c76-a51a-fd948385ff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
