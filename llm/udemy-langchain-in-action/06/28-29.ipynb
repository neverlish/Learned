{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c96f40-4148-4dd4-b53e-5ddc0d8a2795",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea9c04-501b-45a0-8a95-38c00fe2b35f",
   "metadata": {},
   "source": [
    "In some applications like chatbots, it is important to remember previous interactions to keep the whole context of a conversation. Memory does provide you an easy way to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152104a1-7634-4afc-a74c-714e504e34bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d75bff-b1d4-4ee1-b2e3-de806aecba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='hello my friend!')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"hello my friend!\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5f2c78-df30-4f56-9054-18bc9fe83022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"hello my friend!\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499e7bbc-65a6-4162-88f5-2634be1fdf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What is the capital of France?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'history': '',\n",
       " 'response': 'The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, and cuisine.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=ConversationBufferMemory()\n",
    ")\n",
    "conversation.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578a7699-da39-430b-9ae0-e1085d70cb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, and cuisine.\n",
      "Human: Whats the best food there?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the best food there?',\n",
       " 'history': 'Human: What is the capital of France?\\nAI: The capital of France is Paris. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. Paris is also famous for its fashion, art, and cuisine.',\n",
       " 'response': 'Some popular French dishes in Paris include croissants, escargot, coq au vin, ratatouille, and crème brûlée. French cuisine is known for its use of fresh ingredients and rich flavors. There are also many Michelin-starred restaurants in Paris for fine dining experiences.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Whats the best food there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8b173-9039-4224-beee-ec11d094a568",
   "metadata": {},
   "source": [
    "# ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2564fc-29de-4c43-96d0-a30c3c7f5aad",
   "metadata": {},
   "source": [
    "When inputs get long, we might not want to send the whole conversation, but rather a summary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4740f7bb-436d-4c94-a44a-cdb6ab323562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "review = \"I ordered Pizza Salami for 9.99$ and it was awesome! \\\n",
    "The pizza was delivered on time and was still hot when I received it. \\\n",
    "The crust was thin and crispy, and the toppings were fresh and flavorful. \\\n",
    "The Salami was well-cooked and complemented the cheese perfectly. \\\n",
    "The price was reasonable and I believe I got my money's worth. \\\n",
    "Overall, I am very satisfied with my order and I would recommend this pizza place to others.\"\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) # If Token is 1000, no summary will be created\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Hello, how can I help you today?\"},\n",
    "    {\"output\": \"Could you analyze a review for me?\"},\n",
    ")\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Sure, I'd be happy to. Could you provide the review?\"},\n",
    "    {\"output\": f\"{review}\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9159c75c-e99b-403b-9d71-42f3f83aeeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human offers to help the AI and asks how they can assist. The AI requests an analysis of a review and the human agrees to help, asking for the review to be provided.\n",
      "AI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\n",
      "Human: Thank you very much!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Thank you very much!',\n",
       " 'history': \"System: The human offers to help the AI and asks how they can assist. The AI requests an analysis of a review and the human agrees to help, asking for the review to be provided.\\nAI: I ordered Pizza Salami for 9.99$ and it was awesome! The pizza was delivered on time and was still hot when I received it. The crust was thin and crispy, and the toppings were fresh and flavorful. The Salami was well-cooked and complemented the cheese perfectly. The price was reasonable and I believe I got my money's worth. Overall, I am very satisfied with my order and I would recommend this pizza place to others.\",\n",
       " 'response': \"You're welcome! I'm glad I could share my review with you. If you have any other questions or need more information, feel free to ask.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.invoke(\"Thank you very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2802afa-835d-4472-9827-e5af5bd84528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: hello my friend!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b09ab1-b156-4932-872b-3300818ac6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
