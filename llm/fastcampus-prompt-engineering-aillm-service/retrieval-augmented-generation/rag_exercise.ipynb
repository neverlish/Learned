{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG와 LLM을 활용한 질의응답 실습\n",
    "- LLM API 호출 시 RAG를 통해 연관 정보 추출 후 Prompt에 추가하는 실습\n",
    "- RAG 추가 전후로 평가 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./res/rag_data.pkl', 'rb') as f:\n",
    "    rag_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = rag_data['questions'][:10]\n",
    "contexts = rag_data['contexts'][:10]\n",
    "answers = rag_data['answers'][:10]\n",
    "len(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가\n",
    "- RAGAS의 Answer Correctedness 평가 지표\n",
    "  - 모델의 답변과 실제 정답 간의 일치율 측정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline (w/o RAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:05<00:00,  6.55s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    prompt = f\"\"\"You are an expert in Finance. Please answer to the question given below.\n",
    "    \n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/retrieval-augmented-generation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Evaluating: 100%|██████████| 10/10 [00:33<00:00,  3.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_correctness': 0.3855}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness\n",
    "\n",
    "\n",
    "data_samples = {\n",
    "    'question': questions,\n",
    "    'answer': predictions,\n",
    "    'ground_truth': answers\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "score = evaluate(dataset, metrics=[answer_correctness])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글로벌 저금리 현상이 부각된 원인은 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글로벌 저금리 현상이 부각된 원인에는 여러 가지 요인이 복합적으로 작용하고 있습니다. 주요 원인들을 살펴보면 다음과 같습니다:\n",
      "\n",
      "1. **경제 성장 둔화**: 많은 선진국들이 경제 성장률이 둔화되고 있습니다. 경제 성장이 둔화되면 중앙은행들은 경제를 자극하기 위해 금리를 낮추는 경향이 있습니다.\n",
      "\n",
      "2. **인구 고령화**: 인구 고령화는 저축률을 높이고 소비를 줄이는 경향이 있습니다. 이는 자본의 공급을 증가시키고, 자본에 대한 수요를 감소시켜 금리를 낮추는 요인으로 작용합니다.\n",
      "\n",
      "3. **기술 발전**: 기술 발전은 생산성을 높이고, 비용을 절감하며, 인플레이션을 억제하는 효과가 있습니다. 이는 중앙은행들이 금리를 낮게 유지할 수 있는 환경을 조성합니다.\n",
      "\n",
      "4. **글로벌화**: 글로벌화는 자본의 이동을 자유롭게 하고, 전 세계적으로 자본 공급을 증가시킵니다. 이는 금리를 낮추는 요인으로 작용합니다.\n",
      "\n",
      "5. **중앙은행의 통화 정책**: 2008년 금융위기 이후 많은 중앙은행들이 양적 완화(QE)와 같은 비전통적인 통화 정책을 도입하여 금리를 낮추고 유동성을 공급했습니다. 이러한 정책들은 장기적으로 저금리 환경을 조성하는 데 기여했습니다.\n",
      "\n",
      "6. **안전 자산에 대한 수요 증가**: 경제 불확실성과 금융 시장의 변동성 증가로 인해 투자자들은 안전 자산(예: 국채)에 대한 수요가 증가했습니다. 이는 국채 금리를 낮추는 요인으로 작용합니다.\n",
      "\n",
      "7. **부채 수준 증가**: 많은 국가들이 높은 부채 수준을 유지하고 있으며, 이는 금리를 낮게 유지해야 하는 압력으로 작용합니다. 높은 금리는 부채 상환 부담을 증가시키기 때문입니다.\n",
      "\n",
      "이러한 요인들이 복합적으로 작용하여 글로벌 저금리 현상이 지속되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM + RAG\n",
    "- text-embedding-3-large 임베딩 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:59<00:00,  5.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import call_openai, get_embeddings, cosine_similarity\n",
    "\n",
    "\n",
    "def retrieve_context(question, contexts):\n",
    "    question_embedding = get_embeddings([question], model='text-embedding-3-large')[0]\n",
    "    context_embeddings = get_embeddings(contexts, model='text-embedding-3-large')\n",
    "\n",
    "    similarities = [cosine_similarity(question_embedding, context_embedding) for context_embedding in context_embeddings]\n",
    "\n",
    "    most_relevant_index = np.argmax(similarities)\n",
    "    return contexts[most_relevant_index]\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    context = retrieve_context(questions[i], contexts[i])\n",
    "    prompt = f\"\"\"You are an expert in Finance. Please answer to the question given below. Use information given in Context appropriately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{questions[i]}\n",
    "\"\"\"\n",
    "    prediction = call_openai(prompt, model='gpt-4o-2024-05-13')\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'context_relevancy' from 'ragas.metrics' (/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/retrieval-augmented-generation/.venv/lib/python3.11/site-packages/ragas/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m faithfulness, answer_correctness, context_relevancy, context_recall, context_precision\n\u001b[1;32m      6\u001b[0m data_samples \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: questions,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m: answers\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict(data_samples)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'context_relevancy' from 'ragas.metrics' (/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/retrieval-augmented-generation/.venv/lib/python3.11/site-packages/ragas/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_correctness, context_recall, context_precision\n",
    "\n",
    "\n",
    "data_samples = {\n",
    "    'question': questions,\n",
    "    'answer': predictions,\n",
    "    'ground_truth': answers\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "score = evaluate(dataset, metrics=[answer_correctness])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
