{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "# Guardrails (공식 용어는 아니고 자주 사용되는 편)\n",
    "- 안전 장치에는 사실 모델 학습 단계 내 Alignment 과정이 가장 중요\n",
    "\n",
    "모델 학습 단계 이후에 안전 장치를 적용하는 방법\n",
    "\n",
    "1. Prompt 내\n",
    "1. API 내 기능\n",
    "1. 별도의 Guardrail 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt 내 guardrail 가이드라인 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cookbook.openai.com/examples/how_to_use_guardrails 코드를 수정\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "\n",
    "def topical_guardrail(user_request):\n",
    "    print(\"Checking topical guardrail\")\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Your role is to assess whether the user question is allowed or not. The allowed topics are cats and dogs. If the topic is allowed, say 'allowed' otherwise say 'not_allowed'\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ]\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo-0125',\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    print(\"Got guardrail response\")\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'allowed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "bad_request = \"I want to talk about horses\"\n",
    "good_request = \"What are the best breeds of dog for people that like cats?\"\n",
    "\n",
    "topical_guardrail(good_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking topical guardrail\n",
      "Got guardrail response\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not_allowed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topical_guardrail(bad_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API 내 기능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송합니다. 사람을 죽이는 방법을 알려줄 수 없습니다. 나는 사람을 해치는 데 사용될 수 있는 정보를 제공하지 않습니다. 도움이 필요하면 전문가에게 연락하십시오.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://ai.google.dev/gemini-api/docs/safety-settings?hl=ko\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "prompt = '사람을 죽이는 10가지 방법을 알려줘'\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "client = genai.GenerativeModel('gemini-1.5-flash-001')\n",
    "response = client.generate_content(\n",
    "    contents=prompt,\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 고기랑 술 왕창 먹고 먹튀한 거 봤어?\n",
      "P02: 먹었으면 돈을 내야지\n",
      "P02: 그게 뭐야...\n",
      "P03: 왜 그러는거야 대체?\n",
      "P03: 못된 심보군 키키\n",
      "P01: 내 말이\n",
      "P01: 돈을 떠나서 괘씸하다 키키\n",
      "P02: 대박이네\n",
      "P02: 요즘 세상에 그런 생각도 하고 키키\n",
      "P03: 진짜 돈을 많이 줘도 치우기 싫을 듯 키키\n",
      "P01: 그러게\n",
      "P01: 자영업자 가뜩이나 힘든데 ㅠㅠ\n",
      "P02: 그니까 ㅠㅠ\n",
      "P02: 진짜 나쁜 사람들 많아\n",
      "P03: 그니까\n",
      "P03: 숙박업소 사장님은 무슨 죄야 ㅠㅠ\n",
      "P01: 키키 숙박업소 아니야\n",
      "P01: 고깃집 사장님이야\n",
      "P02: 맞아 키키\n",
      "P02: 너 기사 대충 읽었지~?\n",
      "P03: 아 진짜? 키키\n",
      "P03: 나는 펜션 말하는 줄 키키\n",
      "P01: 노노\n",
      "P01: 저 작은 가게에서 엄청 나게 먹어 댔네\n",
      "P02: 아주 그냥 식성이 좋은 사람들이네 키키\n",
      "P03: 한번 찾아봐야겠네 키키\n",
      "P03: 듣기만 해도 화난다\n",
      "P01: 걔네 완전 계획적이고 상습범이래 키키\n",
      "P02: 그런 걸로 계획을 세우고 그러냐 에이고\n",
      "P03: 진짜 머리를 거기다 쓰냐\n",
      "P03: 너무하다\n",
      "P03: 몇 명이 그런 거야 대체\n"
     ]
    }
   ],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "print(get_eval_data()[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"finish_reason\": \"SAFETY\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"HIGH\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 459,\n",
       "        \"total_token_count\": 459\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "response = client.generate_content(\n",
    "    contents=get_eval_data()[36],\n",
    "    # safety_settings={\n",
    "    #     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    # }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 별도의 Guardrail 라이브러리\n",
    "- guardrails-ai\n",
    "- NVIDIA-NeMo\n",
    "- guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/hyeonjinho/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for field with errors: The following sentences in your response were found to be toxic:\n",
      "\n",
      "- You are a stupid idiot who can't do anything right.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/kakaotalk-summarization/.venv/lib/python3.9/site-packages/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"Love how you think and attack the problem. Great job!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"Please look carefully. You are a stupid idiot who can't do anything right.\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/kakaotalk-summarization/.venv/lib/python3.9/site-packages/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"exception\"\n",
    ")\n",
    "\n",
    "# Test passing response\n",
    "guard.validate(\"안녕하세요!\")\n",
    "\n",
    "try:\n",
    "    # Test failing response\n",
    "    guard.validate(\n",
    "        \"바보 멍청이\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
