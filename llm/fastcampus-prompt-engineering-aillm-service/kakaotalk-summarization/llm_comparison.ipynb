{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "# LLM API 비교\n",
    "- 비용으로 1차적으로 추린 후에 2차적으로 성능 비교\n",
    "## Gemini API\n",
    "- 다른 LLM 라인업 대비 항상 좀 더 저렴한 가격에 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyeonjinho/Desktop/dev/Learned/llm/fastcampus-prompt-engineering-aillm-service/kakaotalk-summarization/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 환경변수에 GOOGLE_API_KEY 추가 필요\n",
    "# ~/.zshrc에 export GOOGLE_API_KEY='<API KEY>'\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"Hi!\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude API\n",
    "- OpenAI에 필적하는 성능\n",
    "  - 2024년 6월 기준 가장 좋은 성능의 모델 = Claude 3.5 Sonnet\n",
    "- 현재 기준 가장 비싼 모델인 Claude 3 Opus 보유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings, young one. How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# 환경변수에 ANTHROPIC_API_KEY 추가 필요\n",
    "# ~/.zshrc에 export ANTHROPIC_API_KEY='<API KEY>'\n",
    "import os\n",
    "\n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ['ANTHROPIC_API_KEY']\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Respond only in Yoda-speak.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hi!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동일한 Prompt에 대해 Input / Output 계산\n",
    "- 비용 계산을 위해서는 Tokens 수를 알아야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import get_eval_data\n",
    "\n",
    "conversations = get_eval_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01: 맞다요즘 싸이월드 새로 생겼다매\n",
      "P02: 나 싸이월드 복구하고 싶다\n",
      "P01: 웅 키키귀여우뉴사진\n",
      "P02: 진짜 추억돋네\n",
      "P01: 짱많아 옛날 사진들\n",
      "P01: 맨날 퍼가요~ 이거 했자나\n",
      "P02: 맞아 싸이월드 미니미\n",
      "P01: 추억 돋아서 너무조아\n",
      "P02: 꾸미는거\n",
      "P01: 마자\n",
      "P02: 재밌었는데\n",
      "P01: 귀여워 도토리충전\n",
      "P02: 네이트온도 하고\n",
      "P02: 도토리도 환불해준대자나\n",
      "P01: 마자 키키개웃겨\n",
      "P01: 요즘 사회적으로 멀 자꾸하나바\n",
      "P02: 대박이야 진짜\n",
      "P02: 그니깐 키키\n",
      "P01: 아니 나오늘 엄마가 뭐 신청해달라그래서\n",
      "P02: 웅\n",
      "P01: 지원금 ? 신청함\n",
      "P01: 진짜 요즘 지원금 엄청 많이 받았어\n",
      "P02: 와 대박\n",
      "P01: 뭔지는 잘 모르는데 이것저것 지원해주는거 많아서 좋은듯\n",
      "P02: 다행이다\n",
      "P01: 국가제도가 진짜 괜차나\n",
      "P01: 학교에서도\n",
      "P02: 두분다\n",
      "P01: 맨날 장학금 해준다고\n",
      "P02: 일을 못하는\n",
      "P01: 이것저것 지원해주자나\n",
      "P02: 상황이셔서 더\n",
      "P01: 마자ㅠㅠ\n",
      "P02: 도움주시고\n",
      "P01: 나 그래서 진짜 그런거로\n",
      "P02: 다행이다그래도\n",
      "P01: 돈 마니받앗어\n",
      "P02: 와대박\n"
     ]
    }
   ],
   "source": [
    "print(conversations[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini Pro & Flash\n",
    "\n",
    "- 506 / 116 / 622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 싸이월드 부활과 추억에 대한 이야기를 나누며 옛날 사진과 꾸미기, 도토리 등을 회상합니다. 또한, 요즘 사회적으로 지원금과 장학금 등 다양한 도움을 받을 수 있는 점에 대해 공감하며 긍정적인 반응을 보입니다. 특히 P01은 엄마를 대신해 지원금을 신청했고, 학교에서도 장학금을 받아 돈을 많이 벌었다는 사실을 P02에게 자랑스럽게 이야기합니다. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 506\n",
       "candidates_token_count: 136\n",
       "total_token_count: 642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\n",
    "\n",
    "{conversations[0]}\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash-001')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 호출해보기 전에 Prompt가 몇 토큰인 지 미리 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_tokens: 505"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제로는 여기에 token 1씩 더 추가됨\n",
    "model.count_tokens(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 Prompt에 대해 Gemini Pro와 Gemini Flash 둘 다 506 입력 토큰 -> 동일한 Tokenizer를 사용하는 것을 알 수 있음\n",
    "\n",
    "- 더 많은 단어를 익힌 (보통 더 큰) 모델의 경우 다른 Tokenizer를 써서 입력 토큰 수가 달라질 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사람은 과거 싸이월드를 하던 시절을 회상하며 추억에 잠깁니다. 그러다가 최근 정부와 학교에서 지원금을 많이 받았다는 주제로 이야기가 넘어가며 만족감을 표합니다. 특히 P01은 다양한 지원금 덕분에 돈을 많이 받았다고 자랑합니다. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 506\n",
       "candidates_token_count: 92\n",
       "total_token_count: 598"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"아래 사용자 대화에 대해 3문장 내로 요약해주세요:\n",
    "\n",
    "{conversations[0]}\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-pro-001')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anthropic Claude\n",
    "\n",
    "- 637 / 143 / 780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 두 사람은 과거 싸이월드 사용 경험을 회상하며 추억을 공유하고 있다.\n",
      "2. 최근 정부와 학교에서 제공하는 다양한 지원금 혜택에 대해 이야기하고 있다.\n",
      "3. 경제적 어려움을 겪고 있는 상황에서 이러한 지원이 도움이 되고 있다고 말하고 있다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=637, output_tokens=143, cache_creation_input_tokens=0, cache_read_input_tokens=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ['ANTHROPIC_API_KEY']\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)\n",
    "message.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 대화는 싸이월드의 재출시와 그에 대한 추억을 나누는 것으로 시작합니다. 그 후 화제가 최근의 사회적 지원금과 장학금 등 다양한 국가 지원 제도로 전환됩니다. 대화 참여자들은 이러한 지원 제도에 대해 긍정적인 반응을 보이며, 특히 어려운 상황에 있는 사람들에게 도움이 된다고 평가합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=637, output_tokens=168, cache_creation_input_tokens=0, cache_read_input_tokens=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)\n",
    "message.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 싸이월드가 새로 생겨서 옛날 추억을 되새기며 즐거워하는 두 사람의 대화이다.\n",
      "2. 요즘 사회적으로 여러 지원금과 장학금 등 국가 제도의 도움을 많이 받고 있다는 내용이 언급되었다.\n",
      "3. 두 사람 모두 일을 못하는 상황이지만 국가의 지원으로 도움을 받고 있어 다행이라고 생각하고 있다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=637, output_tokens=170, cache_creation_input_tokens=0, cache_read_input_tokens=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)\n",
    "message.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 사용자는 싸이월드를 통해 추억을 공유하고, 최근 지원금을 받아 도움을 받았다는 이야기를 나누며 국가제도에 대해 이야기하고 있다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=73, prompt_tokens=622, total_tokens=695, prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    messages=[{'role': 'user', 'content': prompt}],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자들은 최근 재개된 싸이월드에 대해 이야기하며, 옛날 사진과 미니미 꾸미기 등 추억을 회상합니다. 또한, 사용자들은 정부 지원금과 장학금 등 다양한 지원 제도에 대해 긍정적인 의견을 나눕니다. 이 대화에서는 싸이월드의 복구와 추억, 그리고 사회적 지원 제도에 대한 만족감이 주된 주제로 다뤄집니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=158, prompt_tokens=622, total_tokens=780, prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4-turbo-2024-04-09',\n",
    "    messages=[{'role': 'user', 'content': prompt}],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "completion.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자들은 싸이월드의 복구와 관련된 추억을 이야기하며, 옛날 사진과 미니미 꾸미기, 도토리 충전 등의 재미를 회상하고 있습니다. 또한, 최근 정부의 다양한 지원금 제도에 대해 이야기하며, 이를 통해 많은 도움을 받고 있다는 점을 공유하고 있습니다. 대화는 싸이월드와 지원금 제도에 대한 긍정적인 경험을 나누는 내용으로 구성되어 있습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=102, prompt_tokens=441, total_tokens=543, prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4o-2024-05-13',\n",
    "    messages=[{'role': 'user', 'content': prompt}],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n",
    "completion.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Tokens 수 정리 (Prompt 고정)\n",
    "\n",
    "- Gemini 506\n",
    "- Claude 637\n",
    "- GPT 622\n",
    "- GPT-4o 441\n",
    "  - Output은 어느 정도 조정이 가능해서 Input만 비교\n",
    "\n",
    "한글 효율화 측면에서는 GPT-4o > Gemini > GPT-3.5/4 >= Claude 순\n",
    "\n",
    "- 다른 Prompt에서는 조금씩 다를 수 있으나, 경향이 크게 달라지지 않을 것으로 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
