from openai import Client
import json
import requests

client = Client()

tools = [
  {
    "type": "function",
    "function": {
      "name": "get_product",
      "description": "Get the product by product_no",
      "parameters": {
        "type": "object",
        "properties": {
          "product_no": {
            "type": "number", 
            "description": "ìƒí’ˆë²ˆí˜¸"
          },
        }, 
        "required": ["product_no"],
        "additionalProperties": False,
      },
      "strict": True,
    }
  },
  {
    "type": "function",
    "function": {
      "name": "get_shipping",
      "description": "Get the shipping info by order_no, order_seq",
      "parameters": {
        "type": "object",
        "properties": {
          "order_no": {
            "type": "number",
            "description": "ì£¼ë¬¸ë²ˆí˜¸"
          },
          "order_seq": {
            "type": "number",
            "description": "ì£¼ë¬¸ìˆœë²ˆ"
          },
        },
        "required": ["order_no", "order_seq"],
        "additionalProperties": False,
      },
      "strict": True,
    }
  },
  {
    "type": "function",
    "function": {
      "name": "get_order",
      "description": "Get the order by order_no",
      "parameters": {
        "type": "object",
        "properties": {
          "order_no": {
            "type": "number",
            "description": "ì£¼ë¬¸ë²ˆí˜¸"
          },
        },
        "required": ["order_no"],
        "additionalProperties": False,
      },
      "strict": True,
    }
  }
]

def get_product(product_no):
  return requests.get(f"http://127.0.0.1:8000/products/{product_no}").json()

def get_order(order_no):
  return requests.get(f"http://127.0.0.1:8000/orders/{order_no}").json()

def get_shipping(order_no, order_seq):
  return requests.get(f"http://127.0.0.1:8000/shipping/{order_no}/{order_seq}").json()

def inference(message):
  response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
      {"role": "user", "content": message},
    ],
    temperature=0,
    tools=tools,
  )
  if response.choices[0].finish_reason == "tool_calls":
    tool_name = response.choices[0].message.tool_calls[0].function.name
    tool_arguments = response.choices[0].message.tool_calls[0].function.arguments
    tool_arguments = json.loads(tool_arguments)

    # if tool_name == "get_product":
    #   result = get_product(tool_arguments["product_no"])
    # elif tool_name == "get_order":
    #   result = get_order(tool_arguments["order_no"])
    # elif tool_name == "get_shipping":
    #   result = get_shipping(tool_arguments["order_no"], tool_arguments["order_seq"])

    result = globals()[tool_name](**tool_arguments)
    prompt = f"""context: {result}

Q: {message}
A: """

    response_answer = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[{"role": "user", "content": prompt}],
      temperature=0,
    )

    return response_answer.choices[0].message.content
  else:
    return response.choices[0].message.content
  
system_message_1 = """
ì•„ë˜ ë§íˆ¬ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ì±„íŒ…í•˜ì„¸ìš”.

ì´ëª¨ì§€ë¥¼ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”.

example1: ì•ˆë…•í•˜ì„¸ìš”!! ğŸ™‚
example2: ê¶ê¸ˆí•œ ê²Œ ìˆë‹¤ë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” ğŸ˜Š
example3: ì£¼ë¬¸ì´ ë¯¸ë¤„ì§€ê³  ìˆì–´ìš” ã… ã… ã…  ğŸ˜­
"""
  
def inference_tone(message):
  response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
      {"role": "system", "content": system_message_1},
      {"role": "user", "content": message},
    ],
    temperature=0,
    tools=tools,
  )
  if response.choices[0].finish_reason == "tool_calls":
    tool_name = response.choices[0].message.tool_calls[0].function.name
    tool_arguments = response.choices[0].message.tool_calls[0].function.arguments
    tool_arguments = json.loads(tool_arguments)

    # if tool_name == "get_product":
    #   result = get_product(tool_arguments["product_no"])
    # elif tool_name == "get_order":
    #   result = get_order(tool_arguments["order_no"])
    # elif tool_name == "get_shipping":
    #   result = get_shipping(tool_arguments["order_no"], tool_arguments["order_seq"])

    result = globals()[tool_name](**tool_arguments)
    prompt = f"""context: {result}

Q: {message}
A: """

    response_answer = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[
        {"role": "system", "content": system_message_1},
        {"role": "user", "content": prompt}
      ],
      temperature=0,
    )

    return response_answer.choices[0].message.content
  else:
    return response.choices[0].message.content

  

if __name__ == "__main__":
  print(inference_tone("ìƒí’ˆë²ˆí˜¸ê°€ 1234567890ì¸ ìƒí’ˆ ì¢€ ì°¾ì•„ì¤˜."))
  print('--------')
  print(inference_tone("""ë‹¤ìŒ ì£¼ë¬¸ì„ ì°¾ì•„ì£¼ì„¸ìš”.
                  
* ì£¼ë¬¸ë²ˆí˜¸: 2024010101"""))
  print('--------')
  print(inference_tone("""ì£¼ë¬¸ë²ˆí˜¸ê°€ 2024010101ì´ê³  ì£¼ë¬¸ìˆœë²ˆì´ 0ì´ì•¼.
ë°°ì†¡ ì¢€ ì¡°íšŒí•´ì¤˜."""))
  print('--------')
  print(inference_tone("ë”¥ëŸ¬ë‹ì´ ë­ì•¼?"))
  
  
