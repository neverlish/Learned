{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal, Annotated, List\n",
    "from operator import add\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    article: str\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    agent_output: str\n",
    "\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    messages: Annotated[List[BaseMessage], add]\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_current_club(player_name: str):\n",
    "    \"\"\"Gets current club of a player\"\"\"\n",
    "    fake_db = {\n",
    "        \"Lionel Messi\": \"Paris Saint-Germain\",\n",
    "        \"Cristiano Ronaldo\": \"Al Nassr FC\",\n",
    "    }\n",
    "    return fake_db.get(player_name, \"Current club information not available.\")\n",
    "\n",
    "\n",
    "tools1 = [get_current_club]\n",
    "model1 = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools(tools1)\n",
    "\n",
    "\n",
    "def call_model_current_club(state: OverallState):\n",
    "    local_messages = state.get(\"messages\", [])\n",
    "    if not local_messages:\n",
    "        human_message = HumanMessage(content=state[\"article\"])\n",
    "        local_messages.append(human_message)\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are an agent tasked with determining the current club of a player.\n",
    "If the current club is mentioned, return it. Otherwise, return 'Current club information not available.'\"\"\"\n",
    "    )\n",
    "    response = model1.invoke([system_message] + local_messages)\n",
    "    state[\"agent_output\"] = response.content\n",
    "    state[\"messages\"] = local_messages + [response]\n",
    "    return state\n",
    "\n",
    "\n",
    "def should_continue(state: OverallState) -> Literal[\"tools\", END]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if getattr(last_message, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "current_club_graph = StateGraph(state_schema=OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "current_club_graph.add_node(\"call_model_current_club\", call_model_current_club)\n",
    "current_club_graph.add_node(\"tools\", ToolNode(tools1))\n",
    "current_club_graph.add_edge(START, \"call_model_current_club\")\n",
    "current_club_graph.add_conditional_edges(\"call_model_current_club\", should_continue)\n",
    "current_club_graph.add_edge(\"tools\", \"call_model_current_club\")\n",
    "\n",
    "current_club_researcher_agent = current_club_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"article\": \"Lionel Messi will join Real Madrid 2025\",\n",
    "}\n",
    "current_club_researcher_agent.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"article\": \"Thomas Müller will join Real Madrid 2025\",\n",
    "}\n",
    "current_club_researcher_agent.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    article: str\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    agent_output: str\n",
    "\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    messages: Annotated[List[BaseMessage], add]\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_market_value(player_name: str):\n",
    "    \"\"\"Gets current market value of a player\"\"\"\n",
    "    fake_market_value_db = {\n",
    "        \"Lionel Messi\": \"€50 million\",\n",
    "        \"Cristiano Ronaldo\": \"€30 million\",\n",
    "    }\n",
    "    return fake_market_value_db.get(\n",
    "        player_name, \"Market value information not available.\"\n",
    "    )\n",
    "\n",
    "\n",
    "tools2 = [get_market_value]\n",
    "model2 = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools(tools2)\n",
    "\n",
    "\n",
    "def call_model_market_value(state: OverallState):\n",
    "    local_messages = state.get(\"messages\", [])\n",
    "    if not local_messages:\n",
    "        human_message = HumanMessage(content=state[\"article\"])\n",
    "        local_messages.append(human_message)\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"You are an agent tasked with determining the market value of a player.\n",
    "If the market value is mentioned, return it. Otherwise, return 'Market value information not available.'\"\"\"\n",
    "    )\n",
    "    response = model2.invoke([system_message] + local_messages)\n",
    "    state[\"agent_output\"] = response.content\n",
    "    state[\"messages\"] = local_messages + [response]\n",
    "    return state\n",
    "\n",
    "\n",
    "def should_continue(state: OverallState) -> Literal[\"tools\", END]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if getattr(last_message, \"tool_calls\", None):\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "market_value_graph = StateGraph(state_schema=OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "market_value_graph.add_node(\"call_model_market_value\", call_model_market_value)\n",
    "market_value_graph.add_node(\"tools\", ToolNode(tools2))\n",
    "market_value_graph.add_edge(START, \"call_model_market_value\")\n",
    "market_value_graph.add_conditional_edges(\"call_model_market_value\", should_continue)\n",
    "market_value_graph.add_edge(\"tools\", \"call_model_market_value\")\n",
    "\n",
    "market_value_researcher_agent = market_value_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_researcher_agent.invoke(\n",
    "    {\"article\": \"Lionel Messi will switch from FC Barcelona to Real Madrid in 2025\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_value_researcher_agent.invoke(\n",
    "    {\"article\": \"Thomas Müller will join Real Madrid 2025\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    article: str\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    agent_output: str\n",
    "\n",
    "\n",
    "class OverallState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "\n",
    "model_text_writer = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def expand_text_to_100_words(state: OverallState):\n",
    "    human_message = HumanMessage(content=state[\"article\"])\n",
    "    system_message = SystemMessage(\n",
    "        content=\"Expand the following text to be at least 100 words. Maintain the original meaning while adding detail.\"\n",
    "    )\n",
    "    response = model_text_writer.invoke([system_message, human_message])\n",
    "    state[\"agent_output\"] = response.content\n",
    "    return state\n",
    "\n",
    "\n",
    "text_writer_graph = StateGraph(state_schema=OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "text_writer_graph.add_node(\"expand_text_to_100_words\", expand_text_to_100_words)\n",
    "text_writer_graph.add_edge(START, \"expand_text_to_100_words\")\n",
    "text_writer_graph.add_edge(\"expand_text_to_100_words\", END)\n",
    "\n",
    "text_writer_agent = text_writer_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_writer_agent.invoke(\n",
    "    {\"article\": \"Lionel Messi will switch from FC Barcelona to Real Madrid in 2025\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class ArticlePostabilityGrader(BaseModel):\n",
    "    \"\"\"Binary scores for verifying if an article mentions market value, current club, and meets the minimum word count of 100 words.\"\"\"\n",
    "\n",
    "    off_or_ontopic: str = Field(\n",
    "        description=\"The Article is about football transfers, 'yes' or 'no'\"\n",
    "    )\n",
    "    mentions_market_value: str = Field(\n",
    "        description=\"The article mentions the player's market value, 'yes' or 'no'\"\n",
    "    )\n",
    "    mentions_current_club: str = Field(\n",
    "        description=\"The article mentions the player's current club, 'yes' or 'no'\"\n",
    "    )\n",
    "    meets_100_words: str = Field(\n",
    "        description=\"The article has at least 100 words, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm_postability = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_postability_grader = llm_postability.with_structured_output(\n",
    "    ArticlePostabilityGrader\n",
    ")\n",
    "\n",
    "postability_system = \"\"\"\n",
    "You are a grader assessing whether a news article meets the following criteria:\n",
    "1. The article is about football transfers or not. If yes answer, answer with 'yes', anotherwise with 'no'.\n",
    "1. The article explicitly mentions the player's market value, for example, by stating \"market value\" or a specific currency amount (e.g., \"$50 million\"). If this is present, respond with 'yes' for mentions_market_value; otherwise, respond 'no'.\n",
    "2. The article mentions the player's current club or indicates that the current club information is unavailable (e.g., \"Current club information not available\"). If this is present, respond with 'yes' for mentions_current_club; otherwise, respond 'no'.\n",
    "3. The article contains at least 100 words. If this is met, respond with 'yes' for meets_100_words; otherwise, respond 'no'.\n",
    "\n",
    "Provide four binary scores ('yes' or 'no') as follows:\n",
    "- off_or_ontopic: 'yes' or 'no' depending on whether the article is related to football transfers or not.\n",
    "- mentions_market_value: 'yes' or 'no' depending on whether the article mentions the player's market value.\n",
    "- mentions_current_club: 'yes' or 'no' depending on whether the article mentions the player's current club or states that the information is unavailable.\n",
    "- meets_100_words: 'yes' or 'no' depending on whether the article has at least 100 words.\n",
    "\"\"\"\n",
    "\n",
    "postability_grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", postability_system), (\"human\", \"News Article:\\n\\n{article}\")]\n",
    ")\n",
    "\n",
    "news_chef = postability_grade_prompt | structured_llm_postability_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_chef.invoke({\"article\": \"Lionel Messi will switch to Real Madrid in 2025\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_chef.invoke({\"article\": \"Today in Munich will be 9°C\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "class InputArticleState(TypedDict):\n",
    "    article: str\n",
    "\n",
    "\n",
    "class OutputFinalArticleState(TypedDict):\n",
    "    final_article: str\n",
    "    off_or_ontopic: str\n",
    "\n",
    "\n",
    "class SharedArticleState(InputArticleState, OutputFinalArticleState):\n",
    "    mentions_market_value: str\n",
    "    mentions_current_club: str\n",
    "    meets_100_words: str\n",
    "\n",
    "\n",
    "def update_article_state(state: SharedArticleState) -> SharedArticleState:\n",
    "    response = news_chef.invoke({\"article\": state[\"article\"]})\n",
    "    state[\"off_or_ontopic\"] = response.off_or_ontopic\n",
    "    state[\"mentions_market_value\"] = response.mentions_market_value\n",
    "    state[\"mentions_current_club\"] = response.mentions_current_club\n",
    "    state[\"meets_100_words\"] = response.meets_100_words\n",
    "    print(\"State after update_article_state:\", state)\n",
    "    return state\n",
    "\n",
    "\n",
    "def market_value_researcher_node(state: SharedArticleState) -> SharedArticleState:\n",
    "    response = market_value_researcher_agent.invoke({\"article\": state[\"article\"]})\n",
    "    state[\"article\"] += f\" {response['agent_output']}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def current_club_researcher_node(state: SharedArticleState) -> SharedArticleState:\n",
    "    response = current_club_researcher_agent.invoke({\"article\": state[\"article\"]})\n",
    "    state[\"article\"] += f\" {response['agent_output']}\"\n",
    "    return state\n",
    "\n",
    "\n",
    "def word_count_rewriter_node(state: SharedArticleState) -> SharedArticleState:\n",
    "    response = text_writer_agent.invoke({\"article\": state[\"article\"]})\n",
    "    state[\"article\"] += f\" {response['agent_output']}\"\n",
    "    state[\"final_article\"] = response[\"agent_output\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "def news_chef_decider(\n",
    "    state: SharedArticleState,\n",
    ") -> Literal[\n",
    "    \"market_value_researcher\", \"current_club_researcher\", \"word_count_rewriter\", END\n",
    "]:\n",
    "    if state[\"off_or_ontopic\"] == \"no\":\n",
    "        return END\n",
    "    if state[\"mentions_market_value\"] == \"no\":\n",
    "        return \"market_value_researcher\"\n",
    "    elif state[\"mentions_current_club\"] == \"no\":\n",
    "        return \"current_club_researcher\"\n",
    "    elif (\n",
    "        state[\"meets_100_words\"] == \"no\"\n",
    "        and state[\"mentions_market_value\"] == \"yes\"\n",
    "        and state[\"mentions_current_club\"] == \"yes\"\n",
    "    ):\n",
    "        return \"word_count_rewriter\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "workflow = StateGraph(\n",
    "    state_schema=SharedArticleState, input_schema=InputArticleState, output_schema=OutputFinalArticleState\n",
    ")\n",
    "\n",
    "workflow.add_node(\"news_chef\", update_article_state)\n",
    "workflow.add_node(\"market_value_researcher\", market_value_researcher_node)\n",
    "workflow.add_node(\"current_club_researcher\", current_club_researcher_node)\n",
    "workflow.add_node(\"word_count_rewriter\", word_count_rewriter_node)\n",
    "\n",
    "workflow.set_entry_point(\"news_chef\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"news_chef\",\n",
    "    news_chef_decider,\n",
    "    {\n",
    "        \"market_value_researcher\": \"market_value_researcher\",\n",
    "        \"current_club_researcher\": \"current_club_researcher\",\n",
    "        \"word_count_rewriter\": \"word_count_rewriter\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"market_value_researcher\", \"news_chef\")\n",
    "workflow.add_edge(\"current_club_researcher\", \"news_chef\")\n",
    "workflow.add_edge(\"word_count_rewriter\", \"news_chef\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"article\": \"Today in Munich will be 9°C\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.invoke({\"article\": \"Lionel Messi will to Real Madrid in 2025\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Human in the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "\n",
    "class InputState(TypedDict):\n",
    "    question: str\n",
    "\n",
    "\n",
    "class IntermediateState(InputState):\n",
    "    off_or_ontopic: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class FinalState(IntermediateState):\n",
    "    api_response: str\n",
    "    status_code: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_node(state: InputState) -> InputState:\n",
    "    return state\n",
    "\n",
    "\n",
    "def newsagent_node(state: IntermediateState) -> IntermediateState:\n",
    "    response = app.invoke({\"article\": state[\"question\"]})\n",
    "    state[\"answer\"] = response.get(\n",
    "        \"final_article\", \"Article not relevant for news agency\"\n",
    "    )\n",
    "    state[\"off_or_ontopic\"] = response[\"off_or_ontopic\"]\n",
    "    return state\n",
    "\n",
    "\n",
    "def api_call_node(state: FinalState) -> FinalState:\n",
    "    state[\"status_code\"] = 200\n",
    "    state[\"api_response\"] = f\"API received answer: {state['answer']}\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(FinalState, input=InputState, output=FinalState)\n",
    "\n",
    "workflow.add_node(\"newsagent_node\", newsagent_node)\n",
    "workflow.add_node(\"api_call_node\", api_call_node)\n",
    "\n",
    "workflow.set_entry_point(\"newsagent_node\")\n",
    "\n",
    "workflow.add_edge(\"newsagent_node\", \"api_call_node\")\n",
    "workflow.add_edge(\"api_call_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app = workflow.compile(\n",
    "    checkpointer=checkpointer, interrupt_after=[\"newsagent_node\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        human_app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app.invoke(\n",
    "    {\"question\": \"The weather will be 9°C in Munich\"}, config=config2, subgraphs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app.invoke(\n",
    "    {\"question\": \"Lionel Messi will to Real Madrid in 2025\"},\n",
    "    config=config,\n",
    "    subgraphs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = human_app.get_state(config2)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app.invoke(None, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = human_app.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = human_app.get_state(config)\n",
    "existing_message = snapshot.values\n",
    "existing_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app.update_state(\n",
    "    config,\n",
    "    {\"answer\": \"Fake news!!!\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_app.invoke(None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = human_app.get_state(config)\n",
    "snapshot.next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
