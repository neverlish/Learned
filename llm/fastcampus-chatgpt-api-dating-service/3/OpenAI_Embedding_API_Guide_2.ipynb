{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862e8a4a-9301-4a2d-8782-9d8a1b8825dc",
   "metadata": {},
   "source": [
    "# OpenAI Embedding API로 문서 임베딩하고 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c456dfb-90ca-4596-b91d-5a80db44f211",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c681fa2-215a-45de-93fc-f33f954b6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cd31a-22da-4aa9-b8a8-b00ef598494b",
   "metadata": {},
   "source": [
    "## Tiktoken?\n",
    "\n",
    "Tiktoken은 OpenAI에서 측정는 텍스트의 토큰 갯수를 확인 할 수 있는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d58ceaa-e1fd-4b4b-8f46-a6b29260bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "num_tokens = len(encoding.encode(\"tiktoken is great!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37161f6c-d821-49f1-bbc5-ae08d273f13d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1ddd2c-959c-4141-8742-027fe64ae335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1609, 5963, 374, 2294, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"tiktoken is great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5dfce99-c932-4ba8-a451-b9b90917c915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(encoding.encode(\"tiktoken is great!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ed7df-2cb9-4496-b9f4-e109766fef3b",
   "metadata": {},
   "source": [
    "## 긴 문서 chunking 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89df4ae-cfff-43ff-9a30-dd67b026fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_text_into_chunks(text, n_slide=400, max_size=800): # n_slide=4000, max_size=8000, MAX_TOKENS = 8191\n",
    "    text_chunk_list = []\n",
    "\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token_ids = encoding.encode(text)\n",
    "\n",
    "    n_chunk = int(math.ceil(len(token_ids) / n_slide))\n",
    "\n",
    "    for chunk_i in range(n_chunk):\n",
    "        token_ids_chunk = token_ids[chunk_i * n_slide:chunk_i * n_slide + max_size]\n",
    "        curr_text_chunk = encoding.decode(token_ids_chunk)\n",
    "        text_chunk_list.append(curr_text_chunk)\n",
    "    return text_chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65933113-4996-448e-b51b-40b0819a1f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all rst files\n",
    "def get_all_doc_data(dir_path, doc_id_start=0):\n",
    "    md_path_list = glob(f\"{dir_path}/**/*.rst\", recursive=True)\n",
    "    doc_list = []\n",
    "    # make docs\n",
    "    for doc_id, md_path in enumerate(md_path_list, start=doc_id_start):\n",
    "        with open(md_path, \"rt\") as f:\n",
    "            text = f.read()\n",
    "        doc_list.append({\"docId\": str(doc_id), \"src\": md_path, \"text\": text})\n",
    "\n",
    "    psg_list = []\n",
    "\n",
    "    for doc in doc_list:\n",
    "        text_chunk_list = long_text_into_chunks(doc['text'])\n",
    "        for psg_id, text_chunk in enumerate(text_chunk_list):\n",
    "\n",
    "            psg_list.append(text_chunk)\n",
    "\n",
    "    return psg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd0f357-656c-4245-aa62-8daf6728ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"./konlpy\"\n",
    "psg_list = get_all_doc_data(dir_path, doc_id_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816a1236-85a7-4aa3-ac14-bc1a08431068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(psg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2353fef5-d5ab-4c9d-98f5-f073a6d85dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # Install `Apache Ant <http://ant.apache.org/manual/install.html>`_\n",
      "        make java\n",
      "\n",
      "    1. 코드를 단 한 줄이라도 수정한 모든 경우::\n",
      "\n",
      "        pip install -r requirements-dev.txt\n",
      "        pip3 install -r requirements-dev.txt\n",
      "        make build      # create tar.gz\n",
      "        make check      # check code styles\n",
      "        make testall    # run tests\n",
      "\n",
      "- PR을 보내기 전 다음을 확인해주세요.\n",
      "    1. PR을 보내면 해당 코드는 KoNLPy의 오픈소스 라이센스를 따름\n",
      "    1. PR를 보낸 후 코드의 일부를 변경하도록 요청될 경우, ``git commit --amend`` 로 커밋을 수정\n",
      "\n",
      "\n",
      "4. 문서 수정하기\n",
      "----------------\n",
      "\n",
      "- 오류 수정: 사소한 오타 등을 발견하여 수정을 요청하고 싶은 경우, 문서를 직접 수정하실 수 있습니다.\n",
      "- 내용 추가: 그 외에도 내용이 잘 이해되지 않는 부분이 있다거나, 설명이 부족한 부분에도 내용을 추가하실 수 있습니다. 특히, KoNLPy는 예제가 풍부한 문서를 지향합니다. 문서에 추가하면 좋을 법한 예제가 있으면 공유해주세요.\n",
      "- 번역: KoNLPy의 문서 영문과 한국어를 지원합니다. 표현이 어색하거나 번역이 덜 된 부분을 수정하실 수 있습니다.\n",
      "\n",
      "> Note: 기왕이면 기여하신 부분에 대해 정확한 attribution을 할 수 있도록, 다음의 과정대로 문서를 설치하고 수정한 후, PR을 보내주시기 바랍니다. 만일 이 과정이 너무 어렵거나 번거롭고, attribution은 따로 받지 않아도 된다면, konlpy@googlegroups.com로 메일을 보내주셔도 됩니다.\n",
      "\n",
      "\n",
      "Setup docs\n",
      "''''''''''\n",
      "\n",
      "1. Fork and clone KoNLPy::\n",
      "\n",
      "    git clone git@github.com:[your_github_id]/konlpy.git\n",
      "\n",
      "2. Include the following lines in your `~/.bashrc`::\n",
      "\n",
      "    export LC_ALL=en_US.UTF-8\n",
      "    export LANG=en_US.UTF-8\n",
      "\n",
      "3. Install dependencies::\n",
      "\n",
      "    $ make init_i18n\n",
      "\n",
      "\n",
      "Modify and push docs\n",
      "''''''''''''''''''''\n",
      "\n",
      "1. Modify a document file::\n",
      "\n",
      "    $ cd docs             # Move to the `docs` folder\n",
      "    $ vi some_file.rst    # Modify corresponding `*.rst` files\n",
      "\n",
      "2. Build docs::\n",
      "\n",
      "    $ make html\n",
      "\n",
      "3. Extract translation phrases::\n",
      "\n",
      "    $ make extract_i18n\n",
      "\n",
      "4. Modify translations::\n",
      "\n",
      "    $ cd locale/ko/LC_MESSAGES\n",
      "    $ vi some_file.po\n",
      "\n",
      "5. Update translations::\n",
      "\n",
      "    $ make update_i18n\n",
      "\n",
      "6. Commit and push your repository\n",
      "\n",
      "7. Send a pull request\n",
      "\n",
      "\n",
      "5. 테스트 추가하기\n",
      "------------------\n",
      "\n",
      "- 코드의 커버리지가 최대화될 수 있도록, 아직 커버되지 않은 테스트 케이스를 추가해주세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(psg_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28241bee-5742-4563-93af-e9a746965101",
   "metadata": {},
   "source": [
    "## 문서 Embedding 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44dd3864-26d2-4f4e-9dab-1d9ed5bd538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94887994-5c51-44cf-bda5-f1f37070d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def encode(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\")\n",
    "    return np.array(response.data[0].embedding, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33af411e-9bd9-4b74-8ca5-6c67a95c0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "psg_embs = np.array([encode(psg) for psg in psg_list], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe9cfca-8fe8-4b0b-aea8-1615a50a4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00967265, -0.00666077,  0.01922067, ...,  0.00560141,\n",
       "        -0.0002207 , -0.03148977],\n",
       "       [ 0.00923838, -0.01505167,  0.01927951, ...,  0.01457001,\n",
       "        -0.00302371, -0.01349298],\n",
       "       [ 0.01724748, -0.0034495 ,  0.0238425 , ...,  0.01991721,\n",
       "        -0.0007711 , -0.00141168],\n",
       "       ...,\n",
       "       [-0.01179341, -0.00282618,  0.01642885, ..., -0.00837972,\n",
       "        -0.00548347, -0.04036063],\n",
       "       [-0.02807183,  0.00458171,  0.01739063, ..., -0.00424482,\n",
       "         0.00233873, -0.0209794 ],\n",
       "       [-0.00574583,  0.01449099,  0.02416089, ...,  0.00822911,\n",
       "        -0.02133473, -0.03003487]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c608c738-4dea-4cf4-9e02-0b59963c65fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1536)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5bf46-8ab1-46ee-9eae-4303293dd4b8",
   "metadata": {},
   "source": [
    "## Faiss Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6695d-ca34-46d6-b3fa-5bbe396e685f",
   "metadata": {},
   "source": [
    "### Faiss Index 빌드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2e53c6-402e-48ea-a718-16ab023e6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /opt/homebrew/Caskroom/miniconda/base/envs/fc-date-prepare/lib/python3.11/site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62246ef6-ef9b-4830-8383-27e1e802a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1551a98-acf8-4f33-bc8f-4f6b3acb0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 norms for each vector (row)\n",
    "norms = np.linalg.norm(psg_embs, axis=1, keepdims=True)\n",
    "\n",
    "# Divide by the norm to normalize\n",
    "psg_embs_normed = psg_embs / norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d210d51c-d1b3-4940-aa1b-5bd13d85314e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 1536)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_embs_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b0a30e-1325-4a0a-9acb-4943b72523fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(psg_embs_normed.shape[1])  # 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa1784c-0be5-457f-a0fb-456abef285a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(psg_embs_normed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d833c0-5123-4094-a846-4d73491527ee",
   "metadata": {},
   "source": [
    "### Faiss Index에서 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81095948-b556-4a82-800b-c09a804b0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Standing on the shoulders of giants\"  # Ubuntu install, Standing on the shoulders of giants\n",
    "query_emb = encode(query)\n",
    "query_emb_normed =  query_emb / np.linalg.norm(query_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd0a7582-1c1d-4d8c-8f68-494f2cec9321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00670303, -0.03380325, -0.00342194, ..., -0.00606922,\n",
       "       -0.01421273, -0.00804748], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_emb_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d35d892a-efb5-4db7-a925-688cb8a0c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list_list, psg_idx_list_list = index.search(query_emb.reshape(1, -1), k=3)  # (1, dim 1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4ceae5-cde5-4a50-923e-ebe956125638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75514424, 0.7136526 , 0.70839906]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feed4923-45a6-4a30-8f6d-8819047dec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 36, 49]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_idx_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4f9f2f-404c-4b4d-8b4b-c97769752857",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list, psg_idx_list = dist_list_list[0], psg_idx_list_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be09ea40-b237-412e-8271-372276519a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고는 실행환경, 에러메세지와함께 설명을 최대한상세히!^^'))\n",
      "    [(오류, NNG),\n",
      "     (보고, NNG),\n",
      "     (는, JX),\n",
      "     (실행, NNG),\n",
      "     (환경, NNG),\n",
      "     (,, SP),\n",
      "     (에러, NNG),\n",
      "     (메세지, NNG),\n",
      "     (와, JKM),\n",
      "     (함께, MAG),\n",
      "     (설명, NNG),\n",
      "     (을, JKO),\n",
      "     (최대한, NNG),\n",
      "     (상세히, MAG),\n",
      "     (!, SF),\n",
      "     (^^, EMO)]\n",
      "\n",
      "\n",
      "Standing on the shoulders of giants\n",
      "-----------------------------------\n",
      "\n",
      "Korean, the `13th most widely spoken language in the world <http://www.koreatimes.co.kr/www/news/nation/2014/05/116_157214.html>`_, is a beautiful, yet complex language.\n",
      "Myriad :ref:`engines` were built by numerous researchers, to computationally extract meaningful features from the labyrinthine text.\n",
      "\n",
      "KoNLPy is not just to create another, but to unify and build upon their shoulders, and see one step further.\n",
      "It is built particularly in the `Python (programming) language <http://python.org>`_, not only because of the language's simplicity and elegance, but also the powerful string processing modules and applicability to various tasks - including crawling, Web programming, and data analysis.\n",
      "\n",
      "The three main philosophies of this project are:\n",
      "\n",
      "- Keep it simple.\n",
      "- Make it easy. For humans.\n",
      "- :ref:`\"Democracy on the web works.\" <contribute>`\n",
      "\n",
      "Please `report <https://github.com/konlpy/konlpy/issues>`_ when you think any have gone stale.\n",
      "\n",
      "License\n",
      "-------\n",
      "\n",
      "KoNLPy is Open Source Software, and is released under the license below:\n",
      "\n",
      "- `GPL v3 or above <http://gnu.org/licenses/gpl.html>`_\n",
      "\n",
      "You are welcome to use the code under the terms of the license, however please acknowledge its use with a citation.\n",
      "\n",
      "- Eunjeong L. Park, Sungzoon Cho. \"`KoNLPy: Korean natural language processing in Python <http://dmlab.snu.ac.kr/~lucypark/docs/2014-10-10-hclt.pdf>`_\", Proceedings of the 26th Annual Conference on Human & Cognitive Language Technology, Chuncheon, Korea, Oct 2014.\n",
      "\n",
      "Here is a BibTeX entry.::\n",
      "\n",
      "    @inproceedings{park2014konlpy,\n",
      "      title={KoNLPy: Korean natural language processing in Python},\n",
      "      author={Park, Eunjeong L. and Cho, Sungzoon},\n",
      "      booktitle={Proceedings of the 26th Annual Conference on Human & Cognitive Language Technology},\n",
      "      address={Chuncheon, Korea},\n",
      "      month={October},\n",
      "      year={2014}\n",
      "    }\n",
      "\n",
      "\n",
      ".. _contribute:\n",
      "\n",
      "Contribute\n",
      "----------\n",
      "\n",
      "KoNLPy isn't perfect,\n",
      "but it will continuously evolve and you are invited to participate!\n",
      "\n",
      "Found a bug?\n",
      "Have a good idea for improving KoNLPy?\n",
      "Visit the `KoNLPy GitHub page <https://github.com/konlpy/konlpy>`_\n",
      "and `suggest an idea <https://github.com/konlpy/konlpy/issues>`_\n",
      "or `make a pull request <https://github.com/konlpy/konlpy/pulls>`_.\n",
      "\n",
      "You are also welcome to join\n",
      "our `gitter <https://gitter.im/konlpy/konlpy>`_\n",
      "and the `mailing list <https://groups.google.com/forum/#!forum/konlpy>`_.\n",
      "Gitter is more focused on\n",
      "******************************\n",
      " up to putting in some more time, try `The Hitchhiker's Guide <http://docs.python-guide.org/en/latest/>`_ or `Learn Python the hard way <http://learnpythonthehardway.org/book/>`_.\n",
      ".. [#] Many use `Sublime Text 2 <http://www.sublimetext.com/>`_ for Python programming. Some others use Vim and Terminal. But other than these, there are numerous great `text editors <http://tutorialzine.com/2012/07/battle-of-the-tools-which-is-the-best-code-editor/>`_ and `Python IDEs <http://pedrokroger.net/choosing-best-python-ide/>`_ out there, so take your pick!\n",
      "\n",
      "******************************\n",
      "한민국의\n",
      "    100 ① 대한민국은 민주공화국이다. ②대한민국의 주권은 국민에게\n",
      "    110 나온다. 제2조 ① 대한민국의 국민이 되는\n",
      "    126 의무를 진다. 제3조 대한민국의 영토는 한반도와\n",
      "    133 부속도서로 한다. 제4조 대한민국은 통일을 지향하며,\n",
      "    147 추진한다. 제5조 ① 대한민국은 국제평화의 유지에\n",
      "    787 군무원이 아닌 국민은 대한민국의 영역안에서는 중대한\n",
      "    1836 파견 또는 외국군대의 대한민국 영역안에서의 주류에\n",
      "    3620 경제 제119조 ① 대한민국의 경제질서는 개인과\n",
      "\n",
      "- zipf.png:\n",
      "    .. image:: zipf.png\n",
      "        :width: 100%\n",
      "\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for psg_idx in psg_idx_list:\n",
    "    print(psg_list[psg_idx])\n",
    "    print(\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ff144fc-98aa-4dc9-9105-344a3bb8c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 36, 49]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psg_idx_list_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
