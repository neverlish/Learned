{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309ed325-6cd0-4a96-bd2f-1e5141127a7b",
   "metadata": {},
   "source": [
    "# Langchain을 통해 가상 대화 상대 만들어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ae69c-65c2-4933-9ab6-150168e990b4",
   "metadata": {},
   "source": [
    "## 기본적인 AI Chat 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7e5dba-679c-4207-840a-215926100c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2d960a-92ea-4df0-b44f-b5eb94aeeba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e54240d-7243-43b8-a26c-54a07d1695a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/st3vh8xs6715dcgqc1gk2hhh0000gn/T/ipykernel_60801/3353824168.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574f9b65-550b-4a2d-8b3e-8477dcd54fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_chain = (  # {\"input\": \"hello\"}\n",
    "    RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n",
    "    ) # {\"input\": \"hello\", \"chat_history\": [~~~]}\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1189af-45fe-4392-96e5-d4e6dc4bdf90",
   "metadata": {},
   "source": [
    "### Runnable 이해하기\n",
    "\n",
    "#### LCEL(LangChain Expression Language)?\n",
    "- LangChain Expression Language, 또는 LCEL,은 체인을 쉽게 결합할 수 있는 선언적 방법입니다. LCEL은 가장 간단한 \"프롬프트 + LLM\" 체인부터 수만은 체인을 쉽게 연결 할 수 있도록 도와줍니다.\n",
    "- https://python.langchain.com/docs/expression_language/why\n",
    "- LCEL object 는 Runnable Interface를 구현함.\n",
    "\n",
    "#### Runnable Interface\n",
    "- Runnable Interface는 invoke, batch, stream, ainvoke 등을 구현해야함\n",
    "- Runnable은 '|'를 이용해 Chain으로 연결 할 수 있음\n",
    "\n",
    "#### RunnablePassthrough ?\n",
    "- RunnablePassthrough는 입력을 그대로 전달하거나 추가 키를 추가하여 전달할 수 있습니다. 이는 일반적으로 RunnableParallel과 함께 사용되어 맵에 새 키에 데이터를 할당합니다.\n",
    "- RunnablePassthrough()는 단독으로 호출될 경우, 입력을 그대로 받아서 전달합니다.\n",
    "- RunnablePassthrough가 assign 함수와 함께 호출되면 (RunnablePassthrough.assign(...)), 입력을 받아서 assign 함수에 전달된 추가 인자를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd15b5db-c11c-4827-9fd1-ea76a9b64647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RunnablePassthrough Example\n",
    "\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477848b2-ed4f-49a9-8b69-a23080f2bdea",
   "metadata": {},
   "source": [
    "### 다시 예제를 보면\n",
    "\n",
    "```python\n",
    "chain = (  # {\"input\": \"hello\"}\n",
    "    RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n",
    "    ) # {\"input\": \"hello\", \"chat_history\": [~~~]}\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7610ceef-72cb-4193-8a76-86f5f666a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # Runnable이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f7d8c9-902f-4b2d-8fc9-d3159a29ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.load_memory_variables를 Runnable로 만들고 \n",
    "get_memory_chain = RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cd1701-53c3-4a6a-8d75-169fd2dbcca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a4fa03-c4d8-46a0-a9d6-326c90b399d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 도움이 필요하신 것이 있나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 21, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BMBSMqUSOyli0dx3C1Rfvkwz830FF', 'finish_reason': 'stop', 'logprobs': None}, id='run-6bb7b1ad-302a-438a-82b7-b349f7ec32fb-0', usage_metadata={'input_tokens': 21, 'output_tokens': 22, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"안녕\"}\n",
    "response = conv_chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157c12d0-64af-4bc5-9c9e-a323b1af810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5a8987-6875-4fca-a1d2-38f1eee42b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(inputs, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a37e6af-ff52-4f44-92f4-6b6467dfd940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='안녕하세요! 도움이 필요하신 것이 있나요?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e37e8df-b520-4c07-9b5c-fa01750a3a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "quit_msg = {'q', ''}\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    if user_input in quit_msg:\n",
    "        break\n",
    "        \n",
    "    ai_output = conv_chain.invoke({\"input\": user_input})\n",
    "    print(f\"AI: {ai_output.content}\")\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": ai_output.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83465468-4390-478c-b22e-3e8ac6b73442",
   "metadata": {},
   "source": [
    "## 인격 부여하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5945259-98fe-4c15-9c8e-142aaa9ce839",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\\\n",
    "- 너는 20대 여성 AI 개발자이다.\n",
    "- 처음 만나는 1:1 소개팅 상황이다. 커피집에서 만났다.\n",
    "- 소개팅이기에 너무 도움을 주려고 대화하지 않는다. 자연스러운 대화를한다.\n",
    "- 너무 적극적으로 이야기하지 않는다.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "394cd3d7-d5ee-4322-ae9b-10f2b6648cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861a3dde-444e-4237-9f0d-e780222490cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"chat_history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73b63556-afe0-46ca-9c1c-c4fa522b7eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 안녕하세요. 만나서 반가워요. 혹시 커피는 드셔보셨나요?\n"
     ]
    }
   ],
   "source": [
    "quit_msg = {'q', ''}\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    if user_input in quit_msg:\n",
    "        break\n",
    "    ai_output = conv_chain.invoke({\"input\": user_input})\n",
    "    print(f\"AI: {ai_output.content}\")\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": ai_output.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4db40-f1bd-481c-a67e-49b8d22f4133",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "- streaming은 AI의 응답이 다 완성되기 이전에도 응답을 들을 수 있는 방법\n",
    "- 사용자가 기다리는 시간을 줄여줌\n",
    "- LCEL object들은 stream이 구현되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0929f498-bd9a-4dca-8fa2-a78288ee4234",
   "metadata": {},
   "source": [
    "### ChatModel의 Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c888d68c-81c4-4f50-af17-4e65c059675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c67d2be-038f-481c-acbf-db4cd2d5465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 도와드릴 수 있는 게 있나요? :)"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(\"안녕\"):\n",
    "    time.sleep(0.5)\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2f9b2-7079-4f09-a897-2dead549f27e",
   "metadata": {},
   "source": [
    "### Chain의 Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f518fac-cbb9-4139-90f5-4b486b67f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'input': '안녕'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8bf0479-1be1-4754-9642-94a27a78c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 오늘은 날씨가 좋네요. 요즘 할 일이 있나요?"
     ]
    }
   ],
   "source": [
    "# conv_chain도 LCEL object이기 때문에 stream이 구현되어있음\n",
    "for chunk in conv_chain.stream(inputs):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537cbf5-b884-4ccd-96d0-56265cfee58a",
   "metadata": {},
   "source": [
    "### Stream을 활용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75174174-4279-43a3-8a41-8dd5608db31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_msg = {'q', ''}\n",
    "while True:\n",
    "    user_input = input(\"user: \")\n",
    "    if user_input in quit_msg:\n",
    "        break\n",
    "    print(f\"AI: \", end='')\n",
    "    response = \"\"\n",
    "    for chunk in conv_chain.stream({\"input\": user_input}):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        response += chunk.content\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630c05c-f1bc-47ae-9d64-c01c62602d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
