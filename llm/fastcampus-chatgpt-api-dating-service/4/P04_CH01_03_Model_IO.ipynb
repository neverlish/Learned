{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c400862-e42c-4e3b-ab22-9c846a55d914",
   "metadata": {},
   "source": [
    "## Model I/O - LangChain으로 LLM 호출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f929d-23a8-4269-b1c7-f57d149be8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967a1117-e70d-4408-8f53-93cfea4ddf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276a289-b42c-46ec-87ee-feea8bc23664",
   "metadata": {},
   "source": [
    "### Chat / LLM 모델​\n",
    "\n",
    "두 가지 유형의 언어 모델이 있습니다\n",
    "\n",
    "- ChatModel: 입력으로 메시지 리스트를 받고 메시지를 반환하는 기본 모델\n",
    "- LLM: 입력으로 문자열을 받고 문자열을 반환하는 기본 모델 `2024년 1월 4일에 지원 종료.`\n",
    "\n",
    "```python\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI  # will be shut off on January 4th, 2024.\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "llm = OpenAI()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf69c55-0e81-4a23-9f75-a44c62cbc4f4",
   "metadata": {},
   "source": [
    "### Message\n",
    "\n",
    "기본 메시지 인터페이스는 BaseMessage에 의해 정의되며, 두 가지 필수 속성이 있습니다\n",
    "\n",
    "- content: 메시지의 내용입니다. 보통 문자열입니다.\n",
    "- role: BaseMessage가 오는 엔티티입니다.\n",
    "\n",
    "\n",
    "LangChain은 다양한 역할을 쉽게 구분할 수 있는 여러 객체를 제공합니다:\n",
    "\n",
    "- HumanMessage: 사용자/인간으로부터 오는 BaseMessage입니다.\n",
    "- AIMessage: AI/어시스턴트로부터 오는 BaseMessage입니다.\n",
    "- SystemMessage: 시스템으로부터 오는 BaseMessage입니다.\n",
    "- FunctionMessage / ToolMessage: 함수 또는 도구 호출의 결과를 포함하는 BaseMessage입니다.\n",
    "\n",
    "```python\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "llm.invoke(text)\n",
    "# >> Feetful of Fun\n",
    "\n",
    "chat_model.invoke(messages)\n",
    "# >> AIMessage(content=\"Socks O'Color\")\n",
    "```\n",
    "\n",
    "이들 역할 중 어느 것도 적절하지 않다면, `role`을 수동으로 지정할 수 있는 ChatMessage 클래스도 있습니다.\n",
    "\n",
    "LangChain은 LLM과 챗모델 모두에 공통적으로 사용되는 인터페이스를 제공합니다.\n",
    "그러나 주어진 언어 모델에 대한 프롬프트를 가장 효과적으로 구성하기 위해서는 두 모델의 차이점을 이해하는 것이 유용합니다.\n",
    "\n",
    "LLM이나 챗모델을 호출하는 가장 간단한 방법은 `.invoke()`를 사용하는 것입니다.\n",
    "\n",
    "- ChatModel.invoke: `BaseMessage의 리스트`를 입력으로 받고 `BaseMessage`를 반환합니다.\n",
    "- LLM.invoke: 문자열을 입력으로 받고 문자열을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb60fa79-5e04-4aab-b168-8b29f28d1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "# 계속 호출 방법이 업데이트 중\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "# from langchain_openai import ChatOpenAI  # pip install langchain_openai 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05010a5-f074-47b8-80c3-3a7f2cde6a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1x/st3vh8xs6715dcgqc1gk2hhh0000gn/T/ipykernel_58663/44520985.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI()\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918eacd6-8f26-4ee4-a438-3df878546491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 11, 'total_tokens': 33, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3899fe31-31ca-49f3-95e0-7dee69bbafb1-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"안녕\")  # 이렇게 호출하는게 권장되진 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bafa7-7b64-4d65-9693-782f51705bed",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b886a98-e907-40be-bf65-7786e4931e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712fc4b4-0ed4-4ba9-99ec-63f20bc90d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 시작\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 AI 번역 모델이다.\"),\n",
    "    HumanMessage(content=\"'안녕' 이 문장이 영어로 뭐야?\"),\n",
    "]\n",
    "\n",
    "# 챗 모델을 호출하여 응답을 받습니다.\n",
    "response = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5928c26b-b056-416f-92ae-6d0a75cb5491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"'안녕' 이라는 문장은 영어로 'hello' 또는 'hi'로 번역될 수 있어.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 42, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cd500c84-91e5-4c62-b047-71f25b069715-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f490ef2-1a60-446d-97df-8d9c26a328a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'안녕' 이라는 문장은 영어로 'hello' 또는 'hi'로 번역될 수 있어.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa52e0-99c3-4d92-b175-6ce06f95c5bd",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4db5c-d360-4121-850d-e8211805032c",
   "metadata": {},
   "source": [
    "Prompt template과 LLM 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75e3e5e-b8e5-46bb-b184-e3bbbeed85dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea047ece-4436-4f1e-9d1b-927b6f7fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 template\n",
    "human_message_prompt = \"'{text}' 여기서 키워드를 뽑아서 콤마로 구분해줘\"\n",
    "human_message_prompt_template = HumanMessagePromptTemplate.from_template(human_message_prompt)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a897e4-17f0-4a69-a552-a9f4ff9518e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4267d4ba-0447-4919-a1f5-30cb301c0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain.invoke({\"text\": \"LangChain is a framework for developing applications powered by language models.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16281632-8245-492b-8a6a-c9d6afe54eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain, framework, developing applications, language models', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 46, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4a1a69ce-fa35-4eb8-aaa8-e0a7e4b1ed5a-0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d994c502-974e-4126-ab8e-d3b91146254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain, framework, developing applications, language models'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51158d-e719-4f7f-84a9-de0b07a47ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
