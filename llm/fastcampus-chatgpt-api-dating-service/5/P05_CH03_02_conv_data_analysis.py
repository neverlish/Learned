import json
from typing import List
import streamlit as st
import pandas as pd
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.schema import StrOutputParser
from langchain.prompts import PromptTemplate
from langchain.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
)


####################################################
# Helpers


@st.cache_data
def load_conv_data():
    with open("./conv_data.json", "rt") as f:
        data = json.load(f)[0]
    return data


class CoT(BaseModel):
    thought: str = Field(description="Step-by-Step Thought Process")
    keywords: List[str] = Field(description="Answer")


def build_keyword_extractor_chain(model):
    parser = JsonOutputParser(pydantic_object=CoT)
    format_instructions = parser.get_format_instructions()

    prompt = PromptTemplate(
        template="{input}\n---\nìœ„ ëŒ€í™”ì—ì„œ ì‚¬ëŒ ì´ë¦„ì„ ì œì™¸í•˜ê³ , ëª…ì‚¬ ìœ„ì£¼ë¡œ ì¶”ë¡ ì„ í†µí•´ ì ì ˆí•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜. í•œêµ­ì–´ë¡œ ì‘ë‹µí•´.\n{format_instructions}",
        input_variables=["input"],
        partial_variables={"format_instructions": format_instructions},
    )
    chain = prompt | model | parser
    return chain


def build_affinity_chain(model):
    chat_message_prompt_template = ChatPromptTemplate.from_messages(
        [
            (
                "human",
                "{input}\n---\nìœ„ ëŒ€í™”ì—ì„œ ì°¸ê°€ìë³„ ë°œì–¸ì„ ëª‡ë²ˆ í–ˆëŠ”ì§€ ë¶„ì„í•´ì¤˜. ëŒ€í™”ì˜ íë¦„ë„ ë¶„ì„í•´ ì£¼ê³ , ë“±ì¥ ì¸ë¬¼ë“¤ì˜ í˜¸ê°ë„ë¥¼ ì •ë¦¬í•´ì„œ í‘œë¡œ ë§Œë“¤ì–´ì¤˜.  ",
            )
        ]
    )

    chain = chat_message_prompt_template | model | StrOutputParser()
    return chain


####################################################
# Initialize

if "messages" not in st.session_state:
    conv_list = load_conv_data()
    st.session_state.messages = conv_list


if "model" not in st.session_state:
    st.session_state.model = ChatOpenAI(model="gpt-4-1106-preview")

if "keyword_extractor_chain" not in st.session_state:
    st.session_state.keyword_extractor_chain = build_keyword_extractor_chain(
        st.session_state.model
    )


if "affinity_chain" not in st.session_state:
    st.session_state.affinity_chain = build_affinity_chain(st.session_state.model)


if "keywords" not in st.session_state:
    st.session_state.keywords = ""

if "report" not in st.session_state:
    st.session_state.report = ""


####################################################
# Sidebar

with st.sidebar:
    st.title("ğŸ§‘ğŸ»â€ğŸ’» ê°€ìƒì˜ ëŒ€í™” ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.header("ëŒ€í™” ë¶„ì„ ì˜µì…˜")
    flag_keyword_analysis = st.checkbox("í‚¤ì›Œë“œ ë¶„ì„")
    flag_comprehensive_analysis = st.checkbox("í¬ê´„ì  ëŒ€í™” ë¶„ì„")


####################################################
# Main

st.subheader("ëŒ€í™”")
with st.container(border=True, height=320):
    for msg in st.session_state.messages:
        role = "ğŸ‘©â€ğŸ’»" if msg["type"] == "human" else "ğŸ§‘ğŸ»â€ğŸ’»"
        with st.chat_message(role):
            st.markdown(msg["content"])


# ë¶„ì„ ê²°ê³¼ ì„¹ì…˜ (ëª¨ì˜ ë°ì´í„°)

if flag_keyword_analysis:

    st.subheader("í‚¤ì›Œë“œ ë¶„ì„")
    with st.container(border=True):
        if not st.session_state.keywords:
            with st.spinner("í‚¤ì›Œë“œ ë¶„ì„ì¤‘..."):
                conv_data = load_conv_data()
                conv_text = ""
                for msg in conv_data:
                    role = "ğŸ‘©â€ğŸ’» ì§€í˜„" if msg["type"] == "human" else "ğŸ§‘ğŸ»â€ğŸ’» ì¤€í˜¸"
                    conv_text += f"{role}: {msg['content']}\n"
                st.session_state.keywords = (
                    st.session_state.keyword_extractor_chain.invoke(
                        {"input": conv_text}
                    )
                )

        st.markdown(st.session_state.keywords["thought"])
        st.markdown(
            "\n".join([f"- {k}" for k in st.session_state.keywords["keywords"][:3]])
        )

if flag_comprehensive_analysis:

    st.subheader("í¬ê´„ì  ëŒ€í™” ë¶„ì„")
    with st.container(border=True):

        message_placeholder = st.empty()
        if not st.session_state.report:
            conv_data = load_conv_data()
            conv_text = ""
            for msg in conv_data:
                role = "ğŸ‘©â€ğŸ’» ì§€í˜„" if msg["type"] == "human" else "ğŸ§‘ğŸ»â€ğŸ’» ì¤€í˜¸"
                conv_text += f"{role}: {msg['content']}\n"

            full_response = ""
            for chunk in st.session_state.affinity_chain.stream({"input": conv_text}):
                full_response += chunk or ""
                message_placeholder.markdown(full_response + "â–Œ")
            st.session_state.report = full_response

        message_placeholder.markdown(st.session_state.report)
